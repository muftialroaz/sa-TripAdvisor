{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset for Aspect-Based Sentiment Analysis and Topic Modeling on Borobudur Temple and Prambanan Temple by Dian Arianto\n",
    "https://github.com/dian9395/dataset-analisis-sentimen-berbasis-aspek-dan-pemodelan-topik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lokasi</th>\n",
       "      <th>text</th>\n",
       "      <th>daya_tarik</th>\n",
       "      <th>amenitas</th>\n",
       "      <th>aksesibilitas</th>\n",
       "      <th>citra</th>\n",
       "      <th>harga</th>\n",
       "      <th>sdm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Candi Borobudur</td>\n",
       "      <td>peninggalan sejarah yang sudah berumur 1200 ta...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Candi Borobudur</td>\n",
       "      <td>Pertama kali bepergian selama masa pandemi. Ca...</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Candi Borobudur</td>\n",
       "      <td>Candi Borobudur di Magelang, Yogyakarta adalah...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Candi Borobudur</td>\n",
       "      <td>Baru pertama kali kesini, pas sih kalau tempat...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Candi Borobudur</td>\n",
       "      <td>candi borobudur, tempat wisata ini sudah terke...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6738</th>\n",
       "      <td>6739.0</td>\n",
       "      <td>Candi Prambanan</td>\n",
       "      <td>The place is great and probably everything you...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6739</th>\n",
       "      <td>6740.0</td>\n",
       "      <td>Candi Prambanan</td>\n",
       "      <td>Prambanan or Rara Jonggrang (Javanese: ꦫꦫꦗꦺꦴꦁꦒ...</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6740</th>\n",
       "      <td>6741.0</td>\n",
       "      <td>Candi Prambanan</td>\n",
       "      <td>This temple is not worth the price. There’s no...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6741</th>\n",
       "      <td>6742.0</td>\n",
       "      <td>Candi Prambanan</td>\n",
       "      <td>Prambanan temple is the largest hindu temple o...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6742</th>\n",
       "      <td>6743.0</td>\n",
       "      <td>Candi Prambanan</td>\n",
       "      <td>Best choice for me of the three most-famous te...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6743 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id           lokasi  \\\n",
       "0        1.0  Candi Borobudur   \n",
       "1        2.0  Candi Borobudur   \n",
       "2        3.0  Candi Borobudur   \n",
       "3        4.0  Candi Borobudur   \n",
       "4        5.0  Candi Borobudur   \n",
       "...      ...              ...   \n",
       "6738  6739.0  Candi Prambanan   \n",
       "6739  6740.0  Candi Prambanan   \n",
       "6740  6741.0  Candi Prambanan   \n",
       "6741  6742.0  Candi Prambanan   \n",
       "6742  6743.0  Candi Prambanan   \n",
       "\n",
       "                                                   text daya_tarik amenitas  \\\n",
       "0     peninggalan sejarah yang sudah berumur 1200 ta...          1        -   \n",
       "1     Pertama kali bepergian selama masa pandemi. Ca...          -        1   \n",
       "2     Candi Borobudur di Magelang, Yogyakarta adalah...          1        -   \n",
       "3     Baru pertama kali kesini, pas sih kalau tempat...          1        -   \n",
       "4     candi borobudur, tempat wisata ini sudah terke...          1        1   \n",
       "...                                                 ...        ...      ...   \n",
       "6738  The place is great and probably everything you...          1        -   \n",
       "6739  Prambanan or Rara Jonggrang (Javanese: ꦫꦫꦗꦺꦴꦁꦒ...          0        -   \n",
       "6740  This temple is not worth the price. There’s no...         -1        -   \n",
       "6741  Prambanan temple is the largest hindu temple o...          1        -   \n",
       "6742  Best choice for me of the three most-famous te...          1        -   \n",
       "\n",
       "     aksesibilitas citra harga sdm  \n",
       "0                -     1     0   0  \n",
       "1                -     1     -   1  \n",
       "2                -     1     -   -  \n",
       "3                -     -    -1   -  \n",
       "4                -     1     -   -  \n",
       "...            ...   ...   ...  ..  \n",
       "6738             -     -    -1   -  \n",
       "6739             -     -     -   -  \n",
       "6740             -    -1    -1  -1  \n",
       "6741             -     -     -   -  \n",
       "6742             -     -    -1   -  \n",
       "\n",
       "[6743 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('dataset/reviews_borobudur_prambanan_TripAdvisor_GMaps_all_tesis.xlsx')\n",
    "df_clean = df.dropna()\n",
    "# print(\"\\nDrop rows with any NaN values:\")\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = df_clean['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Emoji processing; case folding; menghapus username, angka, dan tanda baca; koreksi ejaan dan singkatan serta menghapus whitespace; penghapusan stopwords, dan stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Daftar emoji berdasarkan sentimen\n",
    "emoji_positif = [\"😊\", \"😄\", \"♥\", \"😍\", \"😘\", \"😃\", \"😁\", \"😆\", \"😇\", \"☺\"]\n",
    "emoji_negatif = [\"😢\", \"😠\", \"😡\", \"😭\", \"😱\", \"😨\", \"😫\", \"😩\", \"😖\", \"😔\"]\n",
    "emoji_netral = [\"👍\", \"✨\", \"★\", \"█\", \"👌\", \"♫\", \"�\", \"©\", \"💬\", \"🔔\"]\n",
    "\n",
    "# Fungsi untuk mengganti emoji dengan label sentimen\n",
    "def emotion(teks):\n",
    "    for emoji in emoji_positif:\n",
    "        teks = teks.replace(emoji, \"positif\")\n",
    "    for emoji in emoji_negatif:\n",
    "        teks = teks.replace(emoji, \"negatif\")\n",
    "    for emoji in emoji_netral:\n",
    "        teks = teks.replace(emoji, \"netral\")\n",
    "    return teks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1qqSuE1tuDCCfsdKgXMC3Nj0jda1LuWXB\n",
      "To: d:\\PROJECT\\Python-Pro\\sa-TripAdvisor\\stopwords_uci.txt\n",
      "100%|██████████| 6.91k/6.91k [00:00<00:00, 1.06MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Ufurgc02rF2_yuFh8GNw1VOpkNbJLKWx\n",
      "To: d:\\PROJECT\\Python-Pro\\sa-TripAdvisor\\stopwords_nltk.txt\n",
      "100%|██████████| 7.39k/7.39k [00:00<00:00, 922kB/s]\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "# URL dari file Google Drive\n",
    "stopwords_uci_link = 'https://drive.google.com/uc?id=1qqSuE1tuDCCfsdKgXMC3Nj0jda1LuWXB'\n",
    "stopwords_nltk_link = 'https://drive.google.com/uc?id=1Ufurgc02rF2_yuFh8GNw1VOpkNbJLKWx'\n",
    "stopwords_uci_output = 'stopwords_uci.txt'\n",
    "stopwords_nltk_output = 'stopwords_nltk.txt'\n",
    "# Mengunduh file\n",
    "gdown.download(stopwords_uci_link, stopwords_uci_output, quiet=False)\n",
    "gdown.download(stopwords_nltk_link, stopwords_nltk_output, quiet=False)\n",
    "# Membaca konten file\n",
    "with open(stopwords_uci_output, 'r', encoding='utf-8') as file:\n",
    "    stopwords_uci = file.read()\n",
    "with open(stopwords_nltk_output, 'r', encoding='utf-8') as file:\n",
    "    stopwords_nltk = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # text preprocessing\n",
    "    teks = emotion(text)\n",
    "    teks = teks.lower()\n",
    "    teks = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    stop_words = set(stopwords.words('english') + stopwords_uci.split('\\n') + stopwords_nltk.split('\\n'))\n",
    "    tokens = word_tokenize(teks)\n",
    "    filtered_tokens = [word for word in tokens if word.isalnum() and not any(char.isdigit() for char in word) and word not in stop_words]\n",
    "    stemmer_factory = StemmerFactory()\n",
    "    sastrawi_stemmer = stemmer_factory.create_stemmer()\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    lemma = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    indonesian_stemmed_words = [sastrawi_stemmer.stem(word) for word in lemma]\n",
    "    clean_reviews = ' '.join(indonesian_stemmed_words)\n",
    "    return clean_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       tinggal sejarah umur indonesia bangsa indonesi...\n",
       "1       pertama kali pergi pandemi candi borobudur pro...\n",
       "2       candi borobudur magelang yogyakarta salah reko...\n",
       "3       baru kali kesini pa sih ajaib dunia sulit baya...\n",
       "4       candi borobudur wisata kenal dunia ganti sy wi...\n",
       "                              ...                        \n",
       "6738    the place great probably everything expect how...\n",
       "6739    prambanan rara jonggrang javanese romanized ra...\n",
       "6740    this temple worth price theres much see poorly...\n",
       "6741    prambanan temple largest hindu temple ancient ...\n",
       "6742    best choice three mostfamous temple yogyakarta...\n",
       "Name: text, Length: 6743, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teks = review.apply(preprocess)\n",
    "teks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ekstraksi Fitur\n",
    "words n-gram. words unigram+bigram+trigram untuk fiturnya dan vektornya diekstraksi dengan CountVectorizer dari pustaka Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eksperimen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis Sentimen Berbasis Aspek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import resample\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>daya_tarik</th>\n",
       "      <th>amenitas</th>\n",
       "      <th>aksesibilitas</th>\n",
       "      <th>citra</th>\n",
       "      <th>harga</th>\n",
       "      <th>sdm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tinggal sejarah umur indonesia bangsa indonesi...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pertama kali pergi pandemi candi borobudur pro...</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>candi borobudur magelang yogyakarta salah reko...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baru kali kesini pa sih ajaib dunia sulit baya...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>candi borobudur wisata kenal dunia ganti sy wi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text daya_tarik amenitas  \\\n",
       "0  tinggal sejarah umur indonesia bangsa indonesi...          1        -   \n",
       "1  pertama kali pergi pandemi candi borobudur pro...          -        1   \n",
       "2  candi borobudur magelang yogyakarta salah reko...          1        -   \n",
       "3  baru kali kesini pa sih ajaib dunia sulit baya...          1        -   \n",
       "4  candi borobudur wisata kenal dunia ganti sy wi...          1        1   \n",
       "\n",
       "  aksesibilitas citra harga sdm  \n",
       "0             -     1     0   0  \n",
       "1             -     1     -   1  \n",
       "2             -     1     -   -  \n",
       "3             -     -    -1   -  \n",
       "4             -     1     -   -  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess = pd.concat([pd.DataFrame(teks), df_clean['daya_tarik'], df_clean['amenitas'], df_clean['aksesibilitas'], df_clean['citra'], df_clean['harga'], df_clean['sdm']], axis=1)\n",
    "preprocess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tinggal sejarah umur indonesia bangsa indonesi...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>candi borobudur magelang yogyakarta salah reko...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baru kali kesini pa sih ajaib dunia sulit baya...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>candi borobudur wisata kenal dunia ganti sy wi...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wajar salah ajaib dunia candi bangun tingkat t...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      aspect sentiment\n",
       "0  tinggal sejarah umur indonesia bangsa indonesi...  daya_tarik         1\n",
       "2  candi borobudur magelang yogyakarta salah reko...  daya_tarik         1\n",
       "3  baru kali kesini pa sih ajaib dunia sulit baya...  daya_tarik         1\n",
       "4  candi borobudur wisata kenal dunia ganti sy wi...  daya_tarik         1\n",
       "5  wajar salah ajaib dunia candi bangun tingkat t...  daya_tarik         1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Melakukan melting pada dataframe\n",
    "melted_df = preprocess.melt(id_vars=['text'], value_vars=['daya_tarik', 'amenitas', 'aksesibilitas', 'citra', 'harga', 'sdm'],\n",
    "                    var_name='aspect', value_name='sentiment')\n",
    "# Menghapus baris dengan nilai '-' pada kolom sentiment\n",
    "melted_df = melted_df[melted_df['sentiment'] != '-']\n",
    "\n",
    "melted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tinggal sejarah umur indonesia bangsa indonesi...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>candi borobudur magelang yogyakarta salah reko...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baru kali kesini pa sih ajaib dunia sulit baya...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>candi borobudur wisata kenal dunia ganti sy wi...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wajar salah ajaib dunia candi bangun tingkat t...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      aspect sentiment\n",
       "0  tinggal sejarah umur indonesia bangsa indonesi...  daya_tarik  positive\n",
       "2  candi borobudur magelang yogyakarta salah reko...  daya_tarik  positive\n",
       "3  baru kali kesini pa sih ajaib dunia sulit baya...  daya_tarik  positive\n",
       "4  candi borobudur wisata kenal dunia ganti sy wi...  daya_tarik  positive\n",
       "5  wajar salah ajaib dunia candi bangun tingkat t...  daya_tarik  positive"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mengubah nilai sentiment\n",
    "sentiment_mapping = {1: 'positive', 0: 'neutral', -1: 'negative'}\n",
    "melted_df['sentiment'] = melted_df['sentiment'].astype(int).map(sentiment_mapping)\n",
    "melted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memisahkan dataframe berdasarkan aspek\n",
    "dfs_melted_df = {aspect: melted_df[melted_df['aspect'] == aspect] for aspect in melted_df['aspect'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daftar algoritma klasifikasi\n",
    "classifiers = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Extra Trees': ExtraTreesClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aspect: daya_tarik\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         9\n",
      "     neutral       0.00      0.00      0.00        64\n",
      "    positive       0.94      1.00      0.97      1120\n",
      "\n",
      "    accuracy                           0.94      1193\n",
      "   macro avg       0.31      0.33      0.32      1193\n",
      "weighted avg       0.88      0.94      0.91      1193\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         9\n",
      "     neutral       0.40      0.03      0.06        64\n",
      "    positive       0.94      1.00      0.97      1120\n",
      "\n",
      "    accuracy                           0.94      1193\n",
      "   macro avg       0.45      0.34      0.34      1193\n",
      "weighted avg       0.90      0.94      0.91      1193\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         9\n",
      "     neutral       0.06      0.06      0.06        64\n",
      "    positive       0.94      0.94      0.94      1120\n",
      "\n",
      "    accuracy                           0.88      1193\n",
      "   macro avg       0.33      0.33      0.33      1193\n",
      "weighted avg       0.88      0.88      0.88      1193\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         9\n",
      "     neutral       0.17      0.02      0.03        64\n",
      "    positive       0.94      1.00      0.97      1120\n",
      "\n",
      "    accuracy                           0.94      1193\n",
      "   macro avg       0.37      0.34      0.33      1193\n",
      "weighted avg       0.89      0.94      0.91      1193\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         9\n",
      "     neutral       0.25      0.02      0.03        64\n",
      "    positive       0.94      1.00      0.97      1120\n",
      "\n",
      "    accuracy                           0.94      1193\n",
      "   macro avg       0.40      0.34      0.33      1193\n",
      "weighted avg       0.90      0.94      0.91      1193\n",
      "\n",
      "\n",
      "Aspect: amenitas\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.00      0.00      0.00         8\n",
      "    positive       0.78      1.00      0.88       225\n",
      "\n",
      "    accuracy                           0.78       287\n",
      "   macro avg       0.26      0.33      0.29       287\n",
      "weighted avg       0.61      0.78      0.69       287\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.24      0.39        54\n",
      "     neutral       0.00      0.00      0.00         8\n",
      "    positive       0.82      1.00      0.90       225\n",
      "\n",
      "    accuracy                           0.83       287\n",
      "   macro avg       0.61      0.41      0.43       287\n",
      "weighted avg       0.83      0.83      0.78       287\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.55      0.52      0.53        54\n",
      "     neutral       0.00      0.00      0.00         8\n",
      "    positive       0.87      0.86      0.87       225\n",
      "\n",
      "    accuracy                           0.77       287\n",
      "   macro avg       0.47      0.46      0.47       287\n",
      "weighted avg       0.79      0.77      0.78       287\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.35      0.51        54\n",
      "     neutral       0.00      0.00      0.00         8\n",
      "    positive       0.84      0.99      0.91       225\n",
      "\n",
      "    accuracy                           0.84       287\n",
      "   macro avg       0.58      0.45      0.47       287\n",
      "weighted avg       0.83      0.84      0.81       287\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.41      0.58        54\n",
      "     neutral       0.00      0.00      0.00         8\n",
      "    positive       0.85      1.00      0.92       225\n",
      "\n",
      "    accuracy                           0.86       287\n",
      "   macro avg       0.62      0.47      0.50       287\n",
      "weighted avg       0.85      0.86      0.83       287\n",
      "\n",
      "\n",
      "Aspect: aksesibilitas\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.25      0.39        48\n",
      "     neutral       0.00      0.00      0.00        23\n",
      "    positive       0.64      0.98      0.78       108\n",
      "\n",
      "    accuracy                           0.66       179\n",
      "   macro avg       0.50      0.41      0.39       179\n",
      "weighted avg       0.62      0.66      0.57       179\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.67      0.70        48\n",
      "     neutral       0.00      0.00      0.00        23\n",
      "    positive       0.74      0.92      0.82       108\n",
      "\n",
      "    accuracy                           0.73       179\n",
      "   macro avg       0.49      0.53      0.50       179\n",
      "weighted avg       0.64      0.73      0.68       179\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.49      0.60      0.54        48\n",
      "     neutral       0.24      0.22      0.23        23\n",
      "    positive       0.73      0.67      0.70       108\n",
      "\n",
      "    accuracy                           0.59       179\n",
      "   macro avg       0.49      0.50      0.49       179\n",
      "weighted avg       0.60      0.59      0.59       179\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.69      0.68        48\n",
      "     neutral       0.00      0.00      0.00        23\n",
      "    positive       0.73      0.87      0.80       108\n",
      "\n",
      "    accuracy                           0.71       179\n",
      "   macro avg       0.47      0.52      0.49       179\n",
      "weighted avg       0.62      0.71      0.66       179\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.71      0.69        48\n",
      "     neutral       0.33      0.04      0.08        23\n",
      "    positive       0.75      0.87      0.80       108\n",
      "\n",
      "    accuracy                           0.72       179\n",
      "   macro avg       0.59      0.54      0.52       179\n",
      "weighted avg       0.68      0.72      0.68       179\n",
      "\n",
      "\n",
      "Aspect: citra\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       109\n",
      "     neutral       0.00      0.00      0.00        40\n",
      "    positive       0.84      1.00      0.91       757\n",
      "\n",
      "    accuracy                           0.84       906\n",
      "   macro avg       0.28      0.33      0.30       906\n",
      "weighted avg       0.70      0.84      0.76       906\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.21      0.31       109\n",
      "     neutral       0.00      0.00      0.00        40\n",
      "    positive       0.86      0.98      0.92       757\n",
      "\n",
      "    accuracy                           0.85       906\n",
      "   macro avg       0.48      0.40      0.41       906\n",
      "weighted avg       0.79      0.85      0.80       906\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.44      0.42       109\n",
      "     neutral       0.12      0.10      0.11        40\n",
      "    positive       0.89      0.89      0.89       757\n",
      "\n",
      "    accuracy                           0.80       906\n",
      "   macro avg       0.47      0.48      0.47       906\n",
      "weighted avg       0.80      0.80      0.80       906\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.23      0.33       109\n",
      "     neutral       0.00      0.00      0.00        40\n",
      "    positive       0.86      0.99      0.92       757\n",
      "\n",
      "    accuracy                           0.85       906\n",
      "   macro avg       0.49      0.40      0.42       906\n",
      "weighted avg       0.79      0.85      0.81       906\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.19      0.30       109\n",
      "     neutral       0.00      0.00      0.00        40\n",
      "    positive       0.86      0.99      0.92       757\n",
      "\n",
      "    accuracy                           0.85       906\n",
      "   macro avg       0.50      0.39      0.40       906\n",
      "weighted avg       0.79      0.85      0.80       906\n",
      "\n",
      "\n",
      "Aspect: harga\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.58      0.66        81\n",
      "     neutral       0.52      0.93      0.67        74\n",
      "    positive       0.70      0.29      0.41        66\n",
      "\n",
      "    accuracy                           0.61       221\n",
      "   macro avg       0.66      0.60      0.58       221\n",
      "weighted avg       0.66      0.61      0.59       221\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.73      0.78        81\n",
      "     neutral       0.58      0.82      0.68        74\n",
      "    positive       0.71      0.48      0.58        66\n",
      "\n",
      "    accuracy                           0.69       221\n",
      "   macro avg       0.71      0.68      0.68       221\n",
      "weighted avg       0.71      0.69      0.69       221\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.57      0.58        81\n",
      "     neutral       0.58      0.59      0.59        74\n",
      "    positive       0.57      0.59      0.58        66\n",
      "\n",
      "    accuracy                           0.58       221\n",
      "   macro avg       0.58      0.58      0.58       221\n",
      "weighted avg       0.58      0.58      0.58       221\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.65      0.71        81\n",
      "     neutral       0.54      0.84      0.66        74\n",
      "    positive       0.74      0.42      0.54        66\n",
      "\n",
      "    accuracy                           0.65       221\n",
      "   macro avg       0.68      0.64      0.63       221\n",
      "weighted avg       0.68      0.65      0.64       221\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.63      0.68        81\n",
      "     neutral       0.53      0.81      0.64        74\n",
      "    positive       0.64      0.38      0.48        66\n",
      "\n",
      "    accuracy                           0.62       221\n",
      "   macro avg       0.64      0.61      0.60       221\n",
      "weighted avg       0.64      0.62      0.61       221\n",
      "\n",
      "\n",
      "Aspect: sdm\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        21\n",
      "     neutral       0.00      0.00      0.00         7\n",
      "    positive       0.73      1.00      0.85        77\n",
      "\n",
      "    accuracy                           0.73       105\n",
      "   macro avg       0.24      0.33      0.28       105\n",
      "weighted avg       0.54      0.73      0.62       105\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25        21\n",
      "     neutral       0.00      0.00      0.00         7\n",
      "    positive       0.75      1.00      0.86        77\n",
      "\n",
      "    accuracy                           0.76       105\n",
      "   macro avg       0.58      0.38      0.37       105\n",
      "weighted avg       0.75      0.76      0.68       105\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.24      0.29        21\n",
      "     neutral       0.00      0.00      0.00         7\n",
      "    positive       0.78      0.88      0.83        77\n",
      "\n",
      "    accuracy                           0.70       105\n",
      "   macro avg       0.39      0.37      0.37       105\n",
      "weighted avg       0.65      0.70      0.67       105\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25        21\n",
      "     neutral       0.00      0.00      0.00         7\n",
      "    positive       0.75      1.00      0.86        77\n",
      "\n",
      "    accuracy                           0.76       105\n",
      "   macro avg       0.58      0.38      0.37       105\n",
      "weighted avg       0.75      0.76      0.68       105\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.19      0.32        21\n",
      "     neutral       0.00      0.00      0.00         7\n",
      "    positive       0.76      1.00      0.87        77\n",
      "\n",
      "    accuracy                           0.77       105\n",
      "   macro avg       0.59      0.40      0.40       105\n",
      "weighted avg       0.76      0.77      0.70       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Melakukan pelatihan dan evaluasi model untuk setiap aspek dan setiap algoritma\n",
    "for aspect, df_aspect in dfs_melted_df.items():\n",
    "    print(f'\\nAspect: {aspect}')\n",
    "    # Membagi data menjadi data latih dan data uji\n",
    "    X = df_aspect['text']\n",
    "    y = df_aspect['sentiment']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    for clf_name, clf in classifiers.items():\n",
    "        # Membuat pipeline dengan TfidfVectorizer dan classifier\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(max_features=100000)),\n",
    "            ('clf', clf)\n",
    "        ])\n",
    "        # Melakukan pelatihan model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Melakukan prediksi\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        # Evaluasi model\n",
    "        print(f'\\nClassification Report with {clf_name}:')\n",
    "        print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aspect: daya_tarik\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        56\n",
      "     neutral       0.00      0.00      0.00       345\n",
      "    positive       0.93      1.00      0.97      5561\n",
      "\n",
      "    accuracy                           0.93      5962\n",
      "   macro avg       0.31      0.33      0.32      5962\n",
      "weighted avg       0.87      0.93      0.90      5962\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        56\n",
      "     neutral       0.62      0.01      0.03       345\n",
      "    positive       0.93      1.00      0.97      5561\n",
      "\n",
      "    accuracy                           0.93      5962\n",
      "   macro avg       0.52      0.34      0.33      5962\n",
      "weighted avg       0.91      0.93      0.90      5962\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.04      0.04      0.04        56\n",
      "     neutral       0.11      0.10      0.11       345\n",
      "    positive       0.94      0.94      0.94      5561\n",
      "\n",
      "    accuracy                           0.89      5962\n",
      "   macro avg       0.36      0.36      0.36      5962\n",
      "weighted avg       0.88      0.89      0.88      5962\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        56\n",
      "     neutral       0.25      0.02      0.03       345\n",
      "    positive       0.93      1.00      0.96      5561\n",
      "\n",
      "    accuracy                           0.93      5962\n",
      "   macro avg       0.39      0.34      0.33      5962\n",
      "weighted avg       0.89      0.93      0.90      5962\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        56\n",
      "     neutral       0.32      0.03      0.06       345\n",
      "    positive       0.93      1.00      0.96      5561\n",
      "\n",
      "    accuracy                           0.93      5962\n",
      "   macro avg       0.42      0.34      0.34      5962\n",
      "weighted avg       0.89      0.93      0.90      5962\n",
      "\n",
      "\n",
      "Aspect: amenitas\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       245\n",
      "     neutral       0.00      0.00      0.00        47\n",
      "    positive       0.80      1.00      0.89      1141\n",
      "\n",
      "    accuracy                           0.80      1433\n",
      "   macro avg       0.27      0.33      0.30      1433\n",
      "weighted avg       0.63      0.80      0.71      1433\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.17      0.29       245\n",
      "     neutral       0.00      0.00      0.00        47\n",
      "    positive       0.82      1.00      0.90      1141\n",
      "\n",
      "    accuracy                           0.82      1433\n",
      "   macro avg       0.59      0.39      0.40      1433\n",
      "weighted avg       0.82      0.82      0.77      1433\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.42      0.44      0.43       245\n",
      "     neutral       0.06      0.04      0.05        47\n",
      "    positive       0.86      0.86      0.86      1141\n",
      "\n",
      "    accuracy                           0.76      1433\n",
      "   macro avg       0.44      0.45      0.44      1433\n",
      "weighted avg       0.75      0.76      0.76      1433\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.25      0.39       245\n",
      "     neutral       0.00      0.00      0.00        47\n",
      "    positive       0.83      0.99      0.90      1141\n",
      "\n",
      "    accuracy                           0.83      1433\n",
      "   macro avg       0.56      0.41      0.43      1433\n",
      "weighted avg       0.81      0.83      0.79      1433\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.33      0.47       245\n",
      "     neutral       0.00      0.00      0.00        47\n",
      "    positive       0.84      0.99      0.91      1141\n",
      "\n",
      "    accuracy                           0.84      1433\n",
      "   macro avg       0.57      0.44      0.46      1433\n",
      "weighted avg       0.82      0.84      0.81      1433\n",
      "\n",
      "\n",
      "Aspect: aksesibilitas\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.20      0.33       277\n",
      "     neutral       0.00      0.00      0.00       127\n",
      "    positive       0.58      1.00      0.74       488\n",
      "\n",
      "    accuracy                           0.61       892\n",
      "   macro avg       0.51      0.40      0.35       892\n",
      "weighted avg       0.61      0.61      0.50       892\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71       277\n",
      "     neutral       0.80      0.03      0.06       127\n",
      "    positive       0.69      0.96      0.80       488\n",
      "\n",
      "    accuracy                           0.72       892\n",
      "   macro avg       0.77      0.54      0.52       892\n",
      "weighted avg       0.75      0.72      0.67       892\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.58      0.60       277\n",
      "     neutral       0.28      0.28      0.28       127\n",
      "    positive       0.69      0.72      0.70       488\n",
      "\n",
      "    accuracy                           0.61       892\n",
      "   macro avg       0.53      0.53      0.53       892\n",
      "weighted avg       0.61      0.61      0.61       892\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.65      0.71       277\n",
      "     neutral       0.60      0.02      0.05       127\n",
      "    positive       0.69      0.93      0.79       488\n",
      "\n",
      "    accuracy                           0.72       892\n",
      "   macro avg       0.69      0.53      0.52       892\n",
      "weighted avg       0.71      0.72      0.66       892\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.64      0.70       277\n",
      "     neutral       0.43      0.02      0.04       127\n",
      "    positive       0.69      0.93      0.79       488\n",
      "\n",
      "    accuracy                           0.71       892\n",
      "   macro avg       0.63      0.53      0.51       892\n",
      "weighted avg       0.68      0.71      0.66       892\n",
      "\n",
      "\n",
      "Aspect: citra\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       560\n",
      "     neutral       0.00      0.00      0.00       159\n",
      "    positive       0.84      1.00      0.91      3811\n",
      "\n",
      "    accuracy                           0.84      4530\n",
      "   macro avg       0.28      0.33      0.30      4530\n",
      "weighted avg       0.71      0.84      0.77      4530\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.22      0.34       560\n",
      "     neutral       0.00      0.00      0.00       159\n",
      "    positive       0.87      0.99      0.93      3811\n",
      "\n",
      "    accuracy                           0.86      4530\n",
      "   macro avg       0.52      0.40      0.42      4530\n",
      "weighted avg       0.82      0.86      0.82      4530\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.37      0.38       560\n",
      "     neutral       0.07      0.06      0.07       159\n",
      "    positive       0.89      0.90      0.90      3811\n",
      "\n",
      "    accuracy                           0.81      4530\n",
      "   macro avg       0.45      0.45      0.45      4530\n",
      "weighted avg       0.80      0.81      0.80      4530\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.20      0.30       560\n",
      "     neutral       0.33      0.01      0.02       159\n",
      "    positive       0.87      0.99      0.92      3811\n",
      "\n",
      "    accuracy                           0.86      4530\n",
      "   macro avg       0.62      0.40      0.42      4530\n",
      "weighted avg       0.82      0.86      0.81      4530\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.21      0.32       560\n",
      "     neutral       0.14      0.01      0.01       159\n",
      "    positive       0.87      0.99      0.92      3811\n",
      "\n",
      "    accuracy                           0.86      4530\n",
      "   macro avg       0.57      0.40      0.42      4530\n",
      "weighted avg       0.82      0.86      0.82      4530\n",
      "\n",
      "\n",
      "Aspect: harga\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.62      0.61       362\n",
      "     neutral       0.52      0.78      0.63       411\n",
      "    positive       0.70      0.25      0.37       330\n",
      "\n",
      "    accuracy                           0.57      1103\n",
      "   macro avg       0.61      0.55      0.54      1103\n",
      "weighted avg       0.60      0.57      0.54      1103\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.73      0.72       362\n",
      "     neutral       0.59      0.76      0.67       411\n",
      "    positive       0.68      0.43      0.53       330\n",
      "\n",
      "    accuracy                           0.65      1103\n",
      "   macro avg       0.66      0.64      0.64      1103\n",
      "weighted avg       0.66      0.65      0.64      1103\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.64      0.64       362\n",
      "     neutral       0.57      0.57      0.57       411\n",
      "    positive       0.51      0.50      0.51       330\n",
      "\n",
      "    accuracy                           0.57      1103\n",
      "   macro avg       0.57      0.57      0.57      1103\n",
      "weighted avg       0.57      0.57      0.57      1103\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.78      0.72       362\n",
      "     neutral       0.63      0.74      0.68       411\n",
      "    positive       0.74      0.43      0.55       330\n",
      "\n",
      "    accuracy                           0.66      1103\n",
      "   macro avg       0.68      0.65      0.65      1103\n",
      "weighted avg       0.67      0.66      0.65      1103\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.78      0.71       362\n",
      "     neutral       0.59      0.71      0.64       411\n",
      "    positive       0.68      0.38      0.49       330\n",
      "\n",
      "    accuracy                           0.63      1103\n",
      "   macro avg       0.64      0.62      0.61      1103\n",
      "weighted avg       0.64      0.63      0.62      1103\n",
      "\n",
      "\n",
      "Aspect: sdm\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       118\n",
      "     neutral       0.00      0.00      0.00        27\n",
      "    positive       0.72      1.00      0.84       376\n",
      "\n",
      "    accuracy                           0.72       521\n",
      "   macro avg       0.24      0.33      0.28       521\n",
      "weighted avg       0.52      0.72      0.61       521\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.14      0.23       118\n",
      "     neutral       0.00      0.00      0.00        27\n",
      "    positive       0.74      0.99      0.85       376\n",
      "\n",
      "    accuracy                           0.74       521\n",
      "   macro avg       0.50      0.37      0.36       521\n",
      "weighted avg       0.71      0.74      0.66       521\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.51      0.55       118\n",
      "     neutral       0.07      0.04      0.05        27\n",
      "    positive       0.80      0.86      0.83       376\n",
      "\n",
      "    accuracy                           0.74       521\n",
      "   macro avg       0.49      0.47      0.48       521\n",
      "weighted avg       0.72      0.74      0.73       521\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.17      0.28       118\n",
      "     neutral       0.00      0.00      0.00        27\n",
      "    positive       0.75      0.98      0.85       376\n",
      "\n",
      "    accuracy                           0.74       521\n",
      "   macro avg       0.50      0.38      0.37       521\n",
      "weighted avg       0.71      0.74      0.67       521\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.25      0.37       118\n",
      "     neutral       0.00      0.00      0.00        27\n",
      "    positive       0.76      0.97      0.85       376\n",
      "\n",
      "    accuracy                           0.76       521\n",
      "   macro avg       0.50      0.41      0.41       521\n",
      "weighted avg       0.71      0.76      0.70       521\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Melakukan pelatihan dan evaluasi model untuk setiap aspek dan setiap algoritma dengan cross-validation\n",
    "for aspect, df_aspect in dfs_melted_df.items():\n",
    "    print(f'\\nAspect: {aspect}')\n",
    "    # Membagi data menjadi fitur (X) dan target (y)\n",
    "    X = df_aspect['text']\n",
    "    y = df_aspect['sentiment']\n",
    "    \n",
    "    for clf_name, clf in classifiers.items():\n",
    "        # Membuat pipeline dengan TfidfVectorizer dan classifier\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(max_features=100000)),\n",
    "            ('clf', clf)\n",
    "        ])\n",
    "        \n",
    "        # Menggunakan cross-validation untuk menghasilkan prediksi\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        y_pred = cross_val_predict(pipeline, X, y, cv=skf)\n",
    "\n",
    "        # Evaluasi model\n",
    "        print(f'\\nClassification Report with {clf_name}:')\n",
    "        print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pemodelan Topik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_teks = [i.split() for i in teks]\n",
    "# print(token_teks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Phrases\n",
    "\n",
    "bigram = Phrases(token_teks, min_count=10)\n",
    "trigram = Phrases(bigram[token_teks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range (len(token_teks)):\n",
    "    for token in bigram[token_teks[idx]]:\n",
    "        if '_' in token:\n",
    "            token_teks[idx].append(token)\n",
    "    for token in trigram[token_teks[idx]]:\n",
    "        if '_' in token:\n",
    "            token_teks[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<4256 unique tokens: ['antri', 'bangga', 'bangsa', 'bangsa_indonesia', 'batas']...>\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "term_dictionary = corpora.Dictionary(token_teks)\n",
    "term_dictionary.filter_extremes(no_below=5, no_above=0.2)\n",
    "print(term_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6743\n",
      "[(1, 1), (7, 3), (9, 2), (13, 1), (26, 1), (28, 1), (33, 3), (35, 1), (62, 1), (73, 1), (83, 1), (97, 2), (98, 1), (140, 1), (161, 1), (166, 1), (168, 1), (183, 3), (185, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 1), (200, 3), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (206, 1), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (212, 1), (213, 1), (214, 1)]\n"
     ]
    }
   ],
   "source": [
    "# build corpus\n",
    "# Converting List of documents (corpus) into Document Term matrix using dictionary prepared avobe.\n",
    "doc_term_matrix = [term_dictionary.doc2bow(doc) for doc in token_teks]\n",
    "# The function doc2bow convert document (a list of words) into the bag-of-words format\n",
    "print(len(doc_term_matrix))\n",
    "print(doc_term_matrix[10])\n",
    "\n",
    "tfidf = models.TfidfModel(doc_term_matrix)\n",
    "corpus_tfidf = tfidf[doc_term_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from numpy import array\n",
    "# function to compute coherence values\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start, step):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, iterations=100)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 2\n",
    "limit = 7\n",
    "step = 1\n",
    "\n",
    "model_list, coherence_values = compute_coherence_values(term_dictionary, corpus=corpus_tfidf, texts=token_teks, start=start, limit=limit, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show graps\n",
    "import matplotlib.pyplot as plt\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.title(\"Daya Tarik Positif\")\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel('Coherence Score')\n",
    "plt.legend(('coherence_values'), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num TOpics = 2 has Coherence Value of 0.453\n",
      "Num TOpics = 3 has Coherence Value of 0.53\n",
      "Num TOpics = 4 has Coherence Value of 0.537\n",
      "Num TOpics = 5 has Coherence Value of 0.458\n",
      "Num TOpics = 6 has Coherence Value of 0.492\n"
     ]
    }
   ],
   "source": [
    "# print the coherence score\n",
    "for m, cv, in zip(x, coherence_values):\n",
    "    print('Num TOpics =', m, 'has Coherence Value of', round(cv, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.013*\"one_best\" + 0.010*\"nice_view\" + 0.007*\"tiket_masuk\" + 0.006*\"yg\" + 0.006*\"candi_prambanan\" + 0.006*\"ratu_boko\" + 0.006*\"wonderfull\" + 0.005*\"dont_miss\" + 0.005*\"harga_tiket\" + 0.005*\"sejarah\"\n",
      "Topic: 1 Word: 0.024*\"great_place\" + 0.023*\"historical_place\" + 0.012*\"place\" + 0.008*\"learn_history\" + 0.008*\"historical\" + 0.007*\"amazing\" + 0.007*\"great\" + 0.006*\"tour_guide\" + 0.006*\"roro_jonggrang\" + 0.006*\"year_ago\"\n",
      "Topic: 2 Word: 0.014*\"candi_prambanan\" + 0.007*\"its_really\" + 0.007*\"very_nice\" + 0.006*\"beautifull\" + 0.006*\"prambanan\" + 0.006*\"yg\" + 0.006*\"this_place\" + 0.004*\"local_guide\" + 0.004*\"one_wonder\" + 0.004*\"sejarah\"\n",
      "Topic: 3 Word: 0.009*\"world_heritage\" + 0.009*\"i_love\" + 0.008*\"historical_site\" + 0.007*\"place\" + 0.005*\"love\" + 0.005*\"spot_foto\" + 0.005*\"view\" + 0.005*\"entry_ticket\" + 0.005*\"the_biggest\" + 0.005*\"clean_well\"\n",
      "Topic: 4 Word: 0.013*\"place\" + 0.013*\"hindu_temple\" + 0.011*\"must_visit\" + 0.010*\"nice_place\" + 0.009*\"beautiful\" + 0.007*\"visit\" + 0.007*\"the\" + 0.007*\"one\" + 0.007*\"nice\" + 0.006*\"great\"\n",
      "Topic: 5 Word: 0.009*\"largest_hindu\" + 0.007*\"good\" + 0.007*\"unesco_world\" + 0.006*\"unesco_heritage\" + 0.006*\"heritage_site\" + 0.006*\"ajaib_dunia\" + 0.006*\"story_behind\" + 0.005*\"exit_gate\" + 0.005*\"walk_around\" + 0.005*\"entrance_ticket\"\n"
     ]
    }
   ],
   "source": [
    "model = LdaModel(corpus=corpus_tfidf, id2word=term_dictionary, num_topics=6)\n",
    "for idx, topic in model.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.013*\"one_best\" + 0.010*\"nice_view\" + 0.007*\"tiket_masuk\" + 0.006*\"yg\" + 0.006*\"candi_prambanan\" + 0.006*\"ratu_boko\" + 0.006*\"wonderfull\" + 0.005*\"dont_miss\" + 0.005*\"harga_tiket\" + 0.005*\"sejarah\"'),\n",
       " (1,\n",
       "  '0.024*\"great_place\" + 0.023*\"historical_place\" + 0.012*\"place\" + 0.008*\"learn_history\" + 0.008*\"historical\" + 0.007*\"amazing\" + 0.007*\"great\" + 0.006*\"tour_guide\" + 0.006*\"roro_jonggrang\" + 0.006*\"year_ago\"'),\n",
       " (2,\n",
       "  '0.014*\"candi_prambanan\" + 0.007*\"its_really\" + 0.007*\"very_nice\" + 0.006*\"beautifull\" + 0.006*\"prambanan\" + 0.006*\"yg\" + 0.006*\"this_place\" + 0.004*\"local_guide\" + 0.004*\"one_wonder\" + 0.004*\"sejarah\"'),\n",
       " (3,\n",
       "  '0.009*\"world_heritage\" + 0.009*\"i_love\" + 0.008*\"historical_site\" + 0.007*\"place\" + 0.005*\"love\" + 0.005*\"spot_foto\" + 0.005*\"view\" + 0.005*\"entry_ticket\" + 0.005*\"the_biggest\" + 0.005*\"clean_well\"'),\n",
       " (4,\n",
       "  '0.013*\"place\" + 0.013*\"hindu_temple\" + 0.011*\"must_visit\" + 0.010*\"nice_place\" + 0.009*\"beautiful\" + 0.007*\"visit\" + 0.007*\"the\" + 0.007*\"one\" + 0.007*\"nice\" + 0.006*\"great\"'),\n",
       " (5,\n",
       "  '0.009*\"largest_hindu\" + 0.007*\"good\" + 0.007*\"unesco_world\" + 0.006*\"unesco_heritage\" + 0.006*\"heritage_site\" + 0.006*\"ajaib_dunia\" + 0.006*\"story_behind\" + 0.005*\"exit_gate\" + 0.005*\"walk_around\" + 0.005*\"entrance_ticket\"')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "import pyLDAvis.gensim_models; pyLDAvis.enable_notebook()\n",
    "data = pyLDAvis.gensim_models.prepare(model, corpus_tfidf, term_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el144425249911520643580330688\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el144425249911520643580330688_data = {\"mdsDat\": {\"x\": [-0.1826600922685414, 0.12792305876037338, 0.1100882910594174, -0.013622423373605065, -0.03160284386262685, -0.010125990315017546], \"y\": [-0.01644450375518265, 0.015040632729054286, -0.020043629906791302, -0.05962338462811538, 0.12629975498484716, -0.045228869423812004], \"topics\": [1, 2, 3, 4, 5, 6], \"cluster\": [1, 1, 1, 1, 1, 1], \"Freq\": [30.351665311796676, 20.54196331937524, 18.352408192325854, 10.61866902699394, 10.157941833401352, 9.977352316106945]}, \"tinfo\": {\"Term\": [\"great_place\", \"historical_place\", \"one_best\", \"nice_view\", \"hindu_temple\", \"nice_place\", \"its_really\", \"largest_hindu\", \"world_heritage\", \"must_visit\", \"i_love\", \"place\", \"candi_prambanan\", \"learn_history\", \"very_nice\", \"beautifull\", \"historical_site\", \"historical\", \"great\", \"wonderfull\", \"dont_miss\", \"unesco_world\", \"amazing\", \"tiket_masuk\", \"tample\", \"unesco_heritage\", \"year_ago\", \"story_behind\", \"roro_jonggrang\", \"spot_foto\", \"tample\", \"love_place\", \"hindus\", \"cultural_heritage\", \"little_bit\", \"holiday_season\", \"nice_place\", \"bring_umbrella\", \"hindu_temple\", \"hindus_temple\", \"tourist_attraction\", \"ancient_hindu\", \"ramayana_ballet\", \"temple_compound\", \"dance\", \"if_youre\", \"a_must\", \"well_preserved\", \"of\", \"massive\", \"im_sure\", \"buy_ticket\", \"expensive_foreigner\", \"historic\", \"held\", \"historic_place\", \"parking_lot\", \"no\", \"worth_visiting\", \"earth\", \"besides\", \"must_visit\", \"must_see\", \"temple_complex\", \"must\", \"make_sure\", \"a\", \"beautiful\", \"nice\", \"history\", \"big\", \"complex\", \"ballet\", \"place\", \"visit\", \"ancient\", \"the\", \"one\", \"its\", \"great\", \"time\", \"central_java\", \"hindu\", \"good\", \"also\", \"i\", \"see\", \"amazing\", \"love\", \"it\", \"nice_view\", \"dont_miss\", \"whole_complex\", \"really_hot\", \"southeast_asia\", \"wonderfull\", \"tiket_terus\", \"bring_hat\", \"rekreasi\", \"bored\", \"waris_dunia\", \"tempat_luas\", \"one_best\", \"exotic\", \"fav\", \"memory\", \"bright\", \"beatifull\", \"rb\", \"destroyed_earthquake\", \"exciting\", \"spending\", \"roro_jongrang\", \"pandang_indah\", \"sand\", \"kunjung_wisatawan\", \"bangsa_indonesia\", \"feed\", \"kenal_sejarah\", \"edukasi\", \"entry_fee\", \"a_lot\", \"cocok_libur\", \"komplek_candi\", \"ratu_boko\", \"harga_tiket\", \"tinggal_sejarah\", \"tiket_masuk\", \"tiket\", \"waris_budaya\", \"wajib_kunjung\", \"yg\", \"harga\", \"indah\", \"sejarah\", \"tempat\", \"bagus\", \"candi_prambanan\", \"candi_sewu\", \"tempat_bagus\", \"masuk\", \"prambanan\", \"indonesia\", \"its_really\", \"beautifull\", \"very_nice\", \"raka_pikat\", \"sacred\", \"many_thing\", \"one_wonder\", \"very_good\", \"marathon\", \"much_better\", \"kenang\", \"local_guide\", \"awat_bersih\", \"dewa\", \"vacation\", \"well_organized\", \"dynasty\", \"jgn_lupa\", \"pikat\", \"raka\", \"hospitality\", \"treasure\", \"dewa_siwa\", \"pulau_jawa\", \"prasasti_siwagrha\", \"banyak_spot\", \"kamar_mandi\", \"serve\", \"rara_jonggrang\", \"libur_keluarga\", \"lumayan_mahal\", \"decorated\", \"agama_hindu\", \"bagus_banget\", \"lupa_bawa\", \"bangun_abad\", \"tempat_sejarah\", \"kompleks_candi\", \"wisata_sejarah\", \"arca\", \"candi_prambanan\", \"toilet\", \"siwa\", \"this_place\", \"parkir_luas\", \"yg\", \"siang_panas\", \"tempat_wisata\", \"prambanan\", \"wisata\", \"hindu_besar\", \"very\", \"bagus\", \"sejarah\", \"tiket_masuk\", \"tempat\", \"central_java\", \"candi_sewu\", \"borobudur\", \"largest_hindu\", \"jogja\", \"place\", \"romantic\", \"the_biggest\", \"clean_well\", \"wonderful_place\", \"best_place\", \"great_view\", \"wan_na\", \"well_managed\", \"historical_site\", \"world_heritage\", \"thank\", \"proud\", \"na\", \"wan\", \"i_love\", \"historical_value\", \"hindhu\", \"yogyakarta_city\", \"managed\", \"recreation\", \"rent_bike\", \"watch_ramayana\", \"entry_ticket\", \"rich_history\", \"cafe\", \"creation\", \"island\", \"value\", \"shoot\", \"drone\", \"bike\", \"wonder_world\", \"spot_foto\", \"brahma_vishnu\", \"pertama_kali\", \"early_morning\", \"take_picture\", \"traditional\", \"i_think\", \"view_top\", \"memorable\", \"salah_ajaib\", \"view\", \"love\", \"world\", \"wonderful\", \"performance\", \"place\", \"heritage\", \"historical\", \"i\", \"amazing\", \"good\", \"great\", \"beautiful\", \"good_place\", \"site\", \"visit\", \"learn_history\", \"great_place\", \"jazz\", \"historical_place\", \"prambanan_jazz\", \"easy_access\", \"rame_banget\", \"parking_area\", \"mustsee\", \"mesmerizing\", \"knowing\", \"annual\", \"favourite\", \"concert\", \"i_loved\", \"ever_seen\", \"such_amazing\", \"bandung_bondowoso\", \"beside\", \"i_cant\", \"year_ago\", \"thousand_year\", \"more\", \"manca_negara\", \"language\", \"cleanliness\", \"fully\", \"main_road\", \"mineral_water\", \"bandung\", \"such\", \"roro_jonggrang\", \"amaze\", \"nenek_moyang\", \"lovely\", \"i_visited\", \"event\", \"tour_guide\", \"historical\", \"tempat_bersih\", \"festival\", \"bawa_payung\", \"place\", \"amazing\", \"great\", \"the_best\", \"must_go\", \"i_recommend\", \"learn\", \"dont_forget\", \"ago\", \"visit\", \"i\", \"prambanan\", \"must_visit\", \"best\", \"beautiful\", \"the\", \"tempat_bagus\", \"one\", \"exit_gate\", \"entrance_ticket\", \"iconic\", \"unesco_heritage\", \"rorojongrang\", \"hat_umbrella\", \"marvelous\", \"liked\", \"affordable\", \"story_behind\", \"airport\", \"raining\", \"object\", \"ill\", \"tiket_mahal\", \"trash\", \"relax\", \"keren_banget\", \"landmark\", \"lighting\", \"rain\", \"named\", \"failed\", \"motorbike\", \"one_seven\", \"panas_sengat\", \"station\", \"relic\", \"unesco_world\", \"rest\", \"heritage_site\", \"largest_hindu\", \"there_many\", \"location\", \"walk_around\", \"ajaib_dunia\", \"favorite\", \"highly_recommend\", \"sunrise_tour\", \"prepare\", \"destination\", \"describe\", \"i_hope\", \"unesco\", \"good\", \"heritage\", \"ticket\", \"go\", \"smaller_temple\", \"i_recommend\", \"very_beautiful\", \"amazing\", \"prambanan\", \"tempat_wisata\", \"ticket_price\", \"place\", \"the\", \"i\", \"jogja\", \"yg\"], \"Freq\": [63.0, 64.0, 70.0, 49.0, 99.0, 79.0, 33.0, 32.0, 29.0, 93.0, 30.0, 171.0, 118.0, 22.0, 29.0, 28.0, 23.0, 49.0, 80.0, 30.0, 25.0, 22.0, 82.0, 53.0, 34.0, 16.0, 19.0, 17.0, 21.0, 22.0, 33.34665178633277, 19.765051922013807, 17.965740842527243, 23.846960044655276, 18.55746533971213, 12.121520002453316, 73.93803278220831, 28.087479576451962, 91.9956551940858, 11.242500039886686, 9.232715570176591, 18.263001351588304, 38.8141436074254, 12.973163229125579, 9.380870127846665, 8.628312606935435, 29.441897923014952, 13.74141620259844, 8.695920069290448, 8.627694455400187, 8.468541209714072, 9.463448898166462, 6.846907571303213, 21.69838232447556, 7.281095852949749, 5.633487554863356, 10.180264710761904, 9.686306517707255, 8.343867930938469, 5.452607427438363, 8.140012747481205, 77.2163489966952, 29.555990550409465, 39.03316088635833, 41.0242600512252, 24.754157202717476, 31.66173520248015, 67.08270681798064, 47.89650759575109, 37.69606095811618, 20.884021521262497, 23.621900313266696, 18.262687612125973, 92.84503101718433, 52.54620104665687, 24.156688729538395, 50.53777328813525, 48.14925610660739, 34.2103612631375, 45.21900414752286, 30.557043292601136, 27.58744331727296, 34.42458935157512, 42.01198310599014, 27.28157617161003, 33.545477811003266, 29.664093297906874, 34.73292910337904, 29.25028621008915, 25.576961837189792, 48.17706142389315, 24.62700027428658, 15.930411878619498, 15.531876775571922, 15.581318340955875, 28.627864634638133, 9.81439520483639, 15.133047842067983, 9.548239904582099, 8.054657801093533, 11.050615687919981, 14.872944760549636, 63.810581729637484, 7.167533151224008, 6.382205833406394, 8.097386029214723, 7.608841245626361, 5.9950469044535115, 7.273692603000167, 7.368354790395904, 5.504947459329432, 6.501187082167048, 14.055785044775885, 9.073017921861835, 4.378551848187607, 10.819041707274128, 12.50758089244714, 6.529532539004315, 5.862087475174043, 10.72198353910629, 14.156404759451902, 11.073603330029503, 9.652261625010695, 14.124296895442926, 30.736658273349956, 23.4147797710567, 22.915001711388555, 32.82796899990819, 22.950628654222566, 13.438107514492094, 17.46896553689707, 31.431094419257697, 14.321034750381465, 20.017114904361744, 23.334956595594907, 22.402363978153648, 20.774171370731406, 30.900376930754707, 17.000645700463288, 14.170647502158966, 15.532762858041892, 18.275809048991952, 15.78056178920004, 32.40849457660472, 27.23826577246739, 28.846990087750235, 12.333219475787915, 10.577570895104834, 8.489190330105709, 16.382640089831867, 6.899269408559907, 6.96201728814002, 7.205209351109866, 5.980460036548564, 18.68942898964298, 6.212952715199691, 6.163125311220103, 12.395698178793017, 5.825795791002873, 4.6877982411879415, 5.102973626898322, 4.317618411756382, 4.290200854901701, 4.540060293455245, 5.346873239722483, 4.1687273628480686, 4.430371608214233, 4.045970026710955, 7.189177707019502, 4.402191128038377, 4.534164044669293, 9.565569516521004, 8.67922591575969, 6.893880749886832, 6.541829065527007, 6.738702248903549, 11.242659554683762, 7.635466828497429, 6.052505531388196, 9.236599851647684, 14.074246384916407, 13.367073890524345, 7.1753979172480875, 63.46258696773517, 14.795237635593598, 11.223317807796693, 24.580343464955202, 11.143862010026334, 24.950104917081603, 9.176696014851544, 14.034340573133077, 24.960625875784885, 15.151152644701437, 9.890493842009873, 14.554649151000714, 15.12570135863755, 15.509478450486801, 15.502270670883938, 14.329544728437028, 12.030577843537092, 10.972662632015687, 11.55153275282541, 10.43748320199259, 10.640431059770522, 10.582780102727902, 9.858906898112908, 12.490415818507355, 11.753546472682128, 9.759190899391971, 6.920103179832295, 11.265840747665719, 7.053824407158017, 9.121826925631808, 19.330449423438203, 24.104456247258803, 5.3905157920767275, 7.40529147132513, 4.442181733614048, 3.5843767917891065, 23.716053574054914, 3.016523767668661, 5.068289047575484, 3.0312507241158406, 6.315990925231963, 2.8336746145037424, 3.344440991765614, 6.732323879633642, 12.621528835187394, 3.0821437606627042, 3.0663126458871317, 3.350118121784543, 2.816955307886362, 3.73767354184875, 3.2755728984122015, 2.4908554061751516, 4.264697033714129, 8.399443947214445, 13.45889023513041, 7.21331625081568, 4.694294127605088, 9.543810014241592, 10.460866014307149, 5.387103640251587, 9.39733905111854, 4.920570937323854, 5.7407256227683625, 9.692226455687482, 13.447401292695698, 13.91409775043194, 11.626659042039064, 10.474848064369967, 7.2337962815408074, 18.920666068062385, 10.926285659188634, 9.917114612763797, 10.98593394150279, 11.496080008430251, 11.375454419269111, 10.740403778836408, 11.173628991039093, 8.72318305043631, 8.549571507746357, 8.481886186895712, 20.295538990385094, 58.115644131671985, 11.740155041686435, 55.98760499056086, 7.053499388280212, 4.590076543621088, 3.9358969825928436, 8.670805298741001, 5.323495903636901, 3.671115490426102, 4.433700082017817, 3.38346341893879, 3.646753616862631, 3.0997196451323963, 3.319224252184426, 3.2507776775432413, 4.299539222168492, 4.986412890873587, 4.18079842992649, 4.0000598109739745, 14.225335174074331, 5.29296906791686, 2.4949389575876797, 2.440372628943547, 2.439679056511644, 2.4664003250009907, 2.6947703996359342, 2.304701177418682, 2.577075357971495, 3.621441344741696, 10.878447484630543, 15.026732578418288, 5.482499370151024, 8.670331944069801, 10.129901207712054, 7.849014481098603, 5.9674739336577645, 15.06923801166313, 18.44260518411673, 7.179961707649727, 5.348383348454006, 6.231054160642736, 28.7729420137901, 17.73966101081007, 17.37386909399561, 5.867168149087135, 6.248753311801865, 7.761569300238682, 7.817550017180933, 8.1506231369562, 5.607216974581366, 10.659286542150952, 9.81175465208295, 9.731109545942035, 9.395005026527821, 7.648661724583325, 9.005262725522334, 7.947338873394459, 6.514641284701826, 6.751566649068591, 12.926469760286434, 11.353528833580562, 6.5516787103283445, 14.068018377874845, 4.087611101430659, 6.271597382969464, 3.834531653295296, 3.4716387280147147, 4.451676409612357, 13.479560208877912, 5.524823481309274, 3.9564157127396045, 4.2904182913323154, 3.2524457728153484, 3.5235597368095504, 3.5471088564048845, 2.7662519496961706, 6.7706049107877275, 3.1896357630618497, 2.4638816889273936, 4.70382765159919, 2.4690127456187305, 2.2318518935603753, 2.8481654454525365, 4.031880823799241, 2.484638942821922, 2.9615936305059063, 4.694176537579152, 15.817557074742421, 3.2402369351860267, 13.786608572887166, 21.067503315417458, 8.740170833426008, 7.3767330029581295, 12.009442224182424, 13.686299870954784, 4.15898820306857, 8.08034448248989, 6.29868316310911, 5.949081703890551, 8.521027772791381, 5.13956218155203, 5.47729040680578, 7.279224528944108, 16.48629141729858, 9.485011390387637, 7.954277920565491, 8.758978018186866, 5.89844345926855, 6.573838029366149, 6.0668306467542426, 9.425428917869525, 9.74279514337848, 7.1988218071592245, 6.532430000480617, 8.594150905454637, 7.488573202897932, 6.9640664863506645, 6.659951030778299, 6.505593414424091], \"Total\": [63.0, 64.0, 70.0, 49.0, 99.0, 79.0, 33.0, 32.0, 29.0, 93.0, 30.0, 171.0, 118.0, 22.0, 29.0, 28.0, 23.0, 49.0, 80.0, 30.0, 25.0, 22.0, 82.0, 53.0, 34.0, 16.0, 19.0, 17.0, 21.0, 22.0, 34.18688447805735, 20.71235317104253, 19.077265870597437, 25.45487395459644, 19.819702884139474, 12.956231628802174, 79.29837078008353, 30.12425216463098, 99.73972299644682, 12.203646920212176, 10.066982157902476, 19.93707954118049, 43.10982444006818, 14.441299557319251, 10.453173444251629, 9.622397090091914, 32.92629591468094, 15.45749679841469, 9.799751663722875, 9.74465703148793, 9.58591929947774, 10.729501974535705, 7.799823278526126, 24.84921684591118, 8.367400087941386, 6.484526539664748, 11.77591229678256, 11.205569341645607, 9.70959197200923, 6.369399144721791, 9.52135035182796, 93.30551117163833, 36.64441645142525, 50.48542043508501, 55.859748906843585, 32.22502097469728, 43.206266696391296, 104.24589644593742, 71.57529988136086, 54.35348191752576, 27.30193179319897, 32.11208146524979, 23.603638365952925, 171.5500026407672, 86.90640116466112, 33.374419332521484, 85.29638859817473, 82.20653296701771, 54.42373065436038, 80.50199973619668, 47.11761518129094, 41.025813080901706, 58.563348171687075, 88.76202089545848, 41.526087443540106, 69.03029986121207, 52.918229023364674, 82.70904108371539, 60.31997145251561, 42.498849011011856, 49.302322927341756, 25.344201112549197, 16.656465559705097, 16.248919373599808, 16.311715166568522, 30.039810675528482, 10.521191783353778, 16.36056519244414, 10.412085544981093, 8.815350563227765, 12.124522713977765, 16.34980391844719, 70.4150170786398, 7.922246201356201, 7.0903083948730306, 9.030389721163553, 8.490224158504443, 6.753457170666928, 8.260670677896572, 8.380305528952357, 6.2797430869078505, 7.448324517257854, 16.192361060065494, 10.521529428903529, 5.095262853244754, 12.749317388448281, 14.809096168400375, 7.735558640060901, 6.94651938085944, 12.72421136931329, 16.942289525295244, 13.282096311869056, 11.600764740998091, 17.4035642515516, 41.14099621351214, 33.56064499311916, 33.69647688566518, 53.29383832965313, 35.48636583128309, 18.043488776394277, 26.23148977486608, 77.52377131775762, 22.6600606457638, 39.71030355692648, 51.6969435784526, 50.957505067667704, 48.585296398782916, 118.7829523881598, 33.61576579222616, 24.596983052403623, 32.977781239792826, 94.04449852220435, 64.80568140217194, 33.18228779417582, 28.001179312981865, 29.69904792381973, 13.08523335578885, 11.427501884256735, 9.358878935122089, 18.066218616831655, 7.67251783362859, 7.83877733304002, 8.117156696085692, 6.773239818129589, 21.18828222609571, 7.070007846217611, 7.031244835820539, 14.22337145735515, 6.7463816738324045, 5.479831703939876, 5.977580205212306, 5.068607888974394, 5.044605281073769, 5.341810375259551, 6.297864284334912, 4.9158067485514225, 5.248096199280498, 4.795222912675309, 8.552781463598583, 5.2764921047803, 5.439879681759328, 11.57668106991412, 10.507476929653933, 8.37010916766368, 7.945615284657666, 8.198288606516183, 14.458244601617261, 9.534629749885886, 7.389309756479725, 11.891785896225203, 19.284369534172402, 18.455296646103008, 8.9881694405301, 118.7829523881598, 21.337044907412622, 15.846483684020896, 51.97092170555547, 17.184026962047284, 77.52377131775762, 14.205978859260595, 30.54721210299174, 94.04449852220435, 39.50243060285269, 17.07009571503898, 39.958390433687065, 48.585296398782916, 51.6969435784526, 53.29383832965313, 50.957505067667704, 41.025813080901706, 33.61576579222616, 49.72002784079042, 32.15687816880384, 43.41998222251776, 171.5500026407672, 10.737812321060424, 13.813734301477158, 13.150794958693849, 11.022061908219312, 7.884697604164045, 13.00600947874873, 8.145929947128801, 10.993611962876216, 23.41414352001153, 29.26616910425551, 6.563040628572544, 9.019011523821426, 5.423208051987858, 4.552302759438242, 30.192028897231314, 3.8673130084083476, 6.575384784036619, 3.9579820284423133, 8.28639914981048, 3.7188290459105073, 4.3909432583209025, 8.867000892970701, 16.744874322805806, 4.118556199827, 4.101834945843871, 4.538603138346293, 3.821812673123688, 5.086961471749698, 4.4752039925237, 3.4272541119835127, 5.928464609737762, 12.0585209933022, 22.451847719490647, 11.185251315037402, 6.763206098668576, 16.79466671891655, 19.576316654420093, 8.50285881063039, 18.097090899790835, 7.718869542341281, 9.748980214595116, 27.43641707099388, 53.03788318854722, 60.31997145251561, 45.966695711825466, 37.215762109007464, 16.999045530625484, 171.5500026407672, 45.92578962470948, 49.067412584154226, 69.03029986121207, 82.70904108371539, 88.76202089545848, 80.50199973619668, 104.24589644593742, 33.019305484505104, 33.750988608368665, 86.90640116466112, 22.000913086684577, 63.851270061439074, 12.936821489785926, 64.71671431540928, 8.241900589105077, 5.461321504748739, 4.793108997606592, 10.55968232175372, 6.56633241261561, 4.557237043090109, 5.524925482734496, 4.263676374744317, 4.612468188974104, 3.971996303805355, 4.261484098417275, 4.204193999174674, 5.671707271834628, 6.647807175815632, 5.590839979174767, 5.384174313634275, 19.15577554764422, 7.13991557013928, 3.36711566456075, 3.299195430883485, 3.3126842501283136, 3.3740825199777875, 3.7064643628980147, 3.172070210711766, 3.5685356619451025, 5.020931548357996, 15.210137640808217, 21.883752184177734, 7.801633617049139, 13.65058895197702, 16.752213662519168, 12.79857575281995, 9.875540207373444, 33.29871878907965, 49.067412584154226, 13.029862988102016, 8.72071464721431, 11.90538668618211, 171.5500026407672, 82.70904108371539, 80.50199973619668, 10.849156813159611, 12.721874536560609, 20.31230733456111, 22.263449409740556, 32.38515210841118, 10.12446639433169, 86.90640116466112, 69.03029986121207, 94.04449852220435, 93.30551117163833, 43.48853060452808, 104.24589644593742, 85.29638859817473, 24.596983052403623, 82.20653296701771, 13.768494453337995, 13.358854228204724, 7.7242539152404275, 16.980808378728995, 4.9902439777541705, 7.657400851813871, 4.708818422540951, 4.311083717700245, 5.597884132712663, 17.043059692502602, 6.992185552132956, 5.011036448458675, 5.463033152165781, 4.213289156666956, 4.594034880427032, 4.642551973833875, 3.6752748179532153, 9.00120841660203, 4.296307914478905, 3.3416811613857775, 6.3923841127204, 3.3587877438423583, 3.0742125360073365, 3.9367993628953957, 5.602006251675979, 3.4564798918539257, 4.1306056175117405, 6.682022932236457, 22.64903717222035, 4.674473413351411, 20.102924613264474, 32.15687816880384, 13.985938931447697, 11.718910693984135, 21.22555706235439, 25.422151028273127, 6.17536890977771, 13.7241423257356, 10.770653636471437, 10.165927649124104, 18.148584006944002, 8.714481706136304, 10.08552180469206, 17.473047150232627, 88.76202089545848, 45.92578962470948, 29.850446194305633, 44.208344584901916, 14.328362018711935, 20.31230733456111, 15.784558159595443, 82.70904108371539, 94.04449852220435, 30.54721210299174, 21.3923430990568, 171.5500026407672, 85.29638859817473, 69.03029986121207, 43.41998222251776, 77.52377131775762], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.3864, -5.9095, -6.0049, -5.7217, -5.9725, -6.3984, -4.5902, -5.5581, -4.3717, -6.4737, -6.6707, -5.9885, -5.2346, -6.3305, -6.6547, -6.7384, -5.511, -6.273, -6.7306, -6.7384, -6.757, -6.646, -6.9696, -5.8162, -6.9081, -7.1647, -6.573, -6.6227, -6.7719, -7.1973, -6.7966, -4.5468, -5.5071, -5.229, -5.1792, -5.6844, -5.4383, -4.6875, -5.0244, -5.2639, -5.8544, -5.7312, -5.9885, -4.3625, -4.9317, -5.7088, -4.9707, -5.0191, -5.3609, -5.0819, -5.4738, -5.576, -5.3546, -5.1555, -5.5872, -5.3805, -5.5035, -5.3457, -5.5175, -5.6517, -4.6281, -5.2992, -5.7348, -5.7601, -5.757, -5.1486, -6.2192, -5.7861, -6.2467, -6.4168, -6.1005, -5.8035, -4.3471, -6.5335, -6.6495, -6.4115, -6.4737, -6.7121, -6.5188, -6.5058, -6.7974, -6.631, -5.86, -6.2977, -7.0263, -6.1217, -5.9767, -6.6267, -6.7345, -6.1307, -5.8529, -6.0985, -6.2358, -5.8551, -5.0776, -5.3497, -5.3712, -5.0117, -5.3697, -5.9049, -5.6426, -5.0552, -5.8413, -5.5064, -5.3531, -5.3939, -5.4693, -5.0723, -5.6698, -5.8519, -5.7601, -5.5974, -5.7442, -4.9119, -5.0857, -5.0283, -5.878, -6.0316, -6.2515, -5.5941, -6.4589, -6.4498, -6.4155, -6.6018, -5.4624, -6.5637, -6.5717, -5.873, -6.628, -6.8454, -6.7605, -6.9276, -6.934, -6.8774, -6.7138, -6.9627, -6.9018, -6.9926, -6.4177, -6.9082, -6.8787, -6.1321, -6.2294, -6.4597, -6.5121, -6.4824, -5.9706, -6.3575, -6.5898, -6.1671, -5.746, -5.7975, -6.4197, -4.2399, -5.696, -5.9723, -5.1884, -5.9794, -5.1734, -6.1736, -5.7488, -5.173, -5.6722, -6.0987, -5.7124, -5.6739, -5.6489, -5.6493, -5.728, -5.9029, -5.9949, -5.9435, -6.0449, -6.0257, -6.0311, -5.5548, -5.3182, -5.379, -5.565, -5.9087, -5.4214, -5.8896, -5.6325, -4.8815, -4.6608, -6.1585, -5.841, -6.352, -6.5666, -4.677, -6.7391, -6.2202, -6.7342, -6.0001, -6.8016, -6.6359, -5.9362, -5.3078, -6.7175, -6.7227, -6.6342, -6.8075, -6.5247, -6.6567, -6.9305, -6.3928, -5.715, -5.2435, -5.8672, -6.2968, -5.5873, -5.4955, -6.1592, -5.6027, -6.2497, -6.0956, -5.5718, -5.2444, -5.2103, -5.3899, -5.4942, -5.8644, -4.9029, -5.452, -5.5489, -5.4466, -5.4012, -5.4117, -5.4692, -5.4296, -5.6772, -5.6973, -5.7052, -4.7884, -3.7364, -5.3358, -3.7737, -5.8453, -6.2749, -6.4287, -5.6388, -6.1267, -6.4983, -6.3096, -6.5799, -6.505, -6.6675, -6.5991, -6.6199, -6.3403, -6.1921, -6.3683, -6.4125, -5.1438, -6.1324, -6.8845, -6.9067, -6.9069, -6.8961, -6.8075, -6.9639, -6.8522, -6.5119, -5.412, -5.089, -6.0972, -5.6389, -5.4833, -5.7384, -6.0125, -5.0862, -4.8841, -5.8275, -6.122, -5.9693, -4.4394, -4.923, -4.9438, -6.0294, -5.9664, -5.7496, -5.7424, -5.7007, -6.0748, -5.4324, -5.5152, -5.5235, -5.5586, -5.7643, -5.601, -5.726, -5.9248, -5.889, -5.2216, -5.3513, -5.9012, -5.137, -6.3729, -5.9448, -6.4368, -6.5362, -6.2876, -5.1797, -6.0716, -6.4055, -6.3245, -6.6015, -6.5214, -6.5147, -6.7634, -5.8683, -6.621, -6.8791, -6.2325, -6.8771, -6.978, -6.7342, -6.3866, -6.8707, -6.6951, -6.2345, -5.0198, -6.6052, -5.1572, -4.7331, -5.6129, -5.7825, -5.2952, -5.1645, -6.3556, -5.6914, -5.9405, -5.9976, -5.6383, -6.1439, -6.0803, -5.7958, -4.9783, -5.5312, -5.7072, -5.6108, -6.0062, -5.8978, -5.978, -5.5375, -5.5043, -5.807, -5.9041, -5.6298, -5.7675, -5.8401, -5.8848, -5.9082], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.1674, 1.1455, 1.1323, 1.1271, 1.1265, 1.1257, 1.1223, 1.1223, 1.1115, 1.1103, 1.1058, 1.1046, 1.0874, 1.0851, 1.0841, 1.0833, 1.0805, 1.0746, 1.0728, 1.0706, 1.0684, 1.0668, 1.062, 1.0567, 1.0533, 1.0516, 1.0467, 1.0466, 1.0407, 1.0369, 1.0356, 1.0031, 0.9773, 0.935, 0.8836, 0.9286, 0.8814, 0.7515, 0.7906, 0.8264, 0.9243, 0.8853, 0.9358, 0.5784, 0.6892, 0.8691, 0.6689, 0.6574, 0.728, 0.6156, 0.7593, 0.7955, 0.661, 0.4443, 0.7722, 0.4707, 0.6135, 0.3247, 0.4685, 0.6845, 1.5596, 1.554, 1.5381, 1.5376, 1.5369, 1.5346, 1.5132, 1.5047, 1.4961, 1.4925, 1.49, 1.488, 1.4842, 1.4826, 1.4775, 1.4736, 1.4731, 1.4636, 1.4555, 1.454, 1.451, 1.4467, 1.4412, 1.4346, 1.4311, 1.4185, 1.4138, 1.4132, 1.413, 1.4115, 1.4031, 1.4008, 1.3988, 1.3739, 1.2912, 1.2227, 1.1971, 1.0982, 1.1469, 1.288, 1.1762, 0.6799, 1.1238, 0.8977, 0.7873, 0.7609, 0.7331, 0.2362, 0.901, 1.0312, 0.8298, -0.0555, 0.1701, 1.6718, 1.6678, 1.6663, 1.6362, 1.6181, 1.5979, 1.5976, 1.5892, 1.5768, 1.5762, 1.5709, 1.5699, 1.5662, 1.5636, 1.5579, 1.5487, 1.5393, 1.5372, 1.535, 1.5334, 1.5328, 1.5317, 1.5306, 1.526, 1.5255, 1.5217, 1.5143, 1.5133, 1.5046, 1.5043, 1.5014, 1.501, 1.4994, 1.4439, 1.4733, 1.4958, 1.4427, 1.3805, 1.3729, 1.4702, 1.0686, 1.3293, 1.3505, 0.9467, 1.2623, 0.5617, 1.2584, 0.9176, 0.3689, 0.7371, 1.1497, 0.6855, 0.5285, 0.4915, 0.4606, 0.4267, 0.4687, 0.5758, 0.2358, 0.5702, 0.2892, -1.0902, 2.1572, 2.1419, 2.1302, 2.1209, 2.1121, 2.0989, 2.0986, 2.0559, 2.0509, 2.0485, 2.0457, 2.0454, 2.043, 2.0035, 2.0011, 1.9941, 1.9822, 1.9758, 1.971, 1.9707, 1.9703, 1.9671, 1.9599, 1.9527, 1.9516, 1.9389, 1.9375, 1.9343, 1.9305, 1.9234, 1.9132, 1.881, 1.7308, 1.8039, 1.8774, 1.6774, 1.6159, 1.7862, 1.5872, 1.7923, 1.713, 1.202, 0.8703, 0.7758, 0.8679, 0.9748, 1.3882, 0.0379, 0.8067, 0.6436, 0.4046, 0.2692, 0.1881, 0.2283, 0.0094, 0.9114, 0.8694, -0.0843, 2.2062, 2.1928, 2.1899, 2.142, 2.1312, 2.1131, 2.0899, 2.0898, 2.0771, 2.0707, 2.0669, 2.0557, 2.052, 2.039, 2.037, 2.0297, 2.0099, 1.9993, 1.9963, 1.9898, 1.9893, 1.9876, 1.9871, 1.9854, 1.981, 1.9736, 1.9681, 1.9675, 1.9614, 1.9602, 1.9517, 1.911, 1.9341, 1.833, 1.7839, 1.798, 1.7832, 1.4941, 1.3084, 1.691, 1.798, 1.6395, 0.5015, 0.7474, 0.7536, 1.6722, 1.576, 1.3249, 1.2403, 0.9073, 1.696, 0.1885, 0.3359, 0.0185, -0.0088, 0.5489, -0.162, -0.0864, 0.9583, -0.2125, 2.2417, 2.1422, 2.1402, 2.1167, 2.1053, 2.1052, 2.0995, 2.0883, 2.0757, 2.0703, 2.0693, 2.0685, 2.0632, 2.046, 2.0396, 2.0357, 2.0207, 2.0201, 2.007, 2.0001, 1.9981, 1.9971, 1.9846, 1.9812, 1.976, 1.9747, 1.9722, 1.9518, 1.9459, 1.9384, 1.9277, 1.882, 1.8347, 1.842, 1.7353, 1.6856, 1.9096, 1.7751, 1.7684, 1.769, 1.5488, 1.7768, 1.6944, 1.4292, 0.6214, 0.7275, 0.9824, 0.686, 1.4173, 1.1767, 1.3487, 0.1329, 0.0376, 0.8595, 1.1186, -0.6889, -0.1279, 0.0111, 0.43, -0.1731]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 6, 1, 2, 5, 1, 2, 5, 6, 2, 3, 2, 3, 5, 6, 2, 6, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 6, 5, 2, 3, 3, 1, 2, 3, 4, 5, 6, 2, 3, 4, 1, 3, 6, 5, 2, 5, 1, 2, 5, 3, 5, 2, 3, 2, 4, 5, 6, 2, 1, 2, 3, 4, 5, 6, 3, 5, 6, 1, 1, 2, 3, 4, 5, 6, 4, 1, 2, 3, 4, 5, 6, 1, 4, 2, 1, 2, 3, 4, 5, 6, 2, 4, 5, 2, 2, 5, 1, 4, 1, 4, 1, 2, 3, 4, 5, 6, 2, 3, 4, 5, 1, 2, 3, 2, 4, 5, 1, 2, 1, 2, 3, 4, 5, 6, 5, 2, 4, 1, 4, 1, 1, 3, 3, 4, 6, 1, 2, 3, 4, 6, 2, 3, 3, 1, 2, 3, 5, 2, 4, 3, 2, 3, 4, 5, 6, 1, 5, 2, 3, 5, 3, 6, 2, 4, 4, 6, 3, 5, 5, 2, 6, 2, 1, 6, 2, 1, 6, 5, 1, 2, 2, 3, 5, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 3, 5, 6, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 5, 6, 2, 6, 1, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 4, 6, 2, 4, 1, 2, 3, 4, 5, 6, 2, 3, 1, 2, 3, 4, 5, 6, 1, 1, 1, 6, 1, 1, 2, 3, 4, 5, 6, 1, 4, 5, 6, 3, 4, 4, 1, 2, 3, 4, 5, 1, 3, 1, 2, 3, 4, 5, 6, 5, 5, 6, 1, 2, 3, 4, 6, 5, 2, 3, 4, 5, 6, 1, 4, 5, 6, 1, 2, 4, 5, 6, 6, 1, 6, 1, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 5, 3, 1, 2, 3, 4, 5, 6, 3, 2, 3, 1, 3, 6, 5, 2, 3, 4, 5, 6, 2, 3, 4, 6, 2, 3, 6, 5, 3, 6, 1, 3, 5, 3, 5, 3, 5, 6, 6, 1, 3, 4, 6, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 1, 1, 2, 3, 5, 1, 3, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 4, 6, 5, 3, 3, 6, 1, 1, 2, 3, 4, 5, 6, 1, 4, 6, 2, 5, 5, 5, 6, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 5, 4, 6, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 5, 6, 2, 6, 1, 4, 6, 1, 1, 2, 3, 4, 5, 6, 1, 2, 5, 2, 6, 2, 3, 4, 6, 2, 2, 4, 5, 1, 4, 1, 2, 3, 4, 2, 3, 4, 6, 2, 4, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 5, 3, 2, 5, 6, 3, 4, 3, 5, 6, 6, 3, 3, 1, 3, 6, 5, 3, 5, 1, 2, 3, 4, 5, 6, 2, 2, 4, 2, 6, 2, 6, 4, 3, 6, 4, 4, 1, 2, 3, 4, 5, 6, 2, 3, 6, 3, 1, 2, 3, 4, 5, 6, 2, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 4, 2, 3, 1, 2, 3, 4, 5, 6, 2, 3, 4, 1, 2, 3, 5, 6, 2, 2, 2, 3, 4, 2, 6, 3, 6, 1, 2, 4, 5, 1, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 6, 2, 3, 4, 5, 2, 3, 4, 5, 6, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 5, 4, 2, 3, 4, 6, 1, 2, 3, 4, 6, 5, 6, 1, 2, 3, 4, 5, 6, 1, 4, 6, 1, 2, 3, 4, 5, 6, 6, 1, 2, 3, 5, 2, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 3, 4, 6, 6, 3, 1, 2, 3, 4, 6, 2, 3, 6, 1, 2, 3, 4, 6, 3, 5, 4, 1, 3, 5, 6, 1, 5, 6, 3, 3, 1, 2, 3, 4, 5, 6, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 4, 4, 2, 4, 5, 2, 3, 4, 2, 4, 3, 1, 3, 2, 1, 2, 3, 4, 5, 6, 2, 3, 4, 5, 2, 4, 6, 1, 2, 3, 4, 5, 6, 4, 2, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 2, 5, 6, 1, 2, 3, 4, 5, 6, 4], \"Freq\": [0.7406333026841387, 0.04628958141775867, 0.023144790708879336, 0.06943437212663801, 0.09257916283551734, 0.023144790708879336, 0.07528932003801138, 0.8281825204181252, 0.07528932003801138, 0.8807550073395801, 0.030370862322054486, 0.06074172464410897, 0.7145556973258843, 0.1219766768402344, 0.8538367378816407, 0.0987706374885952, 0.0987706374885952, 0.5926238249315712, 0.1975412749771904, 0.14301679961781782, 0.8581007977069071, 0.23601464696386737, 0.0786715489879558, 0.0393357744939779, 0.0786715489879558, 0.5507008429156905, 0.6501936893696009, 0.04816249550885932, 0.04816249550885932, 0.07224374326328899, 0.07224374326328899, 0.12040623877214832, 0.1281782827912696, 0.1281782827912696, 0.640891413956348, 0.4231701823815626, 0.04836230655789287, 0.060452883197366095, 0.1329963430342054, 0.21763037951051795, 0.10881518975525897, 0.7191136349333682, 0.029963068122223675, 0.05992613624444735, 0.08988920436667103, 0.029963068122223675, 0.08988920436667103, 0.9028403564735041, 0.05015779758186134, 0.7036181305340988, 0.11125735964552783, 0.7788015175186948, 0.8486553523713477, 0.041164717481276925, 0.4322295335534077, 0.30873538110957693, 0.12349415244383077, 0.06174707622191539, 0.041164717481276925, 0.1383293791956103, 0.7608115855758567, 0.06916468959780515, 0.7625942967319862, 0.08473269963688736, 0.12709904945533104, 0.7966649139656419, 0.1504255423710162, 0.7521277118550811, 0.0675260656442895, 0.8778388533757636, 0.0675260656442895, 0.8119838249761513, 0.13533063749602522, 0.11692102788503261, 0.8184471951952283, 0.25198677532094993, 0.08399559177364997, 0.5039735506418999, 0.08399559177364997, 0.8884338566712905, 0.6427111501194354, 0.047963518665629506, 0.06714892613188131, 0.10551974106438491, 0.08633433359813311, 0.047963518665629506, 0.964245101901201, 0.7154559985439644, 0.1788639996359911, 0.8402169549893852, 0.32192396030373815, 0.2529402545243657, 0.022994568593124154, 0.18395654874499323, 0.18395654874499323, 0.022994568593124154, 0.8877956202534868, 0.7691763410393981, 0.10988233443419974, 0.036627444811399915, 0.036627444811399915, 0.036627444811399915, 0.036627444811399915, 0.16867773796902766, 0.6747109518761106, 0.9075078685323182, 0.2212388141700833, 0.2212388141700833, 0.24135143364009087, 0.10056309735003786, 0.10056309735003786, 0.10056309735003786, 0.0894034449324893, 0.6258241145274251, 0.2682103347974679, 0.9422601630590168, 0.9168387414224237, 0.06112258276149491, 0.9294836547967463, 0.03319584481416951, 0.8388087370093853, 0.7313799895921481, 0.058931015429936014, 0.26098021118971665, 0.5303791388694241, 0.058931015429936014, 0.042093582449954293, 0.050512298939945154, 0.5057150893147687, 0.32722741073308564, 0.02974794643028051, 0.11899178572112204, 0.6824971377114408, 0.024374897775408598, 0.2924987733049032, 0.07604103045792762, 0.9124923654951315, 0.5927537302831487, 0.08620121365498559, 0.8620121365498559, 0.7473822594144728, 0.0934227824268091, 0.03114092747560303, 0.03114092747560303, 0.06228185495120606, 0.03114092747560303, 0.7552877119059407, 0.2203321086946511, 0.6609963260839533, 0.9428449751041202, 0.03928520729600501, 0.8609825569238256, 0.12585557746936454, 0.8809890422855519, 0.22950303499882266, 0.11475151749941133, 0.5737575874970566, 0.16530215243526114, 0.11020143495684076, 0.11020143495684076, 0.11020143495684076, 0.4959064573057834, 0.8352917415500348, 0.8533339600739143, 0.8137016373108462, 0.6484453100513865, 0.030878348097685072, 0.030878348097685072, 0.24702678478148057, 0.9864189401346423, 0.5835575462604102, 0.9124367809334568, 0.05954271178681131, 0.05954271178681131, 0.5954271178681131, 0.05954271178681131, 0.23817084714724523, 0.78500340242351, 0.9155293266753094, 0.8644936554990329, 0.0785903323180939, 0.0785903323180939, 0.07485671921538652, 0.8234239113692517, 0.8263345977589195, 0.11804779967984563, 0.7763569764327555, 0.1791593022537128, 0.30378085016150197, 0.6075617003230039, 0.7135731606555099, 0.955453100065341, 0.9441845689125666, 0.8835877883726558, 0.8974562307420301, 0.6505731066328678, 0.8462255329173796, 0.16193364552142947, 0.6477345820857179, 0.8672146530054817, 0.12927314581020707, 0.9049120206714495, 0.11466950134865767, 0.22933900269731533, 0.5733475067432884, 0.8093966935255669, 0.4297831139890477, 0.11310081947080203, 0.022620163894160404, 0.11310081947080203, 0.11310081947080203, 0.20358147504744364, 0.4731753465760595, 0.05633039840191185, 0.09012863744305895, 0.12392687648420606, 0.05633039840191185, 0.1802572748861179, 0.393709068353981, 0.1817118777018374, 0.2725678165527561, 0.06057062590061246, 0.0908559388509187, 0.558992325003901, 0.024844103333506708, 0.024844103333506708, 0.1366425683342869, 0.211174878334807, 0.03726615500026006, 0.015661395600084043, 0.015661395600084043, 0.9083609448048746, 0.04698418680025213, 0.8457628773816854, 0.07688753430742594, 0.044130508546849176, 0.6178271196558884, 0.1323915256405475, 0.044130508546849176, 0.044130508546849176, 0.08826101709369835, 0.029796805162863437, 0.685326518745859, 0.029796805162863437, 0.029796805162863437, 0.17878083097718062, 0.13059261482479684, 0.783555688948781, 0.8365800519193526, 0.41371090525087933, 0.02177425817109891, 0.06532277451329674, 0.23951683988208802, 0.04354851634219782, 0.1959683235398902, 0.14923201761501487, 0.049744005871671625, 0.049744005871671625, 0.049744005871671625, 0.049744005871671625, 0.6964160822034028, 0.07286429827565935, 0.21859289482697805, 0.07286429827565935, 0.5829143862052748, 0.15208235454566074, 0.7604117727283037, 0.5805678988900019, 0.11952868506558863, 0.1536797379414711, 0.034151052875882465, 0.0512265793138237, 0.034151052875882465, 0.3514918779696074, 0.5858197966160124, 0.9224007971555872, 0.020052191242512767, 0.010026095621256384, 0.020052191242512767, 0.020052191242512767, 0.010026095621256384, 0.9435314327585193, 0.9013698996634648, 0.8853397729361436, 0.08048543390328579, 0.9252795810610102, 0.3464621243446197, 0.02038012496144822, 0.04076024992289644, 0.20380124961448218, 0.36684224930606796, 0.02038012496144822, 0.06180783499769836, 0.03090391749884918, 0.865309689967777, 0.046355876248273774, 0.12812768476608888, 0.8114753368518962, 0.7757323995956295, 0.6991272437276417, 0.05519425608376119, 0.07359234144501492, 0.05519425608376119, 0.11038851216752238, 0.9261952351425675, 0.9360122596558956, 0.49253733604458094, 0.05794556894642129, 0.05794556894642129, 0.15935031460265855, 0.14486392236605322, 0.10140474565623725, 0.7429179976344473, 0.3966081356483797, 0.49576016956047464, 0.09936397484950432, 0.06624264989966955, 0.033121324949834774, 0.7949117987960346, 0.033121324949834774, 0.703980099588828, 0.1476937085771414, 0.09846247238476093, 0.04923123619238046, 0.3938498895390437, 0.34461865334666325, 0.27628749989081336, 0.49731749980346407, 0.11051499995632534, 0.05525749997816267, 0.15626738776455917, 0.07813369388227959, 0.07813369388227959, 0.6250695510582367, 0.07813369388227959, 0.9062363921243669, 0.9353178751339633, 0.7120327820968348, 0.8345574117691411, 0.05036476231245403, 0.5036476231245403, 0.25182381156227013, 0.10072952462490806, 0.05036476231245403, 0.05036476231245403, 0.3549071547796296, 0.24689193375974233, 0.13887671273985505, 0.10801522101988727, 0.09258447515990337, 0.046292237579951684, 0.7849678298198759, 0.6117812742002295, 0.04706009801540228, 0.07059014702310341, 0.09412019603080456, 0.09412019603080456, 0.09412019603080456, 0.6247274780909557, 0.03674867518182093, 0.09187168795455232, 0.09187168795455232, 0.03674867518182093, 0.09187168795455232, 0.9643699132046183, 0.9275848792900497, 0.8364588727124264, 0.18424696627008685, 0.18424696627008685, 0.2533395786213694, 0.16121609548632598, 0.06909261235128257, 0.16121609548632598, 0.7580794058947142, 0.8637419218223883, 0.8858390018820983, 0.11109619439047513, 0.11109619439047513, 0.7776733607333259, 0.7239916651364948, 0.8044329194665881, 0.05745949424761344, 0.05745949424761344, 0.05745949424761344, 0.05745949424761344, 0.15556640286756185, 0.7259765467152887, 0.05185546762252062, 0.05185546762252062, 0.8627912902981553, 0.07843557184528685, 0.69827397377403, 0.6037400032685071, 0.3109754605999422, 0.6530484672598785, 0.5839167040446269, 0.044916669541894376, 0.359333356335155, 0.045452658990104436, 0.9090531798020887, 0.8565329298606814, 0.0951703255400757, 0.5985011446066897, 0.6958807103844309, 0.9586420195635005, 0.8967220559578635, 0.04719589768199282, 0.04719589768199282, 0.08533216321149599, 0.17066432642299198, 0.17066432642299198, 0.597325142480472, 0.48076945830170104, 0.16578257182817277, 0.04973477154845183, 0.23209560055944187, 0.033156514365634555, 0.033156514365634555, 0.9656073278994463, 0.29846801746486973, 0.059693603492973944, 0.059693603492973944, 0.5969360349297395, 0.11947275477162345, 0.8363092834013641, 0.10488084238530274, 0.8390467390824219, 0.10488084238530274, 0.630503068074029, 0.7757946851184275, 0.031031787404737103, 0.0930953622142113, 0.0930953622142113, 0.031031787404737103, 0.12067968027136024, 0.7240780816281615, 0.12067968027136024, 0.6062084050184393, 0.8548032360988799, 0.8929964078065313, 0.8494700031014444, 0.9235830436020767, 0.06064689390281626, 0.4851751512225301, 0.3032344695140813, 0.03032344695140813, 0.06064689390281626, 0.0909703408542244, 0.20514966242374938, 0.6154489872712482, 0.10257483121187469, 0.8858975356568787, 0.8777248061004381, 0.8406809639012517, 0.5939801893502538, 0.7620403590478108, 0.8623709338241043, 0.7339811009242997, 0.035803956142648766, 0.05370593421397315, 0.05370593421397315, 0.1074118684279463, 0.035803956142648766, 0.3144190731094421, 0.07860476827736053, 0.07860476827736053, 0.07860476827736053, 0.47162860966416315, 0.8186786120545024, 0.08186786120545024, 0.05457857413696683, 0.027289287068483416, 0.027289287068483416, 0.825246001368088, 0.03215244161174369, 0.03215244161174369, 0.010717480537247897, 0.09645732483523108, 0.010717480537247897, 0.15229201587156072, 0.7614600793578036, 0.7375708181680055, 0.5954529290118394, 0.14651382493722653, 0.07325691246861327, 0.14651382493722653, 0.6593122122175195, 0.6706224085622005, 0.08382780107027506, 0.06985650089189588, 0.04191390053513753, 0.06985650089189588, 0.06985650089189588, 0.9331843677497815, 0.025221199128372476, 0.025221199128372476, 0.012610599564186238, 0.9735849580706162, 0.020283019959804503, 0.8924133790181373, 0.08924133790181372, 0.7321939824608658, 0.9183906193578937, 0.5838951999016696, 0.13380931664413262, 0.0729868999877087, 0.04865793332513914, 0.0851513833189935, 0.0729868999877087, 0.0568060644724801, 0.9088970315596816, 0.02840303223624005, 0.1785074766206884, 0.7140299064827536, 0.05535192622258736, 0.8856308195613978, 0.05535192622258736, 0.5786233574549382, 0.8553889489940731, 0.09469981856745129, 0.09469981856745129, 0.8522983671070616, 0.8491911070645645, 0.08491911070645645, 0.05819357722195178, 0.23277430888780712, 0.6401293494414695, 0.05819357722195178, 0.117653664518799, 0.4117878258157965, 0.4117878258157965, 0.0588268322593995, 0.14785886832531436, 0.7392943416265718, 0.789171324280399, 0.5421159928207395, 0.06995045068654704, 0.06412124646266812, 0.11075488025369948, 0.16904692249248868, 0.05246283801491028, 0.26583160517462257, 0.19139875572572823, 0.26583160517462257, 0.0744328494488943, 0.10633264206984902, 0.10633264206984902, 0.8493186643446369, 0.8341635149904543, 0.2951034183543968, 0.09836780611813227, 0.5902068367087936, 0.11087689569513845, 0.7761382698659692, 0.762181150671055, 0.15643615627072058, 0.7821807813536029, 0.7982380573644289, 0.7929262602580831, 0.917064271894796, 0.9046661754379977, 0.0463931372019486, 0.0463931372019486, 0.8345314079019222, 0.8638054326285577, 0.08638054326285577, 0.07291996490388085, 0.7535063040067688, 0.024306654967960282, 0.048613309935920564, 0.048613309935920564, 0.048613309935920564, 0.8473888226448971, 0.9846808659778178, 0.8067055417078169, 0.9604223819329136, 0.8162654899561279, 0.14965527807090337, 0.7482763903545168, 0.6832244972227677, 0.21392783990251427, 0.6417835197075428, 0.7284106017846775, 0.9312883947865871, 0.04569600275052531, 0.04569600275052531, 0.18278401100210123, 0.04569600275052531, 0.6854400412578796, 0.04569600275052531, 0.8646052263821847, 0.061757516170156054, 0.8015640152728918, 0.9625900841157866, 0.10934372342559398, 0.36447907808531327, 0.03644790780853133, 0.36447907808531327, 0.07289581561706265, 0.03644790780853133, 0.7850429144107313, 0.566912395854258, 0.0377941597236172, 0.1322795590326602, 0.0755883194472344, 0.094485399309043, 0.0755883194472344, 0.038687006649917394, 0.44490057647405007, 0.30949605319933915, 0.09671751662479348, 0.05803050997487609, 0.05803050997487609, 0.919137975930919, 0.6703605031216043, 0.28157158613483924, 0.6335360688033883, 0.41480266437376756, 0.05925752348196679, 0.05925752348196679, 0.26665885566885056, 0.0888862852229502, 0.148143808704917, 0.1893164477255675, 0.6941603083270808, 0.06310548257518916, 0.06979164810981626, 0.06979164810981626, 0.06979164810981626, 0.41874988865889756, 0.41874988865889756, 0.9808901048488515, 0.939808675599582, 0.3117783483772357, 0.04453976405389082, 0.5790169327005806, 0.2420952500912919, 0.7262857502738757, 0.17602473112968836, 0.7627738348953162, 0.13149124927272693, 0.06574562463636346, 0.06574562463636346, 0.7232018709999981, 0.1763137538790026, 0.7052550155160104, 0.09284487587771034, 0.09284487587771034, 0.09284487587771034, 0.09284487587771034, 0.09284487587771034, 0.557069255266262, 0.25541066219272973, 0.05108213243854595, 0.1021642648770919, 0.5108213243854595, 0.05108213243854595, 0.9652824615001362, 0.019624194682845555, 0.43173228302260225, 0.2747387255598378, 0.09812097341422778, 0.07849677873138222, 0.07849677873138222, 0.5691754948228058, 0.04065539248734327, 0.08131078497468654, 0.2845877474114029, 0.07674677783742868, 0.07674677783742868, 0.23024033351228604, 0.5372274448620008, 0.07674677783742868, 0.917442195320506, 0.7568249276045964, 0.08409165862273293, 0.08409165862273293, 0.03273621162639787, 0.19641726975838725, 0.4583069627695702, 0.06547242325279574, 0.03273621162639787, 0.2291534813847851, 0.7725002518330385, 0.03961539752989941, 0.07923079505979883, 0.019807698764949706, 0.07923079505979883, 0.019807698764949706, 0.9001959933315863, 0.06924584564089124, 0.7618420002204825, 0.5979151150262341, 0.0703429547089687, 0.09379060627862494, 0.0703429547089687, 0.09379060627862494, 0.08206678049379683, 0.1843461233387351, 0.1843461233387351, 0.5530383700162053, 0.8687006524163993, 0.0715003836997656, 0.0715003836997656, 0.1430007673995312, 0.6435034532978904, 0.4040721101499185, 0.019241529054758025, 0.4810382263689506, 0.057724587164274074, 0.057724587164274074, 0.7002883928923636, 0.1400576785784727, 0.502505051427387, 0.06700067352365159, 0.06700067352365159, 0.06700067352365159, 0.06700067352365159, 0.26800269409460636, 0.6076940679103626, 0.046745697531566356, 0.32721988272096453, 0.02817983686338621, 0.6481362478578828, 0.19725885804370347, 0.02817983686338621, 0.05635967372677242, 0.05635967372677242, 0.8706943033981025, 0.056291685756302064, 0.6192085433193227, 0.30022232403361104, 0.03752779050420138, 0.9504626667695206, 0.6579280356343081, 0.06367045506138466, 0.042446970040923106, 0.10611742510230776, 0.042446970040923106, 0.08489394008184621, 0.029676693008384214, 0.6825639391928369, 0.05935338601676843, 0.11870677203353686, 0.05935338601676843, 0.029676693008384214, 0.09373369220895193, 0.7030026915671395, 0.09373369220895193, 0.046866846104475966, 0.046866846104475966, 0.24024948379165892, 0.15015592736978683, 0.0900935564218721, 0.030031185473957365, 0.4504677821093605, 0.06006237094791473, 0.8940117166031821, 0.23521500762773725, 0.5880375190693432, 0.11760750381386863, 0.8615950930748013, 0.7939199344826826, 0.22892400882388428, 0.11446200441194214, 0.11446200441194214, 0.05723100220597107, 0.4006170154417975, 0.11778002291724224, 0.05889001145862112, 0.8244601604206957, 0.1766079489200586, 0.04415198723001465, 0.04415198723001465, 0.04415198723001465, 0.7064317956802344, 0.843681825787837, 0.07030681881565308, 0.7863240211693938, 0.375390495893303, 0.375390495893303, 0.12513016529776766, 0.12513016529776766, 0.44347139332149726, 0.12670611237757065, 0.380118337132712, 0.9123471788255807, 0.9764622783325297, 0.3770889559996376, 0.13198113459987315, 0.056563343399945634, 0.24510782139976442, 0.07541779119992752, 0.0942722389999094, 0.1295526494539874, 0.647763247269937, 0.1295526494539874, 0.6098515102423948, 0.05753316134362215, 0.05753316134362215, 0.09205305814979543, 0.12657295495596874, 0.05753316134362215, 0.038122119962784515, 0.6480760393673367, 0.22873271977670706, 0.038122119962784515, 0.038122119962784515, 0.1413390466590295, 0.09422603110601965, 0.04711301555300983, 0.04711301555300983, 0.09422603110601965, 0.565356186636118, 0.8786761802489611, 0.859324846326145, 0.7204815078227824, 0.11084330889581268, 0.11084330889581268, 0.9072522077358676, 0.11277770376596535, 0.7894439263617575, 0.09096191528106054, 0.8186572375295449, 0.8893656318427047, 0.9057093902445984, 0.06469352787461417, 0.9605879436215327, 0.050629795925913705, 0.35440857148139593, 0.37972346944435276, 0.07594469388887055, 0.050629795925913705, 0.07594469388887055, 0.05418498652045013, 0.7044048247658516, 0.16255495956135038, 0.10836997304090026, 0.08292890981866195, 0.6634312785492956, 0.1658578196373239, 0.40305502695508405, 0.08061100539101682, 0.1343516756516947, 0.2687033513033894, 0.05374067026067788, 0.02687033513033894, 0.9072712604293081, 0.9653855782661257, 0.033289157871245714, 0.43509762209979275, 0.08701952441995855, 0.10877440552494819, 0.26105857325987564, 0.02175488110498964, 0.08701952441995855, 0.034169145829701125, 0.034169145829701125, 0.10250743748910336, 0.8200594999128269, 0.8239275165282296, 0.1029909395660287, 0.15661073040548024, 0.7308500752255745, 0.05220357680182675, 0.05159707702563431, 0.39987734694866595, 0.32248173141021447, 0.07739561553845146, 0.06449634628204289, 0.09029488479486004, 0.7579620065078131], \"Term\": [\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a_lot\", \"a_lot\", \"a_lot\", \"a_must\", \"a_must\", \"a_must\", \"affordable\", \"agama_hindu\", \"agama_hindu\", \"ago\", \"ago\", \"ago\", \"ago\", \"airport\", \"airport\", \"ajaib_dunia\", \"ajaib_dunia\", \"ajaib_dunia\", \"ajaib_dunia\", \"ajaib_dunia\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"amaze\", \"amaze\", \"amaze\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"ancient\", \"ancient\", \"ancient\", \"ancient\", \"ancient\", \"ancient\", \"ancient_hindu\", \"ancient_hindu\", \"annual\", \"arca\", \"arca\", \"awat_bersih\", \"bagus\", \"bagus\", \"bagus\", \"bagus\", \"bagus\", \"bagus\", \"bagus_banget\", \"bagus_banget\", \"bagus_banget\", \"ballet\", \"ballet\", \"ballet\", \"bandung\", \"bandung_bondowoso\", \"bandung_bondowoso\", \"bangsa_indonesia\", \"bangsa_indonesia\", \"bangsa_indonesia\", \"bangun_abad\", \"bangun_abad\", \"banyak_spot\", \"banyak_spot\", \"bawa_payung\", \"bawa_payung\", \"bawa_payung\", \"bawa_payung\", \"beatifull\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautifull\", \"beside\", \"beside\", \"besides\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best_place\", \"big\", \"big\", \"big\", \"big\", \"big\", \"big\", \"bike\", \"bike\", \"bored\", \"borobudur\", \"borobudur\", \"borobudur\", \"borobudur\", \"borobudur\", \"borobudur\", \"brahma_vishnu\", \"brahma_vishnu\", \"brahma_vishnu\", \"bright\", \"bring_hat\", \"bring_hat\", \"bring_umbrella\", \"bring_umbrella\", \"buy_ticket\", \"cafe\", \"candi_prambanan\", \"candi_prambanan\", \"candi_prambanan\", \"candi_prambanan\", \"candi_prambanan\", \"candi_prambanan\", \"candi_sewu\", \"candi_sewu\", \"candi_sewu\", \"candi_sewu\", \"central_java\", \"central_java\", \"central_java\", \"clean_well\", \"clean_well\", \"cleanliness\", \"cocok_libur\", \"cocok_libur\", \"complex\", \"complex\", \"complex\", \"complex\", \"complex\", \"complex\", \"concert\", \"creation\", \"creation\", \"cultural_heritage\", \"cultural_heritage\", \"dance\", \"decorated\", \"decorated\", \"describe\", \"describe\", \"describe\", \"destination\", \"destination\", \"destination\", \"destination\", \"destination\", \"destroyed_earthquake\", \"dewa\", \"dewa_siwa\", \"dont_forget\", \"dont_forget\", \"dont_forget\", \"dont_forget\", \"dont_miss\", \"drone\", \"dynasty\", \"early_morning\", \"early_morning\", \"early_morning\", \"early_morning\", \"early_morning\", \"earth\", \"easy_access\", \"edukasi\", \"edukasi\", \"edukasi\", \"entrance_ticket\", \"entrance_ticket\", \"entry_fee\", \"entry_fee\", \"entry_ticket\", \"entry_ticket\", \"event\", \"event\", \"ever_seen\", \"exciting\", \"exit_gate\", \"exotic\", \"expensive_foreigner\", \"failed\", \"fav\", \"favorite\", \"favorite\", \"favourite\", \"feed\", \"feed\", \"festival\", \"festival\", \"festival\", \"fully\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good_place\", \"good_place\", \"good_place\", \"good_place\", \"good_place\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great_place\", \"great_place\", \"great_place\", \"great_place\", \"great_view\", \"great_view\", \"harga\", \"harga\", \"harga\", \"harga\", \"harga\", \"harga\", \"harga_tiket\", \"harga_tiket\", \"harga_tiket\", \"harga_tiket\", \"harga_tiket\", \"hat_umbrella\", \"hat_umbrella\", \"held\", \"heritage\", \"heritage\", \"heritage\", \"heritage\", \"heritage\", \"heritage\", \"heritage_site\", \"heritage_site\", \"heritage_site\", \"heritage_site\", \"heritage_site\", \"heritage_site\", \"highly_recommend\", \"highly_recommend\", \"highly_recommend\", \"highly_recommend\", \"hindhu\", \"hindhu\", \"hindu\", \"hindu\", \"hindu\", \"hindu\", \"hindu\", \"hindu\", \"hindu_besar\", \"hindu_besar\", \"hindu_temple\", \"hindu_temple\", \"hindu_temple\", \"hindu_temple\", \"hindu_temple\", \"hindu_temple\", \"hindus\", \"hindus_temple\", \"historic\", \"historic\", \"historic_place\", \"historical\", \"historical\", \"historical\", \"historical\", \"historical\", \"historical\", \"historical_place\", \"historical_place\", \"historical_place\", \"historical_place\", \"historical_site\", \"historical_site\", \"historical_value\", \"history\", \"history\", \"history\", \"history\", \"history\", \"holiday_season\", \"hospitality\", \"i\", \"i\", \"i\", \"i\", \"i\", \"i\", \"i_cant\", \"i_hope\", \"i_hope\", \"i_love\", \"i_love\", \"i_love\", \"i_love\", \"i_love\", \"i_loved\", \"i_recommend\", \"i_recommend\", \"i_recommend\", \"i_recommend\", \"i_recommend\", \"i_think\", \"i_think\", \"i_think\", \"i_think\", \"i_visited\", \"i_visited\", \"i_visited\", \"i_visited\", \"i_visited\", \"iconic\", \"if_youre\", \"ill\", \"im_sure\", \"indah\", \"indah\", \"indah\", \"indah\", \"indah\", \"indah\", \"indonesia\", \"indonesia\", \"indonesia\", \"indonesia\", \"indonesia\", \"indonesia\", \"island\", \"it\", \"it\", \"it\", \"it\", \"it\", \"it\", \"its\", \"its\", \"its\", \"its\", \"its\", \"its\", \"its_really\", \"jazz\", \"jgn_lupa\", \"jogja\", \"jogja\", \"jogja\", \"jogja\", \"jogja\", \"jogja\", \"kamar_mandi\", \"kenal_sejarah\", \"kenang\", \"keren_banget\", \"keren_banget\", \"keren_banget\", \"knowing\", \"komplek_candi\", \"komplek_candi\", \"komplek_candi\", \"komplek_candi\", \"komplek_candi\", \"kompleks_candi\", \"kompleks_candi\", \"kompleks_candi\", \"kompleks_candi\", \"kunjung_wisatawan\", \"kunjung_wisatawan\", \"landmark\", \"language\", \"largest_hindu\", \"largest_hindu\", \"learn\", \"learn\", \"learn\", \"learn_history\", \"learn_history\", \"libur_keluarga\", \"libur_keluarga\", \"lighting\", \"liked\", \"little_bit\", \"local_guide\", \"local_guide\", \"local_guide\", \"location\", \"location\", \"location\", \"location\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love_place\", \"lovely\", \"lovely\", \"lovely\", \"lovely\", \"lumayan_mahal\", \"lumayan_mahal\", \"lupa_bawa\", \"lupa_bawa\", \"lupa_bawa\", \"main_road\", \"make_sure\", \"make_sure\", \"make_sure\", \"make_sure\", \"make_sure\", \"managed\", \"managed\", \"managed\", \"manca_negara\", \"many_thing\", \"marathon\", \"marvelous\", \"massive\", \"masuk\", \"masuk\", \"masuk\", \"masuk\", \"masuk\", \"masuk\", \"memorable\", \"memorable\", \"memorable\", \"memory\", \"mesmerizing\", \"mineral_water\", \"more\", \"motorbike\", \"much_better\", \"must\", \"must\", \"must\", \"must\", \"must\", \"must\", \"must_go\", \"must_go\", \"must_go\", \"must_go\", \"must_go\", \"must_see\", \"must_see\", \"must_see\", \"must_see\", \"must_see\", \"must_visit\", \"must_visit\", \"must_visit\", \"must_visit\", \"must_visit\", \"must_visit\", \"mustsee\", \"mustsee\", \"na\", \"named\", \"nenek_moyang\", \"nenek_moyang\", \"nenek_moyang\", \"nenek_moyang\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice_place\", \"nice_place\", \"nice_place\", \"nice_place\", \"nice_view\", \"nice_view\", \"no\", \"no\", \"object\", \"of\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one_best\", \"one_best\", \"one_best\", \"one_seven\", \"one_seven\", \"one_wonder\", \"one_wonder\", \"one_wonder\", \"panas_sengat\", \"pandang_indah\", \"parking_area\", \"parking_area\", \"parking_area\", \"parking_lot\", \"parking_lot\", \"parkir_luas\", \"parkir_luas\", \"parkir_luas\", \"parkir_luas\", \"performance\", \"performance\", \"performance\", \"performance\", \"pertama_kali\", \"pertama_kali\", \"pikat\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"prambanan\", \"prambanan\", \"prambanan\", \"prambanan\", \"prambanan\", \"prambanan\", \"prambanan_jazz\", \"prasasti_siwagrha\", \"prepare\", \"prepare\", \"prepare\", \"proud\", \"proud\", \"pulau_jawa\", \"rain\", \"rain\", \"raining\", \"raka\", \"raka_pikat\", \"ramayana_ballet\", \"ramayana_ballet\", \"ramayana_ballet\", \"rame_banget\", \"rara_jonggrang\", \"rara_jonggrang\", \"ratu_boko\", \"ratu_boko\", \"ratu_boko\", \"ratu_boko\", \"ratu_boko\", \"ratu_boko\", \"rb\", \"really_hot\", \"recreation\", \"rekreasi\", \"relax\", \"relic\", \"relic\", \"rent_bike\", \"rest\", \"rest\", \"rich_history\", \"romantic\", \"roro_jonggrang\", \"roro_jonggrang\", \"roro_jonggrang\", \"roro_jonggrang\", \"roro_jonggrang\", \"roro_jonggrang\", \"roro_jongrang\", \"roro_jongrang\", \"rorojongrang\", \"sacred\", \"salah_ajaib\", \"salah_ajaib\", \"salah_ajaib\", \"salah_ajaib\", \"salah_ajaib\", \"salah_ajaib\", \"sand\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"sejarah\", \"sejarah\", \"sejarah\", \"sejarah\", \"sejarah\", \"sejarah\", \"serve\", \"shoot\", \"siang_panas\", \"siang_panas\", \"site\", \"site\", \"site\", \"site\", \"site\", \"site\", \"siwa\", \"siwa\", \"siwa\", \"smaller_temple\", \"smaller_temple\", \"smaller_temple\", \"smaller_temple\", \"smaller_temple\", \"southeast_asia\", \"spending\", \"spot_foto\", \"spot_foto\", \"spot_foto\", \"station\", \"station\", \"story_behind\", \"story_behind\", \"such\", \"such\", \"such\", \"such\", \"such_amazing\", \"such_amazing\", \"sunrise_tour\", \"sunrise_tour\", \"sunrise_tour\", \"sunrise_tour\", \"sunrise_tour\", \"sunrise_tour\", \"take_picture\", \"take_picture\", \"take_picture\", \"take_picture\", \"take_picture\", \"tample\", \"tempat\", \"tempat\", \"tempat\", \"tempat\", \"tempat\", \"tempat\", \"tempat_bagus\", \"tempat_bagus\", \"tempat_bagus\", \"tempat_bagus\", \"tempat_bersih\", \"tempat_bersih\", \"tempat_bersih\", \"tempat_bersih\", \"tempat_bersih\", \"tempat_luas\", \"tempat_sejarah\", \"tempat_sejarah\", \"tempat_sejarah\", \"tempat_wisata\", \"tempat_wisata\", \"tempat_wisata\", \"tempat_wisata\", \"tempat_wisata\", \"tempat_wisata\", \"temple_complex\", \"temple_complex\", \"temple_complex\", \"temple_complex\", \"temple_complex\", \"temple_complex\", \"temple_compound\", \"temple_compound\", \"thank\", \"the\", \"the\", \"the\", \"the\", \"the\", \"the\", \"the_best\", \"the_best\", \"the_best\", \"the_biggest\", \"there_many\", \"there_many\", \"there_many\", \"there_many\", \"this_place\", \"this_place\", \"this_place\", \"this_place\", \"this_place\", \"thousand_year\", \"thousand_year\", \"ticket\", \"ticket\", \"ticket\", \"ticket\", \"ticket\", \"ticket\", \"ticket_price\", \"ticket_price\", \"ticket_price\", \"tiket\", \"tiket\", \"tiket\", \"tiket\", \"tiket\", \"tiket\", \"tiket_mahal\", \"tiket_masuk\", \"tiket_masuk\", \"tiket_masuk\", \"tiket_masuk\", \"tiket_terus\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"tinggal_sejarah\", \"tinggal_sejarah\", \"tinggal_sejarah\", \"tinggal_sejarah\", \"tinggal_sejarah\", \"tinggal_sejarah\", \"toilet\", \"toilet\", \"toilet\", \"toilet\", \"toilet\", \"tour_guide\", \"tour_guide\", \"tour_guide\", \"tour_guide\", \"tour_guide\", \"tour_guide\", \"tourist_attraction\", \"traditional\", \"traditional\", \"traditional\", \"trash\", \"treasure\", \"unesco\", \"unesco\", \"unesco\", \"unesco\", \"unesco\", \"unesco_heritage\", \"unesco_heritage\", \"unesco_heritage\", \"unesco_world\", \"unesco_world\", \"unesco_world\", \"unesco_world\", \"unesco_world\", \"vacation\", \"vacation\", \"value\", \"very\", \"very\", \"very\", \"very\", \"very_beautiful\", \"very_beautiful\", \"very_beautiful\", \"very_good\", \"very_nice\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view_top\", \"view_top\", \"view_top\", \"visit\", \"visit\", \"visit\", \"visit\", \"visit\", \"visit\", \"wajib_kunjung\", \"wajib_kunjung\", \"wajib_kunjung\", \"wajib_kunjung\", \"wajib_kunjung\", \"walk_around\", \"walk_around\", \"walk_around\", \"walk_around\", \"walk_around\", \"walk_around\", \"wan\", \"wan_na\", \"waris_budaya\", \"waris_budaya\", \"waris_budaya\", \"waris_dunia\", \"watch_ramayana\", \"watch_ramayana\", \"well_managed\", \"well_managed\", \"well_organized\", \"well_preserved\", \"well_preserved\", \"whole_complex\", \"wisata\", \"wisata\", \"wisata\", \"wisata\", \"wisata\", \"wisata\", \"wisata_sejarah\", \"wisata_sejarah\", \"wisata_sejarah\", \"wisata_sejarah\", \"wonder_world\", \"wonder_world\", \"wonder_world\", \"wonderful\", \"wonderful\", \"wonderful\", \"wonderful\", \"wonderful\", \"wonderful\", \"wonderful_place\", \"wonderfull\", \"wonderfull\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world_heritage\", \"world_heritage\", \"world_heritage\", \"world_heritage\", \"worth_visiting\", \"worth_visiting\", \"year_ago\", \"year_ago\", \"year_ago\", \"yg\", \"yg\", \"yg\", \"yg\", \"yg\", \"yg\", \"yogyakarta_city\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 1, 3, 4, 2, 6]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el144425249911520643580330688\", ldavis_el144425249911520643580330688_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el144425249911520643580330688\", ldavis_el144425249911520643580330688_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el144425249911520643580330688\", ldavis_el144425249911520643580330688_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "4     -0.182660 -0.016445       1        1  30.351665\n",
       "0      0.127923  0.015041       2        1  20.541963\n",
       "2      0.110088 -0.020044       3        1  18.352408\n",
       "3     -0.013622 -0.059623       4        1  10.618669\n",
       "1     -0.031603  0.126300       5        1  10.157942\n",
       "5     -0.010126 -0.045229       6        1   9.977352, topic_info=                  Term       Freq       Total Category  logprob  loglift\n",
       "2374       great_place  63.000000   63.000000  Default  30.0000  30.0000\n",
       "3298  historical_place  64.000000   64.000000  Default  29.0000  29.0000\n",
       "3634          one_best  70.000000   70.000000  Default  28.0000  28.0000\n",
       "3239         nice_view  49.000000   49.000000  Default  27.0000  27.0000\n",
       "2841      hindu_temple  99.000000   99.000000  Default  26.0000  26.0000\n",
       "...                ...        ...         ...      ...      ...      ...\n",
       "57               place   8.594151  171.550003   Topic6  -5.6298  -0.6889\n",
       "1615               the   7.488573   85.296389   Topic6  -5.7675  -0.1279\n",
       "991                  i   6.964066   69.030300   Topic6  -5.8401   0.0111\n",
       "304              jogja   6.659951   43.419982   Topic6  -5.8848   0.4300\n",
       "109                 yg   6.505593   77.523771   Topic6  -5.9082  -0.1731\n",
       "\n",
       "[383 rows x 6 columns], token_table=      Topic      Freq             Term\n",
       "term                                  \n",
       "1715      1  0.740633                a\n",
       "1715      2  0.046290                a\n",
       "1715      3  0.023145                a\n",
       "1715      4  0.069434                a\n",
       "1715      5  0.092579                a\n",
       "...     ...       ...              ...\n",
       "109       3  0.322482               yg\n",
       "109       4  0.077396               yg\n",
       "109       5  0.064496               yg\n",
       "109       6  0.090295               yg\n",
       "2035      4  0.757962  yogyakarta_city\n",
       "\n",
       "[872 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[5, 1, 3, 4, 2, 6])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluasi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

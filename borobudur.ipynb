{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset for Aspect-Based Sentiment Analysis and Topic Modeling on Borobudur Temple and Prambanan Temple by Dian Arianto\n",
    "https://github.com/dian9395/dataset-analisis-sentimen-berbasis-aspek-dan-pemodelan-topik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lokasi</th>\n",
       "      <th>text</th>\n",
       "      <th>daya_tarik</th>\n",
       "      <th>amenitas</th>\n",
       "      <th>aksesibilitas</th>\n",
       "      <th>citra</th>\n",
       "      <th>harga</th>\n",
       "      <th>sdm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Candi Borobudur</td>\n",
       "      <td>peninggalan sejarah yang sudah berumur 1200 ta...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Candi Borobudur</td>\n",
       "      <td>Pertama kali bepergian selama masa pandemi. Ca...</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Candi Borobudur</td>\n",
       "      <td>Candi Borobudur di Magelang, Yogyakarta adalah...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Candi Borobudur</td>\n",
       "      <td>Baru pertama kali kesini, pas sih kalau tempat...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Candi Borobudur</td>\n",
       "      <td>candi borobudur, tempat wisata ini sudah terke...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6738</th>\n",
       "      <td>6739.0</td>\n",
       "      <td>Candi Prambanan</td>\n",
       "      <td>The place is great and probably everything you...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6739</th>\n",
       "      <td>6740.0</td>\n",
       "      <td>Candi Prambanan</td>\n",
       "      <td>Prambanan or Rara Jonggrang (Javanese: ꦫꦫꦗꦺꦴꦁꦒ...</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6740</th>\n",
       "      <td>6741.0</td>\n",
       "      <td>Candi Prambanan</td>\n",
       "      <td>This temple is not worth the price. There’s no...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6741</th>\n",
       "      <td>6742.0</td>\n",
       "      <td>Candi Prambanan</td>\n",
       "      <td>Prambanan temple is the largest hindu temple o...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6742</th>\n",
       "      <td>6743.0</td>\n",
       "      <td>Candi Prambanan</td>\n",
       "      <td>Best choice for me of the three most-famous te...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6743 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id           lokasi  \\\n",
       "0        1.0  Candi Borobudur   \n",
       "1        2.0  Candi Borobudur   \n",
       "2        3.0  Candi Borobudur   \n",
       "3        4.0  Candi Borobudur   \n",
       "4        5.0  Candi Borobudur   \n",
       "...      ...              ...   \n",
       "6738  6739.0  Candi Prambanan   \n",
       "6739  6740.0  Candi Prambanan   \n",
       "6740  6741.0  Candi Prambanan   \n",
       "6741  6742.0  Candi Prambanan   \n",
       "6742  6743.0  Candi Prambanan   \n",
       "\n",
       "                                                   text daya_tarik amenitas  \\\n",
       "0     peninggalan sejarah yang sudah berumur 1200 ta...          1        -   \n",
       "1     Pertama kali bepergian selama masa pandemi. Ca...          -        1   \n",
       "2     Candi Borobudur di Magelang, Yogyakarta adalah...          1        -   \n",
       "3     Baru pertama kali kesini, pas sih kalau tempat...          1        -   \n",
       "4     candi borobudur, tempat wisata ini sudah terke...          1        1   \n",
       "...                                                 ...        ...      ...   \n",
       "6738  The place is great and probably everything you...          1        -   \n",
       "6739  Prambanan or Rara Jonggrang (Javanese: ꦫꦫꦗꦺꦴꦁꦒ...          0        -   \n",
       "6740  This temple is not worth the price. There’s no...         -1        -   \n",
       "6741  Prambanan temple is the largest hindu temple o...          1        -   \n",
       "6742  Best choice for me of the three most-famous te...          1        -   \n",
       "\n",
       "     aksesibilitas citra harga sdm  \n",
       "0                -     1     0   0  \n",
       "1                -     1     -   1  \n",
       "2                -     1     -   -  \n",
       "3                -     -    -1   -  \n",
       "4                -     1     -   -  \n",
       "...            ...   ...   ...  ..  \n",
       "6738             -     -    -1   -  \n",
       "6739             -     -     -   -  \n",
       "6740             -    -1    -1  -1  \n",
       "6741             -     -     -   -  \n",
       "6742             -     -    -1   -  \n",
       "\n",
       "[6743 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('dataset/reviews_borobudur_prambanan_TripAdvisor_GMaps_all_tesis.xlsx')\n",
    "df_clean = df.dropna()\n",
    "# print(\"\\nDrop rows with any NaN values:\")\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = df_clean['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Emoji processing; case folding; menghapus username, angka, dan tanda baca; koreksi ejaan dan singkatan serta menghapus whitespace; penghapusan stopwords, dan stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Daftar emoji berdasarkan sentimen\n",
    "emoji_positif = [\"😊\", \"😄\", \"♥\", \"😍\", \"😘\", \"😃\", \"😁\", \"😆\", \"😇\", \"☺\"]\n",
    "emoji_negatif = [\"😢\", \"😠\", \"😡\", \"😭\", \"😱\", \"😨\", \"😫\", \"😩\", \"😖\", \"😔\"]\n",
    "emoji_netral = [\"👍\", \"✨\", \"★\", \"█\", \"👌\", \"♫\", \"�\", \"©\", \"💬\", \"🔔\"]\n",
    "\n",
    "# Fungsi untuk mengganti emoji dengan label sentimen\n",
    "def emotion(teks):\n",
    "    for emoji in emoji_positif:\n",
    "        teks = teks.replace(emoji, \"positif\")\n",
    "    for emoji in emoji_negatif:\n",
    "        teks = teks.replace(emoji, \"negatif\")\n",
    "    for emoji in emoji_netral:\n",
    "        teks = teks.replace(emoji, \"netral\")\n",
    "    return teks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1qqSuE1tuDCCfsdKgXMC3Nj0jda1LuWXB\n",
      "To: e:\\PROJECT\\Python-Pro\\sa-TripAdvisor\\stopwords_uci.txt\n",
      "100%|██████████| 6.91k/6.91k [00:00<00:00, 359kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Ufurgc02rF2_yuFh8GNw1VOpkNbJLKWx\n",
      "To: e:\\PROJECT\\Python-Pro\\sa-TripAdvisor\\stopwords_nltk.txt\n",
      "100%|██████████| 7.39k/7.39k [00:00<00:00, 698kB/s]\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "# URL dari file Google Drive\n",
    "stopwords_uci_link = 'https://drive.google.com/uc?id=1qqSuE1tuDCCfsdKgXMC3Nj0jda1LuWXB'\n",
    "stopwords_nltk_link = 'https://drive.google.com/uc?id=1Ufurgc02rF2_yuFh8GNw1VOpkNbJLKWx'\n",
    "stopwords_uci_output = 'stopwords_uci.txt'\n",
    "stopwords_nltk_output = 'stopwords_nltk.txt'\n",
    "# Mengunduh file\n",
    "gdown.download(stopwords_uci_link, stopwords_uci_output, quiet=False)\n",
    "gdown.download(stopwords_nltk_link, stopwords_nltk_output, quiet=False)\n",
    "# Membaca konten file\n",
    "with open(stopwords_uci_output, 'r', encoding='utf-8') as file:\n",
    "    stopwords_uci = file.read()\n",
    "with open(stopwords_nltk_output, 'r', encoding='utf-8') as file:\n",
    "    stopwords_nltk = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # text preprocessing\n",
    "    teks = emotion(text)\n",
    "    teks = teks.lower()\n",
    "    teks = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    stop_words = set(stopwords.words('english') + stopwords_uci.split('\\n') + stopwords_nltk.split('\\n'))\n",
    "    tokens = word_tokenize(teks)\n",
    "    filtered_tokens = [word for word in tokens if word.isalnum() and not any(char.isdigit() for char in word) and word not in stop_words]\n",
    "    stemmer_factory = StemmerFactory()\n",
    "    sastrawi_stemmer = stemmer_factory.create_stemmer()\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    lemma = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    indonesian_stemmed_words = [sastrawi_stemmer.stem(word) for word in lemma]\n",
    "    clean_reviews = ' '.join(indonesian_stemmed_words)\n",
    "    return clean_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       tinggal sejarah umur indonesia bangsa indonesi...\n",
       "1       pertama kali pergi pandemi candi borobudur pro...\n",
       "2       candi borobudur magelang yogyakarta salah reko...\n",
       "3       baru kali kesini pa sih ajaib dunia sulit baya...\n",
       "4       candi borobudur wisata kenal dunia ganti sy wi...\n",
       "                              ...                        \n",
       "6738    the place great probably everything expect how...\n",
       "6739    prambanan rara jonggrang javanese romanized ra...\n",
       "6740    this temple worth price theres much see poorly...\n",
       "6741    prambanan temple largest hindu temple ancient ...\n",
       "6742    best choice three mostfamous temple yogyakarta...\n",
       "Name: text, Length: 6743, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teks = review.apply(preprocess)\n",
    "teks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ekstraksi Fitur\n",
    "words n-gram. words unigram+bigram+trigram untuk fiturnya dan vektornya diekstraksi dengan CountVectorizer dari pustaka Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eksperimen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis Sentimen Berbasis Aspek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import resample\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>daya_tarik</th>\n",
       "      <th>amenitas</th>\n",
       "      <th>aksesibilitas</th>\n",
       "      <th>citra</th>\n",
       "      <th>harga</th>\n",
       "      <th>sdm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tinggal sejarah umur indonesia bangsa indonesi...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pertama kali pergi pandemi candi borobudur pro...</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>candi borobudur magelang yogyakarta salah reko...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baru kali kesini pa sih ajaib dunia sulit baya...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>candi borobudur wisata kenal dunia ganti sy wi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text daya_tarik amenitas  \\\n",
       "0  tinggal sejarah umur indonesia bangsa indonesi...          1        -   \n",
       "1  pertama kali pergi pandemi candi borobudur pro...          -        1   \n",
       "2  candi borobudur magelang yogyakarta salah reko...          1        -   \n",
       "3  baru kali kesini pa sih ajaib dunia sulit baya...          1        -   \n",
       "4  candi borobudur wisata kenal dunia ganti sy wi...          1        1   \n",
       "\n",
       "  aksesibilitas citra harga sdm  \n",
       "0             -     1     0   0  \n",
       "1             -     1     -   1  \n",
       "2             -     1     -   -  \n",
       "3             -     -    -1   -  \n",
       "4             -     1     -   -  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess = pd.concat([pd.DataFrame(teks), df_clean['daya_tarik'], df_clean['amenitas'], df_clean['aksesibilitas'], df_clean['citra'], df_clean['harga'], df_clean['sdm']], axis=1)\n",
    "preprocess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tinggal sejarah umur indonesia bangsa indonesi...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>candi borobudur magelang yogyakarta salah reko...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baru kali kesini pa sih ajaib dunia sulit baya...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>candi borobudur wisata kenal dunia ganti sy wi...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wajar salah ajaib dunia candi bangun tingkat t...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      aspect sentiment\n",
       "0  tinggal sejarah umur indonesia bangsa indonesi...  daya_tarik         1\n",
       "2  candi borobudur magelang yogyakarta salah reko...  daya_tarik         1\n",
       "3  baru kali kesini pa sih ajaib dunia sulit baya...  daya_tarik         1\n",
       "4  candi borobudur wisata kenal dunia ganti sy wi...  daya_tarik         1\n",
       "5  wajar salah ajaib dunia candi bangun tingkat t...  daya_tarik         1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Melakukan melting pada dataframe\n",
    "melted_df = preprocess.melt(id_vars=['text'], value_vars=['daya_tarik', 'amenitas', 'aksesibilitas', 'citra', 'harga', 'sdm'],\n",
    "                    var_name='aspect', value_name='sentiment')\n",
    "# Menghapus baris dengan nilai '-' pada kolom sentiment\n",
    "melted_df = melted_df[melted_df['sentiment'] != '-']\n",
    "\n",
    "melted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tinggal sejarah umur indonesia bangsa indonesi...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>candi borobudur magelang yogyakarta salah reko...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baru kali kesini pa sih ajaib dunia sulit baya...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>candi borobudur wisata kenal dunia ganti sy wi...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wajar salah ajaib dunia candi bangun tingkat t...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      aspect sentiment\n",
       "0  tinggal sejarah umur indonesia bangsa indonesi...  daya_tarik  positive\n",
       "2  candi borobudur magelang yogyakarta salah reko...  daya_tarik  positive\n",
       "3  baru kali kesini pa sih ajaib dunia sulit baya...  daya_tarik  positive\n",
       "4  candi borobudur wisata kenal dunia ganti sy wi...  daya_tarik  positive\n",
       "5  wajar salah ajaib dunia candi bangun tingkat t...  daya_tarik  positive"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mengubah nilai sentiment\n",
    "sentiment_mapping = {1: 'positive', 0: 'neutral', -1: 'negative'}\n",
    "melted_df['sentiment'] = melted_df['sentiment'].astype(int).map(sentiment_mapping)\n",
    "melted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memisahkan dataframe berdasarkan aspek\n",
    "dfs_melted_df = {aspect: melted_df[melted_df['aspect'] == aspect] for aspect in melted_df['aspect'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daftar algoritma klasifikasi\n",
    "classifiers = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Extra Trees': ExtraTreesClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aspect: daya_tarik\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         9\n",
      "     neutral       0.00      0.00      0.00        64\n",
      "    positive       0.94      1.00      0.97      1120\n",
      "\n",
      "    accuracy                           0.94      1193\n",
      "   macro avg       0.31      0.33      0.32      1193\n",
      "weighted avg       0.88      0.94      0.91      1193\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         9\n",
      "     neutral       0.40      0.03      0.06        64\n",
      "    positive       0.94      1.00      0.97      1120\n",
      "\n",
      "    accuracy                           0.94      1193\n",
      "   macro avg       0.45      0.34      0.34      1193\n",
      "weighted avg       0.90      0.94      0.91      1193\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.09      0.11      0.10         9\n",
      "     neutral       0.07      0.06      0.07        64\n",
      "    positive       0.94      0.94      0.94      1120\n",
      "\n",
      "    accuracy                           0.89      1193\n",
      "   macro avg       0.37      0.37      0.37      1193\n",
      "weighted avg       0.89      0.89      0.89      1193\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         9\n",
      "     neutral       0.20      0.02      0.03        64\n",
      "    positive       0.94      1.00      0.97      1120\n",
      "\n",
      "    accuracy                           0.94      1193\n",
      "   macro avg       0.38      0.34      0.33      1193\n",
      "weighted avg       0.89      0.94      0.91      1193\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         9\n",
      "     neutral       0.14      0.02      0.03        64\n",
      "    positive       0.94      0.99      0.97      1120\n",
      "\n",
      "    accuracy                           0.93      1193\n",
      "   macro avg       0.36      0.34      0.33      1193\n",
      "weighted avg       0.89      0.93      0.91      1193\n",
      "\n",
      "\n",
      "Aspect: amenitas\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.00      0.00      0.00         8\n",
      "    positive       0.78      1.00      0.88       225\n",
      "\n",
      "    accuracy                           0.78       287\n",
      "   macro avg       0.26      0.33      0.29       287\n",
      "weighted avg       0.61      0.78      0.69       287\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.24      0.39        54\n",
      "     neutral       0.00      0.00      0.00         8\n",
      "    positive       0.82      1.00      0.90       225\n",
      "\n",
      "    accuracy                           0.83       287\n",
      "   macro avg       0.61      0.41      0.43       287\n",
      "weighted avg       0.83      0.83      0.78       287\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.56      0.52        54\n",
      "     neutral       0.00      0.00      0.00         8\n",
      "    positive       0.88      0.83      0.85       225\n",
      "\n",
      "    accuracy                           0.76       287\n",
      "   macro avg       0.45      0.46      0.46       287\n",
      "weighted avg       0.78      0.76      0.77       287\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.37      0.54        54\n",
      "     neutral       0.00      0.00      0.00         8\n",
      "    positive       0.84      1.00      0.91       225\n",
      "\n",
      "    accuracy                           0.85       287\n",
      "   macro avg       0.61      0.46      0.49       287\n",
      "weighted avg       0.85      0.85      0.82       287\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.37      0.53        54\n",
      "     neutral       0.00      0.00      0.00         8\n",
      "    positive       0.84      1.00      0.91       225\n",
      "\n",
      "    accuracy                           0.85       287\n",
      "   macro avg       0.60      0.46      0.48       287\n",
      "weighted avg       0.84      0.85      0.82       287\n",
      "\n",
      "\n",
      "Aspect: aksesibilitas\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.25      0.39        48\n",
      "     neutral       0.00      0.00      0.00        23\n",
      "    positive       0.64      0.98      0.78       108\n",
      "\n",
      "    accuracy                           0.66       179\n",
      "   macro avg       0.50      0.41      0.39       179\n",
      "weighted avg       0.62      0.66      0.57       179\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.67      0.70        48\n",
      "     neutral       0.00      0.00      0.00        23\n",
      "    positive       0.74      0.92      0.82       108\n",
      "\n",
      "    accuracy                           0.73       179\n",
      "   macro avg       0.49      0.53      0.50       179\n",
      "weighted avg       0.64      0.73      0.68       179\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.62      0.54        48\n",
      "     neutral       0.28      0.22      0.24        23\n",
      "    positive       0.73      0.67      0.70       108\n",
      "\n",
      "    accuracy                           0.60       179\n",
      "   macro avg       0.50      0.50      0.49       179\n",
      "weighted avg       0.61      0.60      0.60       179\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.69      0.69        48\n",
      "     neutral       0.00      0.00      0.00        23\n",
      "    positive       0.73      0.88      0.80       108\n",
      "\n",
      "    accuracy                           0.72       179\n",
      "   macro avg       0.47      0.52      0.50       179\n",
      "weighted avg       0.63      0.72      0.67       179\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.67      0.68        48\n",
      "     neutral       0.50      0.04      0.08        23\n",
      "    positive       0.73      0.89      0.80       108\n",
      "\n",
      "    accuracy                           0.72       179\n",
      "   macro avg       0.64      0.53      0.52       179\n",
      "weighted avg       0.69      0.72      0.68       179\n",
      "\n",
      "\n",
      "Aspect: citra\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       109\n",
      "     neutral       0.00      0.00      0.00        40\n",
      "    positive       0.84      1.00      0.91       757\n",
      "\n",
      "    accuracy                           0.84       906\n",
      "   macro avg       0.28      0.33      0.30       906\n",
      "weighted avg       0.70      0.84      0.76       906\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.21      0.31       109\n",
      "     neutral       0.00      0.00      0.00        40\n",
      "    positive       0.86      0.98      0.92       757\n",
      "\n",
      "    accuracy                           0.85       906\n",
      "   macro avg       0.48      0.40      0.41       906\n",
      "weighted avg       0.79      0.85      0.80       906\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.40      0.39       109\n",
      "     neutral       0.05      0.05      0.05        40\n",
      "    positive       0.89      0.88      0.89       757\n",
      "\n",
      "    accuracy                           0.79       906\n",
      "   macro avg       0.44      0.45      0.44       906\n",
      "weighted avg       0.79      0.79      0.79       906\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.28      0.39       109\n",
      "     neutral       0.00      0.00      0.00        40\n",
      "    positive       0.87      0.98      0.92       757\n",
      "\n",
      "    accuracy                           0.85       906\n",
      "   macro avg       0.50      0.42      0.44       906\n",
      "weighted avg       0.80      0.85      0.82       906\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.54      0.18      0.27       109\n",
      "     neutral       0.00      0.00      0.00        40\n",
      "    positive       0.86      0.98      0.92       757\n",
      "\n",
      "    accuracy                           0.84       906\n",
      "   macro avg       0.47      0.39      0.40       906\n",
      "weighted avg       0.78      0.84      0.80       906\n",
      "\n",
      "\n",
      "Aspect: harga\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.58      0.66        81\n",
      "     neutral       0.52      0.93      0.67        74\n",
      "    positive       0.70      0.29      0.41        66\n",
      "\n",
      "    accuracy                           0.61       221\n",
      "   macro avg       0.66      0.60      0.58       221\n",
      "weighted avg       0.66      0.61      0.59       221\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.73      0.78        81\n",
      "     neutral       0.58      0.82      0.68        74\n",
      "    positive       0.71      0.48      0.58        66\n",
      "\n",
      "    accuracy                           0.69       221\n",
      "   macro avg       0.71      0.68      0.68       221\n",
      "weighted avg       0.71      0.69      0.69       221\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.57      0.60        81\n",
      "     neutral       0.62      0.61      0.61        74\n",
      "    positive       0.55      0.62      0.58        66\n",
      "\n",
      "    accuracy                           0.60       221\n",
      "   macro avg       0.60      0.60      0.60       221\n",
      "weighted avg       0.60      0.60      0.60       221\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.67      0.71        81\n",
      "     neutral       0.54      0.82      0.65        74\n",
      "    positive       0.70      0.39      0.50        66\n",
      "\n",
      "    accuracy                           0.64       221\n",
      "   macro avg       0.67      0.63      0.62       221\n",
      "weighted avg       0.67      0.64      0.63       221\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.63      0.68        81\n",
      "     neutral       0.52      0.76      0.62        74\n",
      "    positive       0.58      0.39      0.47        66\n",
      "\n",
      "    accuracy                           0.60       221\n",
      "   macro avg       0.61      0.59      0.59       221\n",
      "weighted avg       0.62      0.60      0.60       221\n",
      "\n",
      "\n",
      "Aspect: sdm\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        21\n",
      "     neutral       0.00      0.00      0.00         7\n",
      "    positive       0.73      1.00      0.85        77\n",
      "\n",
      "    accuracy                           0.73       105\n",
      "   macro avg       0.24      0.33      0.28       105\n",
      "weighted avg       0.54      0.73      0.62       105\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25        21\n",
      "     neutral       0.00      0.00      0.00         7\n",
      "    positive       0.75      1.00      0.86        77\n",
      "\n",
      "    accuracy                           0.76       105\n",
      "   macro avg       0.58      0.38      0.37       105\n",
      "weighted avg       0.75      0.76      0.68       105\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.47      0.38      0.42        21\n",
      "     neutral       0.25      0.14      0.18         7\n",
      "    positive       0.82      0.90      0.86        77\n",
      "\n",
      "    accuracy                           0.74       105\n",
      "   macro avg       0.51      0.47      0.49       105\n",
      "weighted avg       0.71      0.74      0.72       105\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25        21\n",
      "     neutral       0.00      0.00      0.00         7\n",
      "    positive       0.75      1.00      0.86        77\n",
      "\n",
      "    accuracy                           0.76       105\n",
      "   macro avg       0.58      0.38      0.37       105\n",
      "weighted avg       0.75      0.76      0.68       105\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.19      0.32        21\n",
      "     neutral       0.00      0.00      0.00         7\n",
      "    positive       0.76      1.00      0.87        77\n",
      "\n",
      "    accuracy                           0.77       105\n",
      "   macro avg       0.59      0.40      0.40       105\n",
      "weighted avg       0.76      0.77      0.70       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Melakukan pelatihan dan evaluasi model untuk setiap aspek dan setiap algoritma\n",
    "for aspect, df_aspect in dfs_melted_df.items():\n",
    "    print(f'\\nAspect: {aspect}')\n",
    "    # Membagi data menjadi data latih dan data uji\n",
    "    X = df_aspect['text']\n",
    "    y = df_aspect['sentiment']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    for clf_name, clf in classifiers.items():\n",
    "        # Membuat pipeline dengan TfidfVectorizer dan classifier\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(max_features=100000)),\n",
    "            ('clf', clf)\n",
    "        ])\n",
    "        # Melakukan pelatihan model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Melakukan prediksi\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        # Evaluasi model\n",
    "        print(f'\\nClassification Report with {clf_name}:')\n",
    "        print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aspect: daya_tarik\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        56\n",
      "     neutral       0.00      0.00      0.00       345\n",
      "    positive       0.93      1.00      0.97      5561\n",
      "\n",
      "    accuracy                           0.93      5962\n",
      "   macro avg       0.31      0.33      0.32      5962\n",
      "weighted avg       0.87      0.93      0.90      5962\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        56\n",
      "     neutral       0.62      0.01      0.03       345\n",
      "    positive       0.93      1.00      0.97      5561\n",
      "\n",
      "    accuracy                           0.93      5962\n",
      "   macro avg       0.52      0.34      0.33      5962\n",
      "weighted avg       0.91      0.93      0.90      5962\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.04      0.04      0.04        56\n",
      "     neutral       0.12      0.12      0.12       345\n",
      "    positive       0.94      0.94      0.94      5561\n",
      "\n",
      "    accuracy                           0.89      5962\n",
      "   macro avg       0.37      0.36      0.37      5962\n",
      "weighted avg       0.88      0.89      0.88      5962\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        56\n",
      "     neutral       0.35      0.02      0.04       345\n",
      "    positive       0.93      1.00      0.96      5561\n",
      "\n",
      "    accuracy                           0.93      5962\n",
      "   macro avg       0.43      0.34      0.33      5962\n",
      "weighted avg       0.89      0.93      0.90      5962\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        56\n",
      "     neutral       0.26      0.03      0.05       345\n",
      "    positive       0.93      0.99      0.96      5561\n",
      "\n",
      "    accuracy                           0.93      5962\n",
      "   macro avg       0.40      0.34      0.34      5962\n",
      "weighted avg       0.89      0.93      0.90      5962\n",
      "\n",
      "\n",
      "Aspect: amenitas\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       245\n",
      "     neutral       0.00      0.00      0.00        47\n",
      "    positive       0.80      1.00      0.89      1141\n",
      "\n",
      "    accuracy                           0.80      1433\n",
      "   macro avg       0.27      0.33      0.30      1433\n",
      "weighted avg       0.63      0.80      0.71      1433\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.17      0.29       245\n",
      "     neutral       0.00      0.00      0.00        47\n",
      "    positive       0.82      1.00      0.90      1141\n",
      "\n",
      "    accuracy                           0.82      1433\n",
      "   macro avg       0.59      0.39      0.40      1433\n",
      "weighted avg       0.82      0.82      0.77      1433\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.45      0.44       245\n",
      "     neutral       0.06      0.06      0.06        47\n",
      "    positive       0.86      0.85      0.85      1141\n",
      "\n",
      "    accuracy                           0.75      1433\n",
      "   macro avg       0.45      0.45      0.45      1433\n",
      "weighted avg       0.76      0.75      0.76      1433\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.25      0.39       245\n",
      "     neutral       0.00      0.00      0.00        47\n",
      "    positive       0.83      0.99      0.90      1141\n",
      "\n",
      "    accuracy                           0.83      1433\n",
      "   macro avg       0.55      0.41      0.43      1433\n",
      "weighted avg       0.80      0.83      0.79      1433\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.33      0.48       245\n",
      "     neutral       0.00      0.00      0.00        47\n",
      "    positive       0.84      0.99      0.91      1141\n",
      "\n",
      "    accuracy                           0.84      1433\n",
      "   macro avg       0.56      0.44      0.46      1433\n",
      "weighted avg       0.81      0.84      0.81      1433\n",
      "\n",
      "\n",
      "Aspect: aksesibilitas\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.20      0.33       277\n",
      "     neutral       0.00      0.00      0.00       127\n",
      "    positive       0.58      1.00      0.74       488\n",
      "\n",
      "    accuracy                           0.61       892\n",
      "   macro avg       0.51      0.40      0.35       892\n",
      "weighted avg       0.61      0.61      0.50       892\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71       277\n",
      "     neutral       0.80      0.03      0.06       127\n",
      "    positive       0.69      0.96      0.80       488\n",
      "\n",
      "    accuracy                           0.72       892\n",
      "   macro avg       0.77      0.54      0.52       892\n",
      "weighted avg       0.75      0.72      0.67       892\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.57      0.61       277\n",
      "     neutral       0.28      0.30      0.29       127\n",
      "    positive       0.68      0.72      0.70       488\n",
      "\n",
      "    accuracy                           0.61       892\n",
      "   macro avg       0.54      0.53      0.53       892\n",
      "weighted avg       0.61      0.61      0.61       892\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.63      0.69       277\n",
      "     neutral       0.75      0.02      0.05       127\n",
      "    positive       0.69      0.93      0.79       488\n",
      "\n",
      "    accuracy                           0.71       892\n",
      "   macro avg       0.74      0.53      0.51       892\n",
      "weighted avg       0.72      0.71      0.66       892\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.64      0.71       277\n",
      "     neutral       0.71      0.04      0.07       127\n",
      "    positive       0.69      0.94      0.80       488\n",
      "\n",
      "    accuracy                           0.72       892\n",
      "   macro avg       0.73      0.54      0.53       892\n",
      "weighted avg       0.72      0.72      0.67       892\n",
      "\n",
      "\n",
      "Aspect: citra\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       560\n",
      "     neutral       0.00      0.00      0.00       159\n",
      "    positive       0.84      1.00      0.91      3811\n",
      "\n",
      "    accuracy                           0.84      4530\n",
      "   macro avg       0.28      0.33      0.30      4530\n",
      "weighted avg       0.71      0.84      0.77      4530\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.22      0.34       560\n",
      "     neutral       0.00      0.00      0.00       159\n",
      "    positive       0.87      0.99      0.93      3811\n",
      "\n",
      "    accuracy                           0.86      4530\n",
      "   macro avg       0.52      0.40      0.42      4530\n",
      "weighted avg       0.82      0.86      0.82      4530\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.39      0.37      0.38       560\n",
      "     neutral       0.11      0.09      0.10       159\n",
      "    positive       0.89      0.90      0.90      3811\n",
      "\n",
      "    accuracy                           0.81      4530\n",
      "   macro avg       0.46      0.45      0.46      4530\n",
      "weighted avg       0.80      0.81      0.80      4530\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.21      0.31       560\n",
      "     neutral       0.33      0.01      0.01       159\n",
      "    positive       0.87      0.99      0.92      3811\n",
      "\n",
      "    accuracy                           0.86      4530\n",
      "   macro avg       0.62      0.40      0.42      4530\n",
      "weighted avg       0.82      0.86      0.82      4530\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.22      0.33       560\n",
      "     neutral       0.25      0.01      0.02       159\n",
      "    positive       0.87      0.99      0.93      3811\n",
      "\n",
      "    accuracy                           0.86      4530\n",
      "   macro avg       0.61      0.41      0.43      4530\n",
      "weighted avg       0.83      0.86      0.82      4530\n",
      "\n",
      "\n",
      "Aspect: harga\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.62      0.61       362\n",
      "     neutral       0.52      0.78      0.63       411\n",
      "    positive       0.70      0.25      0.37       330\n",
      "\n",
      "    accuracy                           0.57      1103\n",
      "   macro avg       0.61      0.55      0.54      1103\n",
      "weighted avg       0.60      0.57      0.54      1103\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.73      0.72       362\n",
      "     neutral       0.59      0.76      0.67       411\n",
      "    positive       0.68      0.43      0.53       330\n",
      "\n",
      "    accuracy                           0.65      1103\n",
      "   macro avg       0.66      0.64      0.64      1103\n",
      "weighted avg       0.66      0.65      0.64      1103\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.65      0.66       362\n",
      "     neutral       0.60      0.62      0.61       411\n",
      "    positive       0.55      0.53      0.54       330\n",
      "\n",
      "    accuracy                           0.60      1103\n",
      "   macro avg       0.60      0.60      0.60      1103\n",
      "weighted avg       0.60      0.60      0.60      1103\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.77      0.72       362\n",
      "     neutral       0.60      0.75      0.67       411\n",
      "    positive       0.72      0.41      0.52       330\n",
      "\n",
      "    accuracy                           0.65      1103\n",
      "   macro avg       0.67      0.64      0.64      1103\n",
      "weighted avg       0.66      0.65      0.64      1103\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.78      0.71       362\n",
      "     neutral       0.58      0.69      0.63       411\n",
      "    positive       0.69      0.38      0.49       330\n",
      "\n",
      "    accuracy                           0.62      1103\n",
      "   macro avg       0.64      0.61      0.61      1103\n",
      "weighted avg       0.63      0.62      0.61      1103\n",
      "\n",
      "\n",
      "Aspect: sdm\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       118\n",
      "     neutral       0.00      0.00      0.00        27\n",
      "    positive       0.72      1.00      0.84       376\n",
      "\n",
      "    accuracy                           0.72       521\n",
      "   macro avg       0.24      0.33      0.28       521\n",
      "weighted avg       0.52      0.72      0.61       521\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.14      0.23       118\n",
      "     neutral       0.00      0.00      0.00        27\n",
      "    positive       0.74      0.99      0.85       376\n",
      "\n",
      "    accuracy                           0.74       521\n",
      "   macro avg       0.50      0.37      0.36       521\n",
      "weighted avg       0.71      0.74      0.66       521\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.50      0.53       118\n",
      "     neutral       0.07      0.04      0.05        27\n",
      "    positive       0.80      0.86      0.83       376\n",
      "\n",
      "    accuracy                           0.73       521\n",
      "   macro avg       0.48      0.46      0.47       521\n",
      "weighted avg       0.71      0.73      0.72       521\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.17      0.28       118\n",
      "     neutral       0.00      0.00      0.00        27\n",
      "    positive       0.75      0.98      0.85       376\n",
      "\n",
      "    accuracy                           0.74       521\n",
      "   macro avg       0.50      0.38      0.37       521\n",
      "weighted avg       0.71      0.74      0.67       521\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.24      0.36       118\n",
      "     neutral       0.00      0.00      0.00        27\n",
      "    positive       0.76      0.97      0.85       376\n",
      "\n",
      "    accuracy                           0.76       521\n",
      "   macro avg       0.49      0.40      0.40       521\n",
      "weighted avg       0.71      0.76      0.70       521\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Melakukan pelatihan dan evaluasi model untuk setiap aspek dan setiap algoritma dengan cross-validation\n",
    "for aspect, df_aspect in dfs_melted_df.items():\n",
    "    print(f'\\nAspect: {aspect}')\n",
    "    # Membagi data menjadi fitur (X) dan target (y)\n",
    "    X = df_aspect['text']\n",
    "    y = df_aspect['sentiment']\n",
    "    \n",
    "    for clf_name, clf in classifiers.items():\n",
    "        # Membuat pipeline dengan TfidfVectorizer dan classifier\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(max_features=100000)),\n",
    "            ('clf', clf)\n",
    "        ])\n",
    "        \n",
    "        # Menggunakan cross-validation untuk menghasilkan prediksi\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        y_pred = cross_val_predict(pipeline, X, y, cv=skf)\n",
    "\n",
    "        # Evaluasi model\n",
    "        print(f'\\nClassification Report with {clf_name}:')\n",
    "        print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pemodelan Topik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluasi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

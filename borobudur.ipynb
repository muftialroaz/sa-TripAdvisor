{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset for Aspect-Based Sentiment Analysis and Topic Modeling on Borobudur Temple and Prambanan Temple by Dian Arianto\n",
    "https://github.com/dian9395/dataset-analisis-sentimen-berbasis-aspek-dan-pemodelan-topik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('dataset/reviews_borobudur_prambanan_TripAdvisor_GMaps_all_tesis.xlsx')\n",
    "df_clean = df.dropna()\n",
    "# print(\"\\nDrop rows with any NaN values:\")\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = df_clean['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Emoji processing; case folding; menghapus username, angka, dan tanda baca; koreksi ejaan dan singkatan serta menghapus whitespace; penghapusan stopwords, dan stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Daftar emoji berdasarkan sentimen\n",
    "emoji_positif = [\"😊\", \"😄\", \"♥\", \"😍\", \"😘\", \"😃\", \"😁\", \"😆\", \"😇\", \"☺\"]\n",
    "emoji_negatif = [\"😢\", \"😠\", \"😡\", \"😭\", \"😱\", \"😨\", \"😫\", \"😩\", \"😖\", \"😔\"]\n",
    "emoji_netral = [\"👍\", \"✨\", \"★\", \"█\", \"👌\", \"♫\", \"�\", \"©\", \"💬\", \"🔔\"]\n",
    "\n",
    "# Fungsi untuk mengganti emoji dengan label sentimen\n",
    "def emotion(teks):\n",
    "    for emoji in emoji_positif:\n",
    "        teks = teks.replace(emoji, \"positif\")\n",
    "    for emoji in emoji_negatif:\n",
    "        teks = teks.replace(emoji, \"negatif\")\n",
    "    for emoji in emoji_netral:\n",
    "        teks = teks.replace(emoji, \"netral\")\n",
    "    return teks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1qqSuE1tuDCCfsdKgXMC3Nj0jda1LuWXB\n",
      "To: /home/muftialroaz/Documents/python-pro/sa-TripAdvisor/stopwords_uci.txt\n",
      "100%|██████████| 6.91k/6.91k [00:00<00:00, 11.2MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Ufurgc02rF2_yuFh8GNw1VOpkNbJLKWx\n",
      "To: /home/muftialroaz/Documents/python-pro/sa-TripAdvisor/stopwords_nltk.txt\n",
      "100%|██████████| 7.39k/7.39k [00:00<00:00, 409kB/s]\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "# URL dari file Google Drive\n",
    "stopwords_uci_link = 'https://drive.google.com/uc?id=1qqSuE1tuDCCfsdKgXMC3Nj0jda1LuWXB'\n",
    "stopwords_nltk_link = 'https://drive.google.com/uc?id=1Ufurgc02rF2_yuFh8GNw1VOpkNbJLKWx'\n",
    "stopwords_uci_output = 'stopwords_uci.txt'\n",
    "stopwords_nltk_output = 'stopwords_nltk.txt'\n",
    "# Mengunduh file\n",
    "gdown.download(stopwords_uci_link, stopwords_uci_output, quiet=False)\n",
    "gdown.download(stopwords_nltk_link, stopwords_nltk_output, quiet=False)\n",
    "# Membaca konten file\n",
    "with open(stopwords_uci_output, 'r', encoding='utf-8') as file:\n",
    "    stopwords_uci = file.read()\n",
    "with open(stopwords_nltk_output, 'r', encoding='utf-8') as file:\n",
    "    stopwords_nltk = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # text preprocessing\n",
    "    teks = emotion(text)\n",
    "    teks = teks.lower()\n",
    "    teks = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    stop_words = set(stopwords.words('english') + stopwords_uci.split('\\n') + stopwords_nltk.split('\\n'))\n",
    "    tokens = word_tokenize(teks)\n",
    "    filtered_tokens = [word for word in tokens if word.isalnum() and not any(char.isdigit() for char in word) and word not in stop_words]\n",
    "    stemmer_factory = StemmerFactory()\n",
    "    sastrawi_stemmer = stemmer_factory.create_stemmer()\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    lemma = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    indonesian_stemmed_words = [sastrawi_stemmer.stem(word) for word in lemma]\n",
    "    clean_reviews = ' '.join(indonesian_stemmed_words)\n",
    "    return clean_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       tinggal sejarah umur indonesia bangsa indonesi...\n",
       "1       pertama kali pergi pandemi candi borobudur pro...\n",
       "2       candi borobudur magelang yogyakarta salah reko...\n",
       "3       baru kali kesini pa sih ajaib dunia sulit baya...\n",
       "4       candi borobudur wisata kenal dunia ganti sy wi...\n",
       "                              ...                        \n",
       "6738    the place great probably everything expect how...\n",
       "6739    prambanan rara jonggrang javanese romanized ra...\n",
       "6740    this temple worth price theres much see poorly...\n",
       "6741    prambanan temple largest hindu temple ancient ...\n",
       "6742    best choice three mostfamous temple yogyakarta...\n",
       "Name: text, Length: 6743, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teks = review.apply(preprocess)\n",
    "teks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ekstraksi Fitur\n",
    "words n-gram. words unigram+bigram+trigram untuk fiturnya dan vektornya diekstraksi dengan CountVectorizer dari pustaka Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eksperimen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis Sentimen Berbasis Aspek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import resample\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>daya_tarik</th>\n",
       "      <th>amenitas</th>\n",
       "      <th>aksesibilitas</th>\n",
       "      <th>citra</th>\n",
       "      <th>harga</th>\n",
       "      <th>sdm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tinggal sejarah umur indonesia bangsa indonesi...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pertama kali pergi pandemi candi borobudur pro...</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>candi borobudur magelang yogyakarta salah reko...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baru kali kesini pa sih ajaib dunia sulit baya...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>candi borobudur wisata kenal dunia ganti sy wi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text daya_tarik amenitas  \\\n",
       "0  tinggal sejarah umur indonesia bangsa indonesi...          1        -   \n",
       "1  pertama kali pergi pandemi candi borobudur pro...          -        1   \n",
       "2  candi borobudur magelang yogyakarta salah reko...          1        -   \n",
       "3  baru kali kesini pa sih ajaib dunia sulit baya...          1        -   \n",
       "4  candi borobudur wisata kenal dunia ganti sy wi...          1        1   \n",
       "\n",
       "  aksesibilitas citra harga sdm  \n",
       "0             -     1     0   0  \n",
       "1             -     1     -   1  \n",
       "2             -     1     -   -  \n",
       "3             -     -    -1   -  \n",
       "4             -     1     -   -  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess = pd.concat([pd.DataFrame(teks), df_clean['daya_tarik'], df_clean['amenitas'], df_clean['aksesibilitas'], df_clean['citra'], df_clean['harga'], df_clean['sdm']], axis=1)\n",
    "preprocess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tinggal sejarah umur indonesia bangsa indonesi...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>candi borobudur magelang yogyakarta salah reko...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baru kali kesini pa sih ajaib dunia sulit baya...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>candi borobudur wisata kenal dunia ganti sy wi...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wajar salah ajaib dunia candi bangun tingkat t...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      aspect sentiment\n",
       "0  tinggal sejarah umur indonesia bangsa indonesi...  daya_tarik         1\n",
       "2  candi borobudur magelang yogyakarta salah reko...  daya_tarik         1\n",
       "3  baru kali kesini pa sih ajaib dunia sulit baya...  daya_tarik         1\n",
       "4  candi borobudur wisata kenal dunia ganti sy wi...  daya_tarik         1\n",
       "5  wajar salah ajaib dunia candi bangun tingkat t...  daya_tarik         1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Melakukan melting pada dataframe\n",
    "melted_df = preprocess.melt(id_vars=['text'], value_vars=['daya_tarik', 'amenitas', 'aksesibilitas', 'citra', 'harga', 'sdm'],\n",
    "                    var_name='aspect', value_name='sentiment')\n",
    "# Menghapus baris dengan nilai '-' pada kolom sentiment\n",
    "melted_df = melted_df[melted_df['sentiment'] != '-']\n",
    "\n",
    "melted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tinggal sejarah umur indonesia bangsa indonesi...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>candi borobudur magelang yogyakarta salah reko...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baru kali kesini pa sih ajaib dunia sulit baya...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>candi borobudur wisata kenal dunia ganti sy wi...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wajar salah ajaib dunia candi bangun tingkat t...</td>\n",
       "      <td>daya_tarik</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      aspect sentiment\n",
       "0  tinggal sejarah umur indonesia bangsa indonesi...  daya_tarik  positive\n",
       "2  candi borobudur magelang yogyakarta salah reko...  daya_tarik  positive\n",
       "3  baru kali kesini pa sih ajaib dunia sulit baya...  daya_tarik  positive\n",
       "4  candi borobudur wisata kenal dunia ganti sy wi...  daya_tarik  positive\n",
       "5  wajar salah ajaib dunia candi bangun tingkat t...  daya_tarik  positive"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mengubah nilai sentiment\n",
    "sentiment_mapping = {1: 'positive', 0: 'neutral', -1: 'negative'}\n",
    "melted_df['sentiment'] = melted_df['sentiment'].astype(int).map(sentiment_mapping)\n",
    "melted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memisahkan dataframe berdasarkan aspek\n",
    "dfs_melted_df = {aspect: melted_df[melted_df['aspect'] == aspect] for aspect in melted_df['aspect'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daftar algoritma klasifikasi\n",
    "classifiers = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Extra Trees': ExtraTreesClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aspect: daya_tarik\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         9\n",
      "     neutral       0.00      0.00      0.00        64\n",
      "    positive       0.94      1.00      0.97      1120\n",
      "\n",
      "    accuracy                           0.94      1193\n",
      "   macro avg       0.31      0.33      0.32      1193\n",
      "weighted avg       0.88      0.94      0.91      1193\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         9\n",
      "     neutral       0.40      0.03      0.06        64\n",
      "    positive       0.94      1.00      0.97      1120\n",
      "\n",
      "    accuracy                           0.94      1193\n",
      "   macro avg       0.45      0.34      0.34      1193\n",
      "weighted avg       0.90      0.94      0.91      1193\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         9\n",
      "     neutral       0.05      0.05      0.05        64\n",
      "    positive       0.94      0.95      0.94      1120\n",
      "\n",
      "    accuracy                           0.89      1193\n",
      "   macro avg       0.33      0.33      0.33      1193\n",
      "weighted avg       0.88      0.89      0.89      1193\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         9\n",
      "     neutral       0.17      0.02      0.03        64\n",
      "    positive       0.94      1.00      0.97      1120\n",
      "\n",
      "    accuracy                           0.94      1193\n",
      "   macro avg       0.37      0.34      0.33      1193\n",
      "weighted avg       0.89      0.94      0.91      1193\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         9\n",
      "     neutral       0.12      0.02      0.03        64\n",
      "    positive       0.94      0.99      0.97      1120\n",
      "\n",
      "    accuracy                           0.93      1193\n",
      "   macro avg       0.35      0.34      0.33      1193\n",
      "weighted avg       0.89      0.93      0.91      1193\n",
      "\n",
      "\n",
      "Aspect: amenitas\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.00      0.00      0.00         8\n",
      "    positive       0.78      1.00      0.88       225\n",
      "\n",
      "    accuracy                           0.78       287\n",
      "   macro avg       0.26      0.33      0.29       287\n",
      "weighted avg       0.61      0.78      0.69       287\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.24      0.39        54\n",
      "     neutral       0.00      0.00      0.00         8\n",
      "    positive       0.82      1.00      0.90       225\n",
      "\n",
      "    accuracy                           0.83       287\n",
      "   macro avg       0.61      0.41      0.43       287\n",
      "weighted avg       0.83      0.83      0.78       287\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.54      0.56      0.55        54\n",
      "     neutral       0.00      0.00      0.00         8\n",
      "    positive       0.88      0.84      0.86       225\n",
      "\n",
      "    accuracy                           0.76       287\n",
      "   macro avg       0.47      0.47      0.47       287\n",
      "weighted avg       0.79      0.76      0.77       287\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.41      0.58        54\n",
      "     neutral       0.00      0.00      0.00         8\n",
      "    positive       0.85      1.00      0.92       225\n",
      "\n",
      "    accuracy                           0.86       287\n",
      "   macro avg       0.62      0.47      0.50       287\n",
      "weighted avg       0.85      0.86      0.83       287\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.35      0.52        54\n",
      "     neutral       0.00      0.00      0.00         8\n",
      "    positive       0.84      1.00      0.91       225\n",
      "\n",
      "    accuracy                           0.85       287\n",
      "   macro avg       0.61      0.45      0.48       287\n",
      "weighted avg       0.85      0.85      0.81       287\n",
      "\n",
      "\n",
      "Aspect: aksesibilitas\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.25      0.39        48\n",
      "     neutral       0.00      0.00      0.00        23\n",
      "    positive       0.64      0.98      0.78       108\n",
      "\n",
      "    accuracy                           0.66       179\n",
      "   macro avg       0.50      0.41      0.39       179\n",
      "weighted avg       0.62      0.66      0.57       179\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.67      0.70        48\n",
      "     neutral       0.00      0.00      0.00        23\n",
      "    positive       0.74      0.92      0.82       108\n",
      "\n",
      "    accuracy                           0.73       179\n",
      "   macro avg       0.49      0.53      0.50       179\n",
      "weighted avg       0.64      0.73      0.68       179\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.58      0.53        48\n",
      "     neutral       0.27      0.26      0.27        23\n",
      "    positive       0.74      0.68      0.71       108\n",
      "\n",
      "    accuracy                           0.60       179\n",
      "   macro avg       0.50      0.51      0.50       179\n",
      "weighted avg       0.61      0.60      0.60       179\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.67      0.69        48\n",
      "     neutral       0.00      0.00      0.00        23\n",
      "    positive       0.73      0.91      0.81       108\n",
      "\n",
      "    accuracy                           0.73       179\n",
      "   macro avg       0.48      0.52      0.50       179\n",
      "weighted avg       0.63      0.73      0.67       179\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.71      0.70        48\n",
      "     neutral       0.33      0.04      0.08        23\n",
      "    positive       0.75      0.88      0.81       108\n",
      "\n",
      "    accuracy                           0.73       179\n",
      "   macro avg       0.59      0.54      0.53       179\n",
      "weighted avg       0.68      0.73      0.69       179\n",
      "\n",
      "\n",
      "Aspect: citra\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       109\n",
      "     neutral       0.00      0.00      0.00        40\n",
      "    positive       0.84      1.00      0.91       757\n",
      "\n",
      "    accuracy                           0.84       906\n",
      "   macro avg       0.28      0.33      0.30       906\n",
      "weighted avg       0.70      0.84      0.76       906\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.21      0.31       109\n",
      "     neutral       0.00      0.00      0.00        40\n",
      "    positive       0.86      0.98      0.92       757\n",
      "\n",
      "    accuracy                           0.85       906\n",
      "   macro avg       0.48      0.40      0.41       906\n",
      "weighted avg       0.79      0.85      0.80       906\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.46      0.44       109\n",
      "     neutral       0.06      0.05      0.05        40\n",
      "    positive       0.90      0.89      0.89       757\n",
      "\n",
      "    accuracy                           0.80       906\n",
      "   macro avg       0.46      0.47      0.46       906\n",
      "weighted avg       0.80      0.80      0.80       906\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.28      0.38       109\n",
      "     neutral       0.00      0.00      0.00        40\n",
      "    positive       0.87      0.98      0.92       757\n",
      "\n",
      "    accuracy                           0.86       906\n",
      "   macro avg       0.50      0.42      0.44       906\n",
      "weighted avg       0.80      0.86      0.82       906\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.21      0.32       109\n",
      "     neutral       0.00      0.00      0.00        40\n",
      "    positive       0.86      0.99      0.92       757\n",
      "\n",
      "    accuracy                           0.85       906\n",
      "   macro avg       0.49      0.40      0.41       906\n",
      "weighted avg       0.79      0.85      0.81       906\n",
      "\n",
      "\n",
      "Aspect: harga\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.58      0.66        81\n",
      "     neutral       0.52      0.93      0.67        74\n",
      "    positive       0.70      0.29      0.41        66\n",
      "\n",
      "    accuracy                           0.61       221\n",
      "   macro avg       0.66      0.60      0.58       221\n",
      "weighted avg       0.66      0.61      0.59       221\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.73      0.78        81\n",
      "     neutral       0.58      0.82      0.68        74\n",
      "    positive       0.71      0.48      0.58        66\n",
      "\n",
      "    accuracy                           0.69       221\n",
      "   macro avg       0.71      0.68      0.68       221\n",
      "weighted avg       0.71      0.69      0.69       221\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.58      0.61        81\n",
      "     neutral       0.56      0.61      0.58        74\n",
      "    positive       0.53      0.53      0.53        66\n",
      "\n",
      "    accuracy                           0.57       221\n",
      "   macro avg       0.57      0.57      0.57       221\n",
      "weighted avg       0.58      0.57      0.58       221\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.67      0.70        81\n",
      "     neutral       0.57      0.80      0.66        74\n",
      "    positive       0.64      0.42      0.51        66\n",
      "\n",
      "    accuracy                           0.64       221\n",
      "   macro avg       0.65      0.63      0.62       221\n",
      "weighted avg       0.65      0.64      0.63       221\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.57      0.64        81\n",
      "     neutral       0.52      0.78      0.62        74\n",
      "    positive       0.62      0.44      0.51        66\n",
      "\n",
      "    accuracy                           0.60       221\n",
      "   macro avg       0.63      0.60      0.59       221\n",
      "weighted avg       0.63      0.60      0.60       221\n",
      "\n",
      "\n",
      "Aspect: sdm\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        21\n",
      "     neutral       0.00      0.00      0.00         7\n",
      "    positive       0.73      1.00      0.85        77\n",
      "\n",
      "    accuracy                           0.73       105\n",
      "   macro avg       0.24      0.33      0.28       105\n",
      "weighted avg       0.54      0.73      0.62       105\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25        21\n",
      "     neutral       0.00      0.00      0.00         7\n",
      "    positive       0.75      1.00      0.86        77\n",
      "\n",
      "    accuracy                           0.76       105\n",
      "   macro avg       0.58      0.38      0.37       105\n",
      "weighted avg       0.75      0.76      0.68       105\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.26      0.24      0.25        21\n",
      "     neutral       0.00      0.00      0.00         7\n",
      "    positive       0.76      0.83      0.80        77\n",
      "\n",
      "    accuracy                           0.66       105\n",
      "   macro avg       0.34      0.36      0.35       105\n",
      "weighted avg       0.61      0.66      0.63       105\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.19      0.31        21\n",
      "     neutral       0.00      0.00      0.00         7\n",
      "    positive       0.76      0.99      0.86        77\n",
      "\n",
      "    accuracy                           0.76       105\n",
      "   macro avg       0.52      0.39      0.39       105\n",
      "weighted avg       0.72      0.76      0.69       105\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44        21\n",
      "     neutral       0.00      0.00      0.00         7\n",
      "    positive       0.78      1.00      0.88        77\n",
      "\n",
      "    accuracy                           0.79       105\n",
      "   macro avg       0.59      0.43      0.44       105\n",
      "weighted avg       0.77      0.79      0.73       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Melakukan pelatihan dan evaluasi model untuk setiap aspek dan setiap algoritma\n",
    "for aspect, df_aspect in dfs_melted_df.items():\n",
    "    print(f'\\nAspect: {aspect}')\n",
    "    # Membagi data menjadi data latih dan data uji\n",
    "    X = df_aspect['text']\n",
    "    y = df_aspect['sentiment']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    for clf_name, clf in classifiers.items():\n",
    "        # Membuat pipeline dengan TfidfVectorizer dan classifier\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(max_features=100000)),\n",
    "            ('clf', clf)\n",
    "        ])\n",
    "        # Melakukan pelatihan model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Melakukan prediksi\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        # Evaluasi model\n",
    "        print(f'\\nClassification Report with {clf_name}:')\n",
    "        print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aspect: daya_tarik\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        56\n",
      "     neutral       0.00      0.00      0.00       345\n",
      "    positive       0.93      1.00      0.97      5561\n",
      "\n",
      "    accuracy                           0.93      5962\n",
      "   macro avg       0.31      0.33      0.32      5962\n",
      "weighted avg       0.87      0.93      0.90      5962\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        56\n",
      "     neutral       0.62      0.01      0.03       345\n",
      "    positive       0.93      1.00      0.97      5561\n",
      "\n",
      "    accuracy                           0.93      5962\n",
      "   macro avg       0.52      0.34      0.33      5962\n",
      "weighted avg       0.91      0.93      0.90      5962\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.02      0.02      0.02        56\n",
      "     neutral       0.13      0.12      0.12       345\n",
      "    positive       0.94      0.94      0.94      5561\n",
      "\n",
      "    accuracy                           0.89      5962\n",
      "   macro avg       0.36      0.36      0.36      5962\n",
      "weighted avg       0.88      0.89      0.88      5962\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        56\n",
      "     neutral       0.36      0.02      0.04       345\n",
      "    positive       0.93      1.00      0.96      5561\n",
      "\n",
      "    accuracy                           0.93      5962\n",
      "   macro avg       0.43      0.34      0.34      5962\n",
      "weighted avg       0.89      0.93      0.90      5962\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        56\n",
      "     neutral       0.26      0.03      0.05       345\n",
      "    positive       0.93      0.99      0.96      5561\n",
      "\n",
      "    accuracy                           0.93      5962\n",
      "   macro avg       0.40      0.34      0.34      5962\n",
      "weighted avg       0.89      0.93      0.90      5962\n",
      "\n",
      "\n",
      "Aspect: amenitas\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       245\n",
      "     neutral       0.00      0.00      0.00        47\n",
      "    positive       0.80      1.00      0.89      1141\n",
      "\n",
      "    accuracy                           0.80      1433\n",
      "   macro avg       0.27      0.33      0.30      1433\n",
      "weighted avg       0.63      0.80      0.71      1433\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.17      0.29       245\n",
      "     neutral       0.00      0.00      0.00        47\n",
      "    positive       0.82      1.00      0.90      1141\n",
      "\n",
      "    accuracy                           0.82      1433\n",
      "   macro avg       0.59      0.39      0.40      1433\n",
      "weighted avg       0.82      0.82      0.77      1433\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.42      0.44      0.43       245\n",
      "     neutral       0.08      0.06      0.07        47\n",
      "    positive       0.86      0.85      0.85      1141\n",
      "\n",
      "    accuracy                           0.76      1433\n",
      "   macro avg       0.45      0.45      0.45      1433\n",
      "weighted avg       0.76      0.76      0.76      1433\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.27      0.40       245\n",
      "     neutral       0.00      0.00      0.00        47\n",
      "    positive       0.83      0.99      0.90      1141\n",
      "\n",
      "    accuracy                           0.83      1433\n",
      "   macro avg       0.55      0.42      0.43      1433\n",
      "weighted avg       0.80      0.83      0.79      1433\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.33      0.47       245\n",
      "     neutral       0.00      0.00      0.00        47\n",
      "    positive       0.84      0.99      0.91      1141\n",
      "\n",
      "    accuracy                           0.84      1433\n",
      "   macro avg       0.56      0.44      0.46      1433\n",
      "weighted avg       0.82      0.84      0.81      1433\n",
      "\n",
      "\n",
      "Aspect: aksesibilitas\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.20      0.33       277\n",
      "     neutral       0.00      0.00      0.00       127\n",
      "    positive       0.58      1.00      0.74       488\n",
      "\n",
      "    accuracy                           0.61       892\n",
      "   macro avg       0.51      0.40      0.35       892\n",
      "weighted avg       0.61      0.61      0.50       892\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71       277\n",
      "     neutral       0.80      0.03      0.06       127\n",
      "    positive       0.69      0.96      0.80       488\n",
      "\n",
      "    accuracy                           0.72       892\n",
      "   macro avg       0.77      0.54      0.52       892\n",
      "weighted avg       0.75      0.72      0.67       892\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.59      0.61       277\n",
      "     neutral       0.29      0.30      0.29       127\n",
      "    positive       0.69      0.71      0.70       488\n",
      "\n",
      "    accuracy                           0.62       892\n",
      "   macro avg       0.54      0.53      0.54       892\n",
      "weighted avg       0.62      0.62      0.62       892\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.62      0.70       277\n",
      "     neutral       0.80      0.03      0.06       127\n",
      "    positive       0.69      0.94      0.79       488\n",
      "\n",
      "    accuracy                           0.71       892\n",
      "   macro avg       0.76      0.53      0.52       892\n",
      "weighted avg       0.73      0.71      0.66       892\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.64      0.70       277\n",
      "     neutral       0.57      0.03      0.06       127\n",
      "    positive       0.69      0.93      0.79       488\n",
      "\n",
      "    accuracy                           0.71       892\n",
      "   macro avg       0.68      0.53      0.52       892\n",
      "weighted avg       0.70      0.71      0.66       892\n",
      "\n",
      "\n",
      "Aspect: citra\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       560\n",
      "     neutral       0.00      0.00      0.00       159\n",
      "    positive       0.84      1.00      0.91      3811\n",
      "\n",
      "    accuracy                           0.84      4530\n",
      "   macro avg       0.28      0.33      0.30      4530\n",
      "weighted avg       0.71      0.84      0.77      4530\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.22      0.34       560\n",
      "     neutral       0.00      0.00      0.00       159\n",
      "    positive       0.87      0.99      0.93      3811\n",
      "\n",
      "    accuracy                           0.86      4530\n",
      "   macro avg       0.52      0.40      0.42      4530\n",
      "weighted avg       0.82      0.86      0.82      4530\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.39      0.37      0.38       560\n",
      "     neutral       0.09      0.08      0.08       159\n",
      "    positive       0.89      0.90      0.90      3811\n",
      "\n",
      "    accuracy                           0.81      4530\n",
      "   macro avg       0.46      0.45      0.45      4530\n",
      "weighted avg       0.80      0.81      0.80      4530\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.21      0.31       560\n",
      "     neutral       0.25      0.01      0.01       159\n",
      "    positive       0.87      0.99      0.92      3811\n",
      "\n",
      "    accuracy                           0.86      4530\n",
      "   macro avg       0.59      0.40      0.42      4530\n",
      "weighted avg       0.82      0.86      0.82      4530\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.21      0.32       560\n",
      "     neutral       0.33      0.02      0.04       159\n",
      "    positive       0.87      0.99      0.92      3811\n",
      "\n",
      "    accuracy                           0.86      4530\n",
      "   macro avg       0.63      0.41      0.43      4530\n",
      "weighted avg       0.83      0.86      0.82      4530\n",
      "\n",
      "\n",
      "Aspect: harga\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.62      0.61       362\n",
      "     neutral       0.52      0.78      0.63       411\n",
      "    positive       0.70      0.25      0.37       330\n",
      "\n",
      "    accuracy                           0.57      1103\n",
      "   macro avg       0.61      0.55      0.54      1103\n",
      "weighted avg       0.60      0.57      0.54      1103\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.73      0.72       362\n",
      "     neutral       0.59      0.76      0.67       411\n",
      "    positive       0.68      0.43      0.53       330\n",
      "\n",
      "    accuracy                           0.65      1103\n",
      "   macro avg       0.66      0.64      0.64      1103\n",
      "weighted avg       0.66      0.65      0.64      1103\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.66      0.66       362\n",
      "     neutral       0.58      0.59      0.58       411\n",
      "    positive       0.53      0.52      0.52       330\n",
      "\n",
      "    accuracy                           0.59      1103\n",
      "   macro avg       0.59      0.59      0.59      1103\n",
      "weighted avg       0.59      0.59      0.59      1103\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.78      0.71       362\n",
      "     neutral       0.61      0.71      0.65       411\n",
      "    positive       0.74      0.43      0.54       330\n",
      "\n",
      "    accuracy                           0.65      1103\n",
      "   macro avg       0.67      0.64      0.64      1103\n",
      "weighted avg       0.66      0.65      0.64      1103\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.78      0.72       362\n",
      "     neutral       0.57      0.69      0.62       411\n",
      "    positive       0.68      0.36      0.47       330\n",
      "\n",
      "    accuracy                           0.62      1103\n",
      "   macro avg       0.64      0.61      0.60      1103\n",
      "weighted avg       0.63      0.62      0.61      1103\n",
      "\n",
      "\n",
      "Aspect: sdm\n",
      "\n",
      "Classification Report with Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       118\n",
      "     neutral       0.00      0.00      0.00        27\n",
      "    positive       0.72      1.00      0.84       376\n",
      "\n",
      "    accuracy                           0.72       521\n",
      "   macro avg       0.24      0.33      0.28       521\n",
      "weighted avg       0.52      0.72      0.61       521\n",
      "\n",
      "\n",
      "Classification Report with Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.14      0.23       118\n",
      "     neutral       0.00      0.00      0.00        27\n",
      "    positive       0.74      0.99      0.85       376\n",
      "\n",
      "    accuracy                           0.74       521\n",
      "   macro avg       0.50      0.37      0.36       521\n",
      "weighted avg       0.71      0.74      0.66       521\n",
      "\n",
      "\n",
      "Classification Report with Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.51      0.54       118\n",
      "     neutral       0.17      0.07      0.10        27\n",
      "    positive       0.81      0.86      0.83       376\n",
      "\n",
      "    accuracy                           0.74       521\n",
      "   macro avg       0.51      0.48      0.49       521\n",
      "weighted avg       0.72      0.74      0.73       521\n",
      "\n",
      "\n",
      "Classification Report with Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.14      0.22       118\n",
      "     neutral       0.00      0.00      0.00        27\n",
      "    positive       0.74      0.97      0.84       376\n",
      "\n",
      "    accuracy                           0.73       521\n",
      "   macro avg       0.46      0.37      0.35       521\n",
      "weighted avg       0.68      0.73      0.66       521\n",
      "\n",
      "\n",
      "Classification Report with Extra Trees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.23      0.35       118\n",
      "     neutral       0.00      0.00      0.00        27\n",
      "    positive       0.76      0.98      0.85       376\n",
      "\n",
      "    accuracy                           0.76       521\n",
      "   macro avg       0.51      0.40      0.40       521\n",
      "weighted avg       0.72      0.76      0.70       521\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Melakukan pelatihan dan evaluasi model untuk setiap aspek dan setiap algoritma dengan cross-validation\n",
    "for aspect, df_aspect in dfs_melted_df.items():\n",
    "    print(f'\\nAspect: {aspect}')\n",
    "    # Membagi data menjadi fitur (X) dan target (y)\n",
    "    X = df_aspect['text']\n",
    "    y = df_aspect['sentiment']\n",
    "    \n",
    "    for clf_name, clf in classifiers.items():\n",
    "        # Membuat pipeline dengan TfidfVectorizer dan classifier\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(max_features=100000)),\n",
    "            ('clf', clf)\n",
    "        ])\n",
    "        \n",
    "        # Menggunakan cross-validation untuk menghasilkan prediksi\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        y_pred = cross_val_predict(pipeline, X, y, cv=skf)\n",
    "\n",
    "        # Evaluasi model\n",
    "        print(f'\\nClassification Report with {clf_name}:')\n",
    "        print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pemodelan Topik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_teks = [i.split() for i in teks]\n",
    "# print(token_teks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Phrases\n",
    "\n",
    "bigram = Phrases(token_teks, min_count=10)\n",
    "trigram = Phrases(bigram[token_teks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range (len(token_teks)):\n",
    "    for token in bigram[token_teks[idx]]:\n",
    "        if '_' in token:\n",
    "            token_teks[idx].append(token)\n",
    "    for token in trigram[token_teks[idx]]:\n",
    "        if '_' in token:\n",
    "            token_teks[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<4256 unique tokens: ['antri', 'bangga', 'bangsa', 'bangsa_indonesia', 'batas']...>\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "term_dictionary = corpora.Dictionary(token_teks)\n",
    "term_dictionary.filter_extremes(no_below=5, no_above=0.2)\n",
    "print(term_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6743\n",
      "[(1, 1), (7, 3), (9, 2), (13, 1), (26, 1), (28, 1), (33, 3), (35, 1), (62, 1), (73, 1), (83, 1), (97, 2), (98, 1), (140, 1), (161, 1), (166, 1), (168, 1), (183, 3), (185, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 1), (200, 3), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (206, 1), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (212, 1), (213, 1), (214, 1)]\n"
     ]
    }
   ],
   "source": [
    "# build corpus\n",
    "# Converting List of documents (corpus) into Document Term matrix using dictionary prepared avobe.\n",
    "doc_term_matrix = [term_dictionary.doc2bow(doc) for doc in token_teks]\n",
    "# The function doc2bow convert document (a list of words) into the bag-of-words format\n",
    "print(len(doc_term_matrix))\n",
    "print(doc_term_matrix[10])\n",
    "\n",
    "tfidf = models.TfidfModel(doc_term_matrix)\n",
    "corpus_tfidf = tfidf[doc_term_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from numpy import array\n",
    "# function to compute coherence values\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start, step):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, iterations=100)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 2\n",
    "limit = 7\n",
    "step = 1\n",
    "\n",
    "model_list, coherence_values = compute_coherence_values(term_dictionary, corpus=corpus_tfidf, texts=token_teks, start=start, limit=limit, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show graps\n",
    "import matplotlib.pyplot as plt\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.title(\"Daya Tarik Positif\")\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel('Coherence Score')\n",
    "plt.legend(('coherence_values'), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num TOpics = 2 has Coherence Value of 0.41\n",
      "Num TOpics = 3 has Coherence Value of 0.52\n",
      "Num TOpics = 4 has Coherence Value of 0.554\n",
      "Num TOpics = 5 has Coherence Value of 0.513\n",
      "Num TOpics = 6 has Coherence Value of 0.532\n"
     ]
    }
   ],
   "source": [
    "# print the coherence score\n",
    "for m, cv, in zip(x, coherence_values):\n",
    "    print('Num TOpics =', m, 'has Coherence Value of', round(cv, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.018*\"must_visit\" + 0.012*\"hindu_temple\" + 0.009*\"place\" + 0.008*\"heritage\" + 0.007*\"central_java\" + 0.007*\"beautiful\" + 0.007*\"hindu\" + 0.007*\"world_heritage\" + 0.006*\"largest_hindu\" + 0.006*\"must\"\n",
      "Topic: 1 Word: 0.013*\"tample\" + 0.007*\"yg\" + 0.007*\"tempat_bagus\" + 0.006*\"bagus\" + 0.006*\"tempat\" + 0.006*\"wonderfull\" + 0.005*\"candi_prambanan\" + 0.005*\"exit_gate\" + 0.005*\"harga_tiket\" + 0.005*\"banget\"\n",
      "Topic: 2 Word: 0.025*\"nice_place\" + 0.011*\"great_place\" + 0.010*\"place\" + 0.009*\"love_place\" + 0.007*\"tiket_masuk\" + 0.006*\"little_bit\" + 0.005*\"holiday_season\" + 0.005*\"nice\" + 0.005*\"salah_ajaib\" + 0.005*\"love\"\n",
      "Topic: 3 Word: 0.033*\"historical_place\" + 0.019*\"one_best\" + 0.009*\"historical\" + 0.009*\"i_love\" + 0.007*\"place\" + 0.007*\"bring_umbrella\" + 0.007*\"great_view\" + 0.006*\"best\" + 0.006*\"entry_ticket\" + 0.006*\"parking_area\"\n",
      "Topic: 4 Word: 0.012*\"place\" + 0.008*\"beautiful\" + 0.008*\"amazing\" + 0.007*\"great\" + 0.007*\"good\" + 0.007*\"visit\" + 0.006*\"the\" + 0.006*\"i\" + 0.006*\"great_place\" + 0.006*\"hindu_temple\"\n",
      "Topic: 5 Word: 0.009*\"candi_prambanan\" + 0.009*\"tempat_wisata\" + 0.008*\"yg\" + 0.005*\"romantic\" + 0.005*\"well_managed\" + 0.005*\"recomended\" + 0.005*\"sejarah\" + 0.005*\"tourist_attraction\" + 0.005*\"cagar_budaya\" + 0.004*\"tempat\"\n"
     ]
    }
   ],
   "source": [
    "model = LdaModel(corpus=corpus_tfidf, id2word=term_dictionary, num_topics=6)\n",
    "for idx, topic in model.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.018*\"must_visit\" + 0.012*\"hindu_temple\" + 0.009*\"place\" + 0.008*\"heritage\" + 0.007*\"central_java\" + 0.007*\"beautiful\" + 0.007*\"hindu\" + 0.007*\"world_heritage\" + 0.006*\"largest_hindu\" + 0.006*\"must\"'),\n",
       " (1,\n",
       "  '0.013*\"tample\" + 0.007*\"yg\" + 0.007*\"tempat_bagus\" + 0.006*\"bagus\" + 0.006*\"tempat\" + 0.006*\"wonderfull\" + 0.005*\"candi_prambanan\" + 0.005*\"exit_gate\" + 0.005*\"harga_tiket\" + 0.005*\"banget\"'),\n",
       " (2,\n",
       "  '0.025*\"nice_place\" + 0.011*\"great_place\" + 0.010*\"place\" + 0.009*\"love_place\" + 0.007*\"tiket_masuk\" + 0.006*\"little_bit\" + 0.005*\"holiday_season\" + 0.005*\"nice\" + 0.005*\"salah_ajaib\" + 0.005*\"love\"'),\n",
       " (3,\n",
       "  '0.033*\"historical_place\" + 0.019*\"one_best\" + 0.009*\"historical\" + 0.009*\"i_love\" + 0.007*\"place\" + 0.007*\"bring_umbrella\" + 0.007*\"great_view\" + 0.006*\"best\" + 0.006*\"entry_ticket\" + 0.006*\"parking_area\"'),\n",
       " (4,\n",
       "  '0.012*\"place\" + 0.008*\"beautiful\" + 0.008*\"amazing\" + 0.007*\"great\" + 0.007*\"good\" + 0.007*\"visit\" + 0.006*\"the\" + 0.006*\"i\" + 0.006*\"great_place\" + 0.006*\"hindu_temple\"'),\n",
       " (5,\n",
       "  '0.009*\"candi_prambanan\" + 0.009*\"tempat_wisata\" + 0.008*\"yg\" + 0.005*\"romantic\" + 0.005*\"well_managed\" + 0.005*\"recomended\" + 0.005*\"sejarah\" + 0.005*\"tourist_attraction\" + 0.005*\"cagar_budaya\" + 0.004*\"tempat\"')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "import pyLDAvis.gensim_models; pyLDAvis.enable_notebook()\n",
    "data = pyLDAvis.gensim_models.prepare(model, corpus_tfidf, term_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el219461279844152166243659113434\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el219461279844152166243659113434_data = {\"mdsDat\": {\"x\": [0.188593836939273, -0.16261078764420606, 0.09131430545717804, -0.0901540496578673, -0.021127677704159162, -0.006015627390218436], \"y\": [-0.05146427100513556, 0.020288192232845947, 0.12516936959265068, -0.005614154882089173, -0.035559334707802634, -0.052819801230469435], \"topics\": [1, 2, 3, 4, 5, 6], \"cluster\": [1, 1, 1, 1, 1, 1], \"Freq\": [33.007772294145, 23.231394543461743, 13.811299879326903, 12.92738690082525, 9.045828082450374, 7.976318299790735]}, \"tinfo\": {\"Term\": [\"historical_place\", \"nice_place\", \"must_visit\", \"tample\", \"one_best\", \"great_place\", \"hindu_temple\", \"place\", \"tempat_wisata\", \"love_place\", \"historical\", \"tempat_bagus\", \"i_love\", \"wonderfull\", \"yg\", \"tiket_masuk\", \"candi_prambanan\", \"bring_umbrella\", \"world_heritage\", \"exit_gate\", \"heritage\", \"great\", \"best\", \"largest_hindu\", \"central_java\", \"little_bit\", \"love\", \"cultural_heritage\", \"romantic\", \"well_managed\", \"learn_history\", \"nice_view\", \"beautifull\", \"jazz\", \"ramayana_ballet\", \"highly_recommend\", \"of\", \"i_suggest\", \"prambanan_jazz\", \"really_hot\", \"local_guide\", \"i_hope\", \"lifetime\", \"iconic\", \"local_tourist\", \"memorable\", \"rara_jonggrang\", \"one_wonder\", \"location\", \"scenery\", \"kingdom\", \"travelling\", \"they\", \"learn\", \"is\", \"this_one\", \"i_came\", \"spectacular\", \"never_forget\", \"affordable\", \"well_maintained\", \"even\", \"find\", \"cool\", \"human\", \"you\", \"take_photo\", \"really\", \"get\", \"i_recommend\", \"recommend\", \"clean\", \"amazing\", \"like\", \"great\", \"enjoy\", \"make_sure\", \"historical_site\", \"i\", \"price\", \"time\", \"also\", \"its\", \"history\", \"good\", \"beautiful\", \"place\", \"visit\", \"great_place\", \"the\", \"many\", \"one\", \"it\", \"temple_complex\", \"nice\", \"go\", \"hindu_temple\", \"see\", \"around\", \"view\", \"prambanan\", \"love\", \"tample\", \"exit_gate\", \"wonderfull\", \"hindhu\", \"tempat_bagus\", \"bagus_banget\", \"rame_banget\", \"parkir_mobil\", \"tiket_terus\", \"lumayan_mahal\", \"expensive_foreigner\", \"angle\", \"must_visited\", \"kesini_pa\", \"marvelous\", \"destroyed_earthquake\", \"siang_panas\", \"kalo_kesini\", \"his\", \"cuman\", \"beatifull\", \"musholla\", \"terus\", \"htm\", \"rame\", \"worthy\", \"tempat_bersih\", \"harga_jangkau\", \"sinar_matahari\", \"haha\", \"study_tour\", \"sewa_payung\", \"jangan_lupa\", \"pertama_kali\", \"musim_libur\", \"banget\", \"harga_tiket\", \"pa\", \"suka\", \"kesana\", \"panas\", \"keren\", \"payung\", \"ajar_sejarah\", \"bagus\", \"gak\", \"tiket\", \"kesini\", \"bawa\", \"tempat\", \"yg\", \"spot_foto\", \"bgt\", \"harga\", \"bersih\", \"sejarah\", \"ajaib_dunia\", \"tiket_masuk\", \"masuk\", \"candi_prambanan\", \"indah\", \"wisata\", \"tinggal_sejarah\", \"cultural_heritage\", \"very_nice\", \"the_biggest\", \"story_behind\", \"largest_hindu\", \"ancient_hindu\", \"world_heritage\", \"whole_complex\", \"southeast_asia\", \"national\", \"best_place\", \"must_come\", \"a_lot\", \"come_back\", \"unesco_heritage\", \"well_preserved\", \"dont_miss\", \"hindus\", \"taman_wisata\", \"brahma_vishnu\", \"heritage_site\", \"indonesias\", \"herritage\", \"one_oldest\", \"square_three\", \"province\", \"its_really\", \"knowing\", \"gods\", \"unesco_world\", \"central_java\", \"must_visit\", \"three_main\", \"watch_ramayana\", \"south_east\", \"hindus_temple\", \"heritage\", \"vishnu\", \"hindu_temple\", \"hindu\", \"world\", \"this_place\", \"must\", \"very_beautiful\", \"java\", \"place\", \"beautiful\", \"one\", \"candi_prambanan\", \"visit\", \"prambanan\", \"good\", \"the\", \"a_must\", \"amazing\", \"romantic\", \"well_managed\", \"tourist_attraction\", \"recomended\", \"preserve\", \"if_youre\", \"spend_time\", \"ill\", \"golden\", \"go_early\", \"easy_access\", \"manca_negara\", \"sunny\", \"cagar_budaya\", \"historical_building\", \"main_road\", \"hospitality\", \"tempat_wisata\", \"kamar_mandi\", \"kenal_sejarah\", \"pulau_jawa\", \"pd\", \"ticket_expensive\", \"jual_souvenir\", \"kalo_jogja\", \"much_better\", \"sunny_day\", \"cagar\", \"became\", \"lg\", \"agama_hindu\", \"parkir_luas\", \"tempat_luas\", \"candi_prambanan\", \"yg\", \"hindu_besar\", \"utk\", \"sejarah\", \"awesome\", \"jogja\", \"wisata\", \"ajaib_dunia\", \"tempat\", \"salah\", \"tinggal_sejarah\", \"luas\", \"salah_ajaib\", \"prambanan\", \"bagus\", \"indah\", \"indonesia\", \"kunjung\", \"borobudur\", \"love_place\", \"restoration_work\", \"raka_pikat\", \"historic_place\", \"holiday_season\", \"artistic\", \"mesmerizing\", \"marathon\", \"worlds\", \"noon\", \"raining\", \"mineral_water\", \"anymore\", \"suggested\", \"rich_history\", \"raka\", \"legacy\", \"main_anak\", \"an_amazing\", \"artist\", \"middle\", \"named\", \"worth_seeing\", \"far_away\", \"half_day\", \"little_bit\", \"kenang\", \"dewasa_rp\", \"careful\", \"restoring\", \"nice_place\", \"wahana\", \"describe\", \"the_best\", \"nenek_moyang\", \"salah_destinasi\", \"great_place\", \"largest_buddhist\", \"word\", \"tiket_masuk\", \"salah_ajaib\", \"historic\", \"always\", \"place\", \"love\", \"nice\", \"waris_budaya\", \"best\", \"bring_umbrella\", \"jogja\", \"great\", \"must_see\", \"borobudur\", \"the\", \"candi_prambanan\", \"salah\", \"i_love\", \"yg\", \"one_best\", \"great_view\", \"parking_area\", \"foreign_tourist\", \"historical_place\", \"dont_forget_bring_umbrella\", \"historical_value\", \"meet\", \"arrange\", \"annual\", \"around_mute\", \"stage\", \"more\", \"exciting\", \"such_amazing\", \"landmark\", \"hot_weather\", \"prasasti_siwagrha\", \"monumental\", \"state\", \"bring_hat\", \"tempel\", \"civilization\", \"hot_day\", \"polite\", \"destinasi_wajib\", \"masuk_dewasa\", \"situs_sejarah\", \"rumah_siwa\", \"bit_expensive\", \"destination\", \"entry_ticket\", \"feel_like\", \"have\", \"i_love\", \"amaze\", \"such\", \"bring_umbrella\", \"historical\", \"bangsa_indonesia\", \"view_top\", \"best\", \"lovely\", \"destinasi_wisata\", \"view\", \"love\", \"place\", \"bring\", \"dont_forget\", \"great\", \"umbrella\", \"candi_prambanan\", \"nice_place\", \"nice\", \"entrance_fee\", \"little_bit\", \"one\", \"yg\"], \"Freq\": [70.0, 81.0, 76.0, 73.0, 37.0, 76.0, 90.0, 169.0, 32.0, 21.0, 52.0, 39.0, 29.0, 34.0, 84.0, 46.0, 100.0, 28.0, 24.0, 29.0, 39.0, 85.0, 38.0, 22.0, 30.0, 19.0, 56.0, 19.0, 17.0, 17.0, 25.73978912755495, 25.44460553424367, 16.982552906116272, 14.806839093915663, 40.47459639423845, 11.63098549678397, 9.287151928356138, 13.730379488759835, 9.116970246896352, 8.15822573195172, 13.147776796975458, 10.078021056566673, 7.3445578521815955, 7.151372702077412, 9.96589050088517, 9.477848659301078, 7.360274499185697, 10.360549998730166, 10.193505468272695, 13.636950115420174, 7.639808301297597, 5.5689474446285, 10.947152973009556, 20.8613607093222, 6.530308557447637, 8.385394379208405, 9.00152733189671, 8.82016735988723, 5.100246295739013, 5.036758179275942, 22.676876655102713, 8.041178277638725, 14.678496236126078, 12.508955289536726, 11.30503901180978, 31.82096914928892, 18.471666825301448, 29.38912198877851, 27.730546586526494, 17.427842074340774, 16.49474897898209, 27.02126643810191, 59.7018094291309, 26.045802439082333, 58.926197256632676, 22.515847302772254, 24.94299519182241, 21.748172989129984, 49.520627560503975, 22.207135783181155, 34.783398730465954, 30.33901295087975, 37.36778409503248, 36.735776346781314, 54.23914242673337, 61.726059340896114, 93.0365894929442, 51.68218546293488, 47.991848322913874, 49.75935350156196, 28.173045331784213, 43.34810130009062, 29.332658803631027, 31.76552586096935, 40.216453683190835, 30.04995427143013, 45.30174410487604, 31.951619223953223, 26.98069372505081, 28.935950290639898, 30.04427567769931, 27.91981398647391, 73.20189190619841, 28.31522840461847, 33.14838689059759, 13.133136370852297, 37.42669549573315, 17.993106002670288, 10.47567154109823, 11.290631074059668, 10.604472778965736, 10.484520322564391, 13.806388840843205, 9.745236887516581, 8.52127790039634, 9.46365105975582, 8.098239426735223, 8.32500032294317, 15.597431794962013, 6.457275285046531, 6.851168725663828, 6.89080262164403, 6.637828978930631, 6.010239180850625, 7.1257412093932455, 7.415495642371338, 9.061609782661614, 7.453107831276061, 23.47984506732161, 6.6005503879189416, 4.930219896296305, 4.949925861329774, 10.717261966990813, 16.362200421577356, 14.55946207050826, 10.63659877528329, 11.746453004477331, 27.899671869694473, 27.99325841012975, 18.896839569497285, 14.603337332696572, 14.813236607774193, 24.93360497502911, 19.420830996212203, 17.38332020731727, 19.198837823977442, 35.88175043320169, 17.879186865361614, 24.781520681101966, 24.940214626668496, 16.64045740966231, 34.352262505729506, 41.76804761242048, 19.497143136801263, 14.15136410948841, 16.917348853064503, 19.068216725230435, 25.775110203365895, 20.792803604136825, 22.6978267037393, 19.37132610732318, 28.500810080754174, 19.96582740777169, 19.752054762605315, 18.395597701822403, 18.80088642090872, 13.382534273143678, 10.828564386126558, 11.423943042132736, 20.355298892903967, 14.274675443425826, 21.580256480318816, 6.253170159120558, 6.125374816207876, 7.099896299221412, 5.964163246807561, 5.953157237335328, 5.710976797590719, 9.671757318169833, 11.002843180207375, 10.367457965299256, 8.865616899087659, 12.694760545751933, 3.8094309128987827, 8.177640985853696, 13.322273631742211, 3.6364400889350015, 3.6099085990555952, 3.459108828827862, 3.319938603036151, 3.302466890972199, 14.001394268108003, 4.091884148627645, 4.110570133297442, 14.535163348162339, 23.072928187075284, 58.175392315829974, 6.442748325014006, 5.7302226518350565, 11.084957641707295, 7.606731446966124, 24.871303343863246, 7.611648730121156, 40.61589146786723, 21.88784905608219, 18.614699498082565, 17.11939320176375, 20.2843733341763, 9.079701609631574, 11.87057619780426, 29.187267283295945, 22.417441686601837, 18.39343719013988, 20.053145270636616, 18.617740002732727, 17.833547551354922, 16.417999711283, 15.112336017948566, 12.124797113133676, 12.50252348169297, 17.058247431394506, 16.537605412961753, 14.404215371887707, 16.099494917960154, 6.683303232674842, 13.025522878097595, 13.381139409962275, 5.256413297100828, 5.900103200579133, 13.293119749693824, 7.78991978978211, 4.618276899818044, 4.6746025337354205, 14.172932081675844, 5.705545210361437, 4.209927881798183, 4.199387524230627, 26.52788524842532, 4.1519452610547, 4.869724650679878, 4.032569255926547, 3.77765945717564, 6.1495338914096225, 3.241109570667569, 3.5149584254692794, 5.711297352728354, 2.6591946136013482, 4.866298357301656, 5.108621484762964, 4.443451426866704, 5.591843337758344, 11.515084040738216, 8.639043916753664, 28.93027633824902, 24.09797257531986, 7.622496222890289, 8.591443466953972, 15.891036729624926, 11.685042927490384, 13.341757441464873, 12.732178424808502, 11.611296179028336, 13.424213844307568, 10.0533060091771, 10.18192762519199, 9.029970014445476, 9.123717619583601, 12.570794842153783, 9.963105684903411, 8.584382131639225, 9.406853618289706, 7.875539202786761, 7.830371504351642, 19.9083035835668, 8.625064282790666, 7.603140277243735, 5.8251629394548345, 11.909391408086053, 4.92518414474846, 4.590552908261404, 4.452722962596661, 3.5750019019953125, 4.180933673891701, 4.1390987673190445, 3.2993703148897713, 3.575409027930812, 2.8020110188849, 3.3795271189541523, 2.622712857977364, 2.4388488719446437, 4.982550236062273, 2.281991917165208, 2.8643194825888845, 6.789771396944998, 2.522270517697864, 3.1181641460287763, 2.409554505593775, 2.937376222619831, 14.028927946605206, 3.32125731420437, 2.3049390612963316, 2.4578420170771156, 2.121884525525191, 53.57397630228597, 3.362693434478939, 5.663569576057687, 7.575283361123234, 8.585570792600631, 5.2777946286316615, 24.464507294340237, 4.860309347168003, 3.781583060339601, 14.449893636749001, 11.005829601887738, 9.490482103762053, 7.765036900183155, 21.059262502620022, 10.617964690782891, 11.35720127054076, 5.368140195167513, 8.292513912196162, 7.207066635762166, 8.29741205923642, 9.605206199468551, 6.811202748797333, 6.838241369586272, 7.365214970759108, 7.073783561501215, 6.058420070718761, 5.975460390334935, 6.436607969829722, 36.103760868078446, 12.621634195378455, 10.660819795654822, 10.26712379689295, 62.217277414944405, 3.712042989335839, 3.123925909367091, 3.8113935454277166, 3.1046106178043744, 3.4839164692036158, 3.755779214661632, 2.800135449089339, 2.7351644139608724, 2.6427474322869493, 4.582682892956597, 3.0808470533015573, 2.6081475254935738, 2.248015464138315, 2.6920655025619746, 2.3228087102002424, 6.778175890222419, 2.577339413728188, 2.098436771310768, 3.717774803611225, 2.7915346079577366, 1.9272435543688586, 1.8892284471406577, 4.371011773849407, 1.865509784300872, 1.848874108112602, 10.541904147681329, 10.724761546507649, 6.044166733372474, 4.367053742391534, 16.35932260799775, 5.104109527216485, 9.0573272594081, 13.021377991334713, 16.886280503199387, 5.170235081035597, 4.530675848151556, 11.71420255986469, 7.162178477858435, 5.573668612656728, 10.645970826832233, 9.67688107442467, 13.647548283665053, 6.651321895629443, 6.910336526023469, 8.522142220786542, 5.624820854586395, 8.21664779546255, 7.5329837647928946, 6.935702065987982, 5.005874939007786, 5.067643583072122, 5.473687873423151, 5.103652711289864], \"Total\": [70.0, 81.0, 76.0, 73.0, 37.0, 76.0, 90.0, 169.0, 32.0, 21.0, 52.0, 39.0, 29.0, 34.0, 84.0, 46.0, 100.0, 28.0, 24.0, 29.0, 39.0, 85.0, 38.0, 22.0, 30.0, 19.0, 56.0, 19.0, 17.0, 17.0, 26.945688092027158, 26.658350116072526, 17.843457672989643, 15.975941326328929, 43.67551237570875, 12.705175358527919, 10.23862996657653, 15.141202881917458, 10.080052585861244, 9.020050711127368, 14.537014886332049, 11.276634220777561, 8.23612314425876, 8.055345768104376, 11.315026763512769, 10.773949328656403, 8.393098388707715, 11.829308611102105, 11.667190980547113, 15.647239600927517, 8.788974443298972, 6.433237295255642, 12.651414006461167, 24.112937624605408, 7.56297946448948, 9.720243338103225, 10.475695943746942, 10.298044712182616, 5.9579271246590055, 5.887989271026218, 26.560980809452836, 9.430426652086052, 17.35700561999745, 14.94574432954268, 13.465500189268756, 40.65285821568791, 22.703357886681065, 37.498303736317396, 35.447862395875696, 21.48780948159861, 20.2900152292016, 35.08328895968653, 84.87820635556764, 33.91494344150876, 85.98009159126335, 28.86208813928199, 32.49845460894371, 27.829757233085374, 71.88044050096579, 28.54370566265629, 48.207223567036735, 41.18608607594307, 53.15085200558102, 52.27205911465322, 85.45524081901182, 102.192808274737, 169.63389565955006, 84.49756290461917, 76.99485315292925, 82.69793722215749, 40.033483061369644, 74.20338753873136, 42.518004831138924, 48.50734995925127, 69.89987575691711, 45.191949708912304, 90.37170786724818, 50.841984183381925, 39.067637251043365, 53.84307728807595, 86.48263978297004, 56.95678471224317, 73.92447967983685, 29.079159349031322, 34.06215335529979, 13.84388843024548, 39.66708938491287, 19.14644656029912, 11.175277319054965, 12.068244618091365, 11.418584354326763, 11.348133646978358, 14.994240130339435, 10.641431816411425, 9.379231378589417, 10.4425949841301, 8.93906266420765, 9.205032369703805, 17.27844173780402, 7.159601389447175, 7.611311452646454, 7.664241629593362, 7.403627539759595, 6.843274484549481, 8.162988834112058, 8.517750406145796, 10.439064682003146, 8.588228108677624, 27.060078921160198, 7.60792854540151, 5.690594842833245, 5.749642767317964, 12.48282822647455, 19.169229195911882, 17.13010856026337, 12.412753649775134, 13.83388655464161, 34.993913429469416, 37.16131595234087, 24.166366312823573, 18.224004978735092, 18.55503288799354, 34.10124140313915, 25.695241547058934, 22.531662233357903, 25.72774835547739, 56.16314066263051, 23.898809330498523, 36.31739309007661, 37.33225673244441, 21.961538555249916, 58.762566118588126, 84.03008320519496, 28.699497184238346, 18.11342847618473, 24.55174217517041, 30.870135362092196, 54.109688211771406, 37.48688546052533, 46.03347890517726, 33.96857803869077, 100.01468885111633, 39.84450238030938, 42.32276700718457, 35.151470228711176, 19.954198151881638, 14.570196196961454, 12.071310672469242, 12.76251957080726, 22.798740292665915, 16.116029264450773, 24.62318740476843, 7.149415189417559, 7.0114130572889595, 8.164253540328964, 6.919942265889519, 6.960912632334383, 6.6814456854128075, 11.360956797715465, 13.043353878648627, 12.510784130679594, 10.765612338010866, 15.635230704201296, 4.6966967339924315, 10.135932613297404, 16.574541112339315, 4.530325570383916, 4.498911209883866, 4.344972819220763, 4.219083622917974, 4.2148337890695, 17.920603643760657, 5.276653182034625, 5.31244418897592, 18.840740914293008, 30.13876334782061, 76.76767476549894, 8.407755432716137, 7.467899637451884, 15.205254361027782, 10.37879511996989, 39.77268310909651, 10.596441372280085, 90.37170786724818, 49.66775718808065, 39.94012232794667, 38.64476617623622, 52.408799594796655, 14.02999602758577, 25.889283815779848, 169.63389565955006, 102.192808274737, 74.20338753873136, 100.01468885111633, 84.49756290461917, 86.48263978297004, 85.45524081901182, 82.69793722215749, 30.400022841610706, 84.87820635556764, 17.870508884661184, 17.36181694105141, 15.19379553295467, 17.562711741829723, 7.489451978524182, 14.801889806672671, 15.263631157896205, 6.066482516225687, 6.811019870761767, 15.470265844211571, 9.078483389172499, 5.4017387188958095, 5.498744166853539, 16.95803615332155, 6.8583756127806765, 5.076839076632496, 5.069196865948221, 32.18876050097048, 5.0560238559444715, 5.935076636519118, 4.966078813380353, 4.680406864048077, 7.8472027099460115, 4.148918741372685, 4.503796105389635, 7.358538087003305, 3.446054432095567, 6.310025675495449, 6.659038033112833, 5.8254531186740435, 7.415283007455433, 17.239325789299635, 14.604175692155223, 100.01468885111633, 84.03008320519496, 13.913545007778488, 17.07034723638411, 54.109688211771406, 34.11316671734441, 46.11870184049404, 42.32276700718457, 37.48688546052533, 58.762566118588126, 32.57893088213388, 35.151470228711176, 26.834789629471373, 30.632958002884095, 86.48263978297004, 56.16314066263051, 39.84450238030938, 62.97799091822899, 30.329361445644096, 49.765047945535954, 21.51340450498516, 9.481266340306869, 8.495434166816525, 6.683483703666, 13.936114068426917, 5.801774918244557, 5.469892723584051, 5.310631305070434, 4.429614900135511, 5.252520966257347, 5.25860103655095, 4.229977400615105, 4.598381785763289, 3.679657654876381, 4.452064561795325, 3.5109444508454444, 3.305051580246174, 6.761277924693871, 3.1440110750523704, 3.946397737077011, 9.388714037217715, 3.4882073037316528, 4.332833246457747, 3.364064420605578, 4.161942066147398, 19.918301318217143, 4.732484180036053, 3.2972205301621162, 3.5163190446058996, 3.047629060292696, 81.66518345579301, 4.861028873569281, 8.383355803634235, 11.575999086675559, 14.407680609154957, 9.035743214456245, 76.99485315292925, 8.597084824392638, 6.011444127057762, 46.03347890517726, 30.632958002884095, 25.701904264430723, 20.74268058330434, 169.63389565955006, 56.95678471224317, 69.89987575691711, 13.129620099713511, 38.84891652796299, 28.03920212301705, 46.11870184049404, 85.98009159126335, 37.93497472598114, 49.765047945535954, 82.69793722215749, 100.01468885111633, 32.57893088213388, 29.381282390090032, 84.03008320519496, 37.04443365955922, 13.579187308869367, 11.529740923549278, 11.305988417245583, 70.44069543356056, 4.743030875140771, 3.995341517004003, 4.946016534406953, 4.062078861199889, 4.639358420195693, 5.0156866837492995, 3.7622829221741454, 3.6886038106332184, 3.5866611083748756, 6.240986717956457, 4.21642045810643, 3.635285436991941, 3.138041890181964, 3.7677127571658344, 3.2794131930225285, 9.59029393674018, 3.652838152987938, 2.9896302767616567, 5.343374809395522, 4.04304210478847, 2.794960812940367, 2.7563646434574354, 6.392277207698198, 2.7542460511419913, 2.739294100706549, 15.82584090406106, 16.13912393313172, 9.083046000712804, 6.711653437428094, 29.381282390090032, 8.048379058740235, 17.054102868530286, 28.03920212301705, 52.1408237254713, 9.826787787887074, 8.310867148087214, 38.84891652796299, 17.69582784059736, 11.771603273695854, 53.84307728807595, 56.95678471224317, 169.63389565955006, 28.889862172862458, 32.5080228040851, 85.98009159126335, 20.210974986420453, 100.01468885111633, 81.66518345579301, 69.89987575691711, 17.853839360027703, 19.918301318217143, 74.20338753873136, 84.03008320519496], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.7293, -5.7408, -6.1451, -6.2822, -5.2766, -6.5236, -6.7487, -6.3577, -6.7672, -6.8783, -6.401, -6.6669, -6.9833, -7.01, -6.6781, -6.7283, -6.9812, -6.6393, -6.6555, -6.3645, -6.9439, -7.2601, -6.5842, -5.9394, -7.1008, -6.8508, -6.7799, -6.8003, -7.348, -7.3605, -5.856, -6.8927, -6.2909, -6.4509, -6.552, -5.5172, -6.0611, -5.5967, -5.6548, -6.1192, -6.1743, -5.6807, -4.8879, -5.7174, -4.901, -5.8631, -5.7607, -5.8978, -5.0749, -5.8769, -5.4282, -5.5649, -5.3565, -5.3735, -4.9839, -4.8546, -4.4443, -5.0322, -5.1063, -5.0701, -5.6389, -5.208, -5.5986, -5.5189, -5.283, -5.5744, -5.164, -5.5131, -5.6822, -5.6122, -5.5746, -5.648, -4.3328, -5.2827, -5.1251, -6.0509, -5.0037, -5.7361, -6.277, -6.2021, -6.2648, -6.2762, -6.0009, -6.3493, -6.4835, -6.3786, -6.5344, -6.5068, -5.879, -6.7609, -6.7016, -6.6959, -6.7333, -6.8326, -6.6623, -6.6225, -6.422, -6.6174, -5.4699, -6.7389, -7.0307, -7.0267, -6.2542, -5.8311, -5.9478, -6.2618, -6.1625, -5.2974, -5.2941, -5.6871, -5.9448, -5.9305, -5.4098, -5.6597, -5.7705, -5.6712, -5.0458, -5.7424, -5.416, -5.4096, -5.8142, -5.0894, -4.8939, -5.6558, -5.9762, -5.7977, -5.678, -5.3767, -5.5915, -5.5038, -5.6623, -5.2761, -5.632, -5.6428, -5.7139, -5.1721, -5.5121, -5.7239, -5.6703, -5.0927, -5.4476, -5.0343, -6.273, -6.2936, -6.146, -6.3203, -6.3221, -6.3637, -5.8368, -5.7079, -5.7674, -5.9239, -5.5649, -6.7686, -6.0046, -5.5166, -6.815, -6.8224, -6.865, -6.9061, -6.9114, -5.4669, -6.697, -6.6925, -5.4295, -4.9674, -4.0426, -6.2431, -6.3603, -5.7005, -6.077, -4.8923, -6.0764, -4.4019, -5.0201, -5.1821, -5.2658, -5.0962, -5.9, -5.632, -4.7323, -4.9962, -5.194, -5.1077, -5.1819, -5.225, -5.3077, -5.3905, -5.6108, -5.5801, -5.2033, -5.2343, -5.3724, -5.2611, -6.1403, -5.473, -5.4461, -6.3805, -6.2649, -5.4527, -5.9871, -6.5099, -6.4978, -5.3886, -6.2985, -6.6025, -6.605, -4.7617, -6.6163, -6.4569, -6.6455, -6.7108, -6.2235, -6.864, -6.7829, -6.2975, -7.0619, -6.4576, -6.409, -6.5485, -6.3186, -5.5962, -5.8836, -4.675, -4.8578, -6.0088, -5.8891, -5.2741, -5.5816, -5.449, -5.4958, -5.5879, -5.4428, -5.732, -5.7193, -5.8394, -5.829, -5.5085, -5.741, -5.89, -5.7985, -5.9761, -5.9819, -4.6917, -5.5282, -5.6543, -5.9207, -5.2055, -6.0885, -6.1589, -6.1893, -6.4089, -6.2523, -6.2624, -6.4891, -6.4088, -6.6525, -6.4651, -6.7186, -6.7913, -6.0769, -6.8578, -6.6305, -5.7674, -6.7577, -6.5456, -6.8034, -6.6053, -5.0417, -6.4825, -6.8478, -6.7836, -6.9306, -3.7018, -6.4701, -5.9488, -5.658, -5.5328, -6.0194, -4.4856, -6.1018, -6.3527, -5.0122, -5.2844, -5.4326, -5.6332, -4.6355, -5.3203, -5.253, -6.0024, -5.5675, -5.7078, -5.5669, -5.4206, -5.7643, -5.7603, -5.6861, -5.7265, -5.8814, -5.8952, -5.8209, -3.9706, -5.0216, -5.1905, -5.2281, -3.4264, -6.2454, -6.4179, -6.219, -6.4241, -6.3089, -6.2337, -6.5274, -6.5508, -6.5852, -6.0347, -6.4318, -6.5984, -6.747, -6.5667, -6.7143, -5.6433, -6.6103, -6.8158, -6.2439, -6.5304, -6.9009, -6.9209, -6.082, -6.9335, -6.9425, -5.2017, -5.1845, -5.7579, -6.0829, -4.7622, -5.927, -5.3535, -4.9904, -4.7305, -5.9141, -6.0462, -5.0962, -5.5882, -5.839, -5.1919, -5.2873, -4.9435, -5.6622, -5.624, -5.4144, -5.8298, -5.4509, -5.5377, -5.6203, -5.9464, -5.9342, -5.8571, -5.9271], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.0626, 1.0618, 1.059, 1.0324, 1.0323, 1.0201, 1.0109, 1.0106, 1.008, 1.008, 1.008, 0.9961, 0.9939, 0.9894, 0.9815, 0.9803, 0.9771, 0.9759, 0.9734, 0.9709, 0.9683, 0.9642, 0.9637, 0.9636, 0.9616, 0.9607, 0.9568, 0.9535, 0.953, 0.9523, 0.9503, 0.9491, 0.9408, 0.9304, 0.9335, 0.8635, 0.9022, 0.8648, 0.8629, 0.899, 0.9013, 0.8473, 0.7566, 0.8444, 0.7306, 0.8601, 0.8438, 0.8619, 0.7358, 0.8574, 0.7821, 0.8028, 0.7561, 0.7557, 0.6538, 0.6043, 0.5078, 0.6168, 0.6357, 0.6004, 0.7571, 0.5709, 0.7372, 0.6851, 0.5556, 0.7004, 0.4178, 0.6439, 0.7383, 0.4874, 0.0512, 0.3955, 1.4498, 1.433, 1.4325, 1.407, 1.4015, 1.3975, 1.395, 1.3931, 1.3857, 1.3805, 1.3771, 1.3717, 1.3637, 1.3612, 1.3609, 1.3592, 1.3573, 1.3564, 1.3544, 1.3533, 1.3505, 1.3299, 1.3238, 1.3211, 1.3182, 1.3179, 1.3177, 1.3176, 1.3162, 1.3099, 1.3072, 1.3013, 1.2971, 1.3052, 1.2961, 1.2331, 1.1764, 1.2137, 1.2382, 1.2344, 1.1465, 1.1797, 1.2003, 1.1669, 1.0116, 1.1695, 1.0775, 1.0563, 1.1822, 0.9228, 0.7606, 1.0731, 1.2128, 1.0872, 0.9779, 0.7181, 0.8703, 0.7526, 0.898, 0.2043, 0.7687, 0.6976, 0.8121, 1.9201, 1.8947, 1.871, 1.8689, 1.8663, 1.8584, 1.8478, 1.8457, 1.8446, 1.84, 1.831, 1.8233, 1.8227, 1.8187, 1.8096, 1.7918, 1.7855, 1.7713, 1.7703, 1.765, 1.7613, 1.7599, 1.7595, 1.7517, 1.74, 1.7357, 1.7329, 1.7254, 1.7232, 1.7202, 1.7125, 1.7024, 1.7135, 1.7148, 1.6636, 1.669, 1.5102, 1.6488, 1.1799, 1.1603, 1.2163, 1.1655, 1.0305, 1.5445, 1.1999, 0.2198, 0.4627, 0.5849, 0.3728, 0.4671, 0.4008, 0.3301, 0.28, 1.0605, 0.0644, 1.9993, 1.9972, 1.9925, 1.9588, 1.9319, 1.918, 1.9142, 1.9025, 1.9023, 1.8941, 1.8927, 1.8891, 1.8834, 1.8664, 1.8618, 1.8586, 1.8576, 1.8524, 1.8488, 1.848, 1.8376, 1.8315, 1.802, 1.7989, 1.7979, 1.7924, 1.7866, 1.786, 1.7808, 1.775, 1.7636, 1.6423, 1.5208, 0.8054, 0.7968, 1.4441, 1.3592, 0.8206, 0.9744, 0.8055, 0.8446, 0.8738, 0.5694, 0.8701, 0.8068, 0.9567, 0.8346, 0.1173, 0.3165, 0.5108, 0.1445, 0.6975, 0.1965, 2.3253, 2.3082, 2.2919, 2.2654, 2.2457, 2.2391, 2.2276, 2.2267, 2.1885, 2.1747, 2.1635, 2.1544, 2.1512, 2.1304, 2.1272, 2.1112, 2.0989, 2.0976, 2.0824, 2.0824, 2.0788, 2.0786, 2.0739, 2.0692, 2.0544, 2.0523, 2.0488, 2.0448, 2.0447, 2.0408, 1.9813, 2.0344, 2.0107, 1.9788, 1.8852, 1.8652, 1.2564, 1.8325, 1.9393, 1.2442, 1.3792, 1.4066, 1.4203, 0.3166, 0.7231, 0.5857, 1.5085, 0.8585, 1.0443, 0.6876, 0.2111, 0.6856, 0.4181, -0.0156, -0.2461, 0.7206, 0.8102, -0.1663, 2.503, 2.4556, 2.4503, 2.4323, 2.4046, 2.2836, 2.2827, 2.2681, 2.2599, 2.2423, 2.2394, 2.2333, 2.2296, 2.2233, 2.2198, 2.2149, 2.1966, 2.1951, 2.1925, 2.1838, 2.1816, 2.1799, 2.1747, 2.166, 2.1583, 2.157, 2.1509, 2.1486, 2.1391, 2.1356, 2.1224, 2.12, 2.1214, 2.0989, 1.9431, 2.0733, 1.8959, 1.7617, 1.4012, 1.8865, 1.922, 1.3298, 1.6242, 1.7811, 0.9078, 0.7561, 0.0086, 1.06, 0.9802, 0.2172, 1.2497, 0.0295, 0.1454, 0.2183, 1.2571, 1.1599, -0.0782, -0.2725]}, \"token.table\": {\"Topic\": [3, 1, 2, 3, 1, 2, 4, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 3, 5, 6, 1, 2, 3, 4, 5, 6, 5, 2, 3, 2, 6, 5, 1, 2, 3, 4, 5, 6, 6, 6, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 2, 1, 2, 3, 4, 5, 6, 2, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 1, 2, 3, 4, 5, 6, 1, 1, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 2, 4, 5, 6, 6, 1, 2, 3, 4, 5, 6, 2, 3, 6, 1, 2, 3, 4, 5, 6, 2, 4, 6, 2, 3, 5, 6, 4, 3, 4, 5, 1, 2, 3, 4, 5, 6, 5, 1, 2, 3, 4, 5, 6, 6, 1, 3, 4, 5, 6, 1, 3, 1, 5, 3, 2, 2, 3, 5, 6, 2, 6, 1, 2, 3, 6, 2, 5, 1, 3, 4, 6, 6, 3, 6, 1, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 3, 6, 1, 6, 2, 2, 3, 5, 2, 6, 1, 2, 3, 6, 6, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 4, 5, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 5, 6, 6, 2, 5, 1, 2, 3, 4, 5, 6, 2, 1, 2, 3, 4, 5, 6, 2, 3, 6, 1, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 3, 1, 2, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 3, 4, 5, 3, 4, 5, 2, 1, 5, 5, 1, 2, 3, 4, 5, 6, 4, 3, 6, 1, 2, 6, 1, 2, 3, 4, 5, 6, 2, 5, 4, 3, 6, 6, 2, 6, 1, 3, 5, 1, 2, 3, 4, 5, 6, 1, 6, 1, 1, 2, 3, 5, 6, 1, 2, 4, 5, 1, 5, 1, 2, 4, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 1, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 3, 2, 5, 1, 2, 3, 5, 6, 1, 1, 2, 3, 4, 5, 6, 4, 4, 2, 4, 4, 4, 5, 1, 2, 3, 4, 5, 6, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 2, 1, 3, 1, 2, 3, 4, 5, 6, 6, 1, 2, 3, 4, 5, 2, 3, 6, 1, 3, 4, 1, 5, 1, 4, 1, 1, 2, 3, 4, 5, 6, 5, 6, 1, 1, 1, 1, 2, 3, 4, 5, 6, 4, 5, 1, 3, 6, 1, 2, 3, 4, 5, 6, 2, 4, 5, 4, 1, 2, 3, 4, 4, 1, 2, 3, 4, 5, 5, 2, 1, 2, 3, 4, 5, 6, 6, 6, 1, 5, 1, 5, 5, 6, 6, 1, 4, 2, 1, 2, 3, 1, 2, 3, 4, 5, 6, 3, 1, 2, 3, 4, 5, 1, 3, 5, 6, 2, 5, 3, 2, 3, 4, 5, 6, 1, 1, 2, 3, 4, 5, 6, 1, 2, 3, 5, 6, 1, 5, 1, 1, 2, 3, 4, 5, 6, 6, 3, 1, 1, 2, 4, 6, 1, 2, 3, 4, 5, 6, 6, 2, 3, 4, 2, 2, 4, 6, 4, 2, 6, 1, 2, 3, 4, 5, 6, 6, 1, 2, 3, 4, 5, 6, 1, 6, 4, 1, 2, 3, 4, 5, 6, 3, 4, 5, 5, 5, 1, 2, 3, 2, 4, 2, 1, 1, 2, 3, 4, 5, 6, 1, 4, 5, 1, 2, 3, 4, 5, 5, 5, 4, 6, 1, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 1, 2, 5, 1, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 4, 6, 2, 4, 2, 3, 4, 6, 2, 3, 4, 3, 1, 2, 4, 2, 3, 4, 3, 6, 6, 3, 2, 5, 1, 5, 6, 1, 6, 5, 2, 3, 4, 5, 4, 4, 1, 2, 5, 3, 2, 1, 2, 3, 4, 5, 6, 2, 4, 2, 4, 6, 1, 2, 4, 1, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 1, 2, 3, 4, 5, 6, 1, 5, 6, 3, 4, 1, 1, 1, 3, 4, 2, 3, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 1, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 4, 1, 1, 2, 3, 5, 6, 1, 3, 2, 3, 5, 2, 3, 4, 5, 2, 3, 5, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 6, 1, 2, 3, 1, 2, 3, 4, 5, 6, 3, 5, 1, 2, 3, 5, 6, 1, 3, 1, 2, 3, 5, 6, 4, 2, 3, 3, 1, 2, 3, 4, 5, 6, 2, 1, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 6, 5, 5, 1, 2, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6], \"Freq\": [0.8980092456785863, 0.5263153940167322, 0.032894712126045764, 0.3947365455125492, 0.8491863299758612, 0.13485661963199322, 0.8091397177919593, 0.5601959123041457, 0.026675995824006937, 0.3201119498880832, 0.0800279874720208, 0.026675995824006937, 0.03886853937558441, 0.7385022481361038, 0.07773707875116882, 0.07773707875116882, 0.03886853937558441, 0.03886853937558441, 0.7284013330298725, 0.024280044434329084, 0.1456802666059745, 0.024280044434329084, 0.024280044434329084, 0.024280044434329084, 0.43388799069894785, 0.04820977674432754, 0.04820977674432754, 0.09641955348865508, 0.3856782139546203, 0.24849724216556077, 0.12424862108278038, 0.6212431054139019, 0.706895239381602, 0.0471263492921068, 0.1531606351993471, 0.0235631746460534, 0.0353447619690801, 0.0471263492921068, 0.6361300746902381, 0.062050023835947626, 0.8687003337032668, 0.9397231662545452, 0.6466411361839676, 0.8698712256524904, 0.6911091097345264, 0.05119326738774269, 0.12798316846935673, 0.05119326738774269, 0.05119326738774269, 0.05119326738774269, 0.7974979802785331, 0.7385380989658671, 0.7601869349899886, 0.8618052355455476, 0.5276554988032854, 0.0586283887559206, 0.0293141943779603, 0.3517703325355236, 0.0586283887559206, 0.03561054414698621, 0.6409897946457518, 0.03561054414698621, 0.17805272073493103, 0.07122108829397242, 0.03561054414698621, 0.9401222280756619, 0.028576398064638013, 0.8001391458098643, 0.028576398064638013, 0.08572919419391405, 0.028576398064638013, 0.028576398064638013, 0.20352530686225737, 0.20352530686225737, 0.10176265343112868, 0.5088132671556435, 0.045534150418662246, 0.7740805571172582, 0.045534150418662246, 0.09106830083732449, 0.045534150418662246, 0.045534150418662246, 0.9454824628073197, 0.6066963130450244, 0.04892712201976003, 0.21527933688694414, 0.04892712201976003, 0.039141697615808026, 0.039141697615808026, 0.952730144098337, 0.15017184089164004, 0.7508592044582002, 0.06478753580251395, 0.6154815901238825, 0.06478753580251395, 0.1295750716050279, 0.06478753580251395, 0.09718130370377093, 0.2574074361327971, 0.02574074361327971, 0.18018520529295798, 0.02574074361327971, 0.2059259489062377, 0.3088889233593565, 0.8670592570657429, 0.7729072394222328, 0.05520765995873091, 0.05520765995873091, 0.05520765995873091, 0.7301151050134186, 0.2813219433712177, 0.26122751884470213, 0.1205665471590933, 0.1607553962121244, 0.14066097168560884, 0.06028327357954665, 0.09865890373897047, 0.7892712299117638, 0.09865890373897047, 0.44998483974116993, 0.03461421844162846, 0.20768531064977072, 0.03461421844162846, 0.06922843688325692, 0.24229952909139918, 0.10427209078222563, 0.10427209078222563, 0.7299046354755794, 0.03566435291605933, 0.21398611749635596, 0.2496504704124153, 0.46363658790877127, 0.7923898026940137, 0.05896909235000841, 0.8255672929001178, 0.05896909235000841, 0.06998971931433318, 0.2899574085879517, 0.19997062661238052, 0.2899574085879517, 0.06998971931433318, 0.0799882506449522, 0.5687766026430503, 0.09953958513088546, 0.033179861710295154, 0.7631368193367885, 0.033179861710295154, 0.033179861710295154, 0.033179861710295154, 0.6689790425076856, 0.7695971729168589, 0.0855107969907621, 0.0285035989969207, 0.0570071979938414, 0.0570071979938414, 0.08802075545266456, 0.8802075545266456, 0.8698128185093731, 0.13381735669374972, 0.9521805815187989, 0.9133323736782286, 0.1192839745113161, 0.1192839745113161, 0.7157038470678967, 0.7155735388990843, 0.42475097773407905, 0.5097011732808949, 0.12637559116917327, 0.06318779558458663, 0.12637559116917327, 0.695065751430453, 0.8690898281172933, 0.6065714991473939, 0.5537094676129624, 0.1538081854480451, 0.06152327417921804, 0.21533145962726313, 0.8433426020827415, 0.8359951777404336, 0.0928883530822704, 0.11015055677610815, 0.8812044542088652, 0.7968931384661823, 0.03464752775939923, 0.03464752775939923, 0.03464752775939923, 0.03464752775939923, 0.06929505551879846, 0.16803108505146452, 0.11202072336764302, 0.22404144673528603, 0.16803108505146452, 0.28005180841910754, 0.24784492743056957, 0.6815735504340663, 0.8483179282488099, 0.8364325229933159, 0.9628889083044531, 0.9336918628955606, 0.06669227592111147, 0.5945189360077631, 0.2201904515118659, 0.6605713545355977, 0.8642043638401612, 0.05761362425601074, 0.05761362425601074, 0.05761362425601074, 0.884487019705991, 0.7531755976239894, 0.0418430887568883, 0.1255292662706649, 0.0836861775137766, 0.7898924817327704, 0.028210445776170368, 0.056420891552340736, 0.056420891552340736, 0.056420891552340736, 0.028210445776170368, 0.6638350456936294, 0.06638350456936294, 0.08851133942581725, 0.06638350456936294, 0.06638350456936294, 0.044255669712908625, 0.06464013030352447, 0.8403216939458181, 0.06464013030352447, 0.7529490866559259, 0.8809253406757336, 0.6319097516133411, 0.046808129749136375, 0.1872325189965455, 0.035106097311852276, 0.035106097311852276, 0.05851016218642047, 0.6862053634517777, 0.023261198761077212, 0.046522397522154424, 0.03489179814161582, 0.11630599380538605, 0.10467539442484744, 0.6234182940080567, 0.012987881125167848, 0.038963643375503544, 0.31170914700402835, 0.012987881125167848, 0.9573474247246693, 0.8696192445939297, 0.7208173377523783, 0.08146061431121714, 0.6924152216453456, 0.04073030715560857, 0.08146061431121714, 0.08146061431121714, 0.04073030715560857, 0.9200927635198464, 0.10763881465150406, 0.7534717025605284, 0.026909703662876015, 0.026909703662876015, 0.08072911098862805, 0.026909703662876015, 0.1489945822326607, 0.1489945822326607, 0.5959783289306428, 0.07542865518453952, 0.025142885061513173, 0.6285721265378293, 0.025142885061513173, 0.12571442530756585, 0.10057154024605269, 0.060333495402507764, 0.7843354402326009, 0.060333495402507764, 0.060333495402507764, 0.060333495402507764, 0.889104010590877, 0.9444969991654154, 0.9390425288026887, 0.3221405778282194, 0.08053514445705486, 0.4429432945138017, 0.08053514445705486, 0.04026757222852743, 0.04026757222852743, 0.07187240918406786, 0.1437448183681357, 0.07187240918406786, 0.5749792734725429, 0.07187240918406786, 0.49794345002423657, 0.022130820001077182, 0.45368181002208224, 0.011065410000538591, 0.831455591922082, 0.06395812245554477, 0.06395812245554477, 0.7708023819265072, 0.0963502977408134, 0.0963502977408134, 0.9196838210537421, 0.5836143441230828, 0.3501686064738496, 0.8977354125527234, 0.44111309251841135, 0.019178830109496146, 0.11507298065697688, 0.05753649032848844, 0.03835766021899229, 0.3260401118614345, 0.874842723518805, 0.09937437381779368, 0.8801730252433155, 0.790520729869872, 0.2155965626917833, 0.7508744840039652, 0.7078351346145447, 0.019130679313906614, 0.19130679313906615, 0.03826135862781323, 0.03826135862781323, 0.019130679313906614, 0.07175601427269877, 0.8610721712723852, 0.7890796324896286, 0.1871476427671984, 0.7485905710687936, 0.8252446890339331, 0.8218132330984134, 0.11740189044263048, 0.8169024429383158, 0.07426385844893779, 0.07426385844893779, 0.6955995212540218, 0.05564796170032174, 0.08347194255048261, 0.05564796170032174, 0.05564796170032174, 0.06955995212540218, 0.8591314647092444, 0.09545905163436048, 0.8867894270769799, 0.034035274115104264, 0.034035274115104264, 0.20421164469062558, 0.20421164469062558, 0.5445643858416682, 0.7911462550223275, 0.04653801500131338, 0.09307603000262676, 0.04653801500131338, 0.924629311764896, 0.06604495084034973, 0.8689881479348682, 0.06755894099071062, 0.8782662328792381, 0.8242008423541608, 0.05019513058314347, 0.5019513058314347, 0.0752926958747152, 0.2258780876241456, 0.10039026116628694, 0.0752926958747152, 0.365206950311631, 0.19054275668432918, 0.15878563057027434, 0.1429070675132469, 0.06351425222810973, 0.07939281528513717, 0.8829387508370675, 0.9255611538900982, 0.6820639894833743, 0.047038895826439615, 0.11759723956609903, 0.023519447913219808, 0.047038895826439615, 0.047038895826439615, 0.6961318323949891, 0.03762874769702644, 0.13170061693959254, 0.01881437384851322, 0.05644312154553966, 0.05644312154553966, 0.16740507516578537, 0.7812236841069984, 0.8756511931743053, 0.05837674621162035, 0.3090081617137628, 0.03862602021422035, 0.4635122425706441, 0.11587806064266103, 0.03862602021422035, 0.9389118108038778, 0.15178224279187588, 0.21683177541696555, 0.08673271016678623, 0.28188130804205525, 0.17346542033357246, 0.08673271016678623, 0.7230799605893073, 0.8881396729335174, 0.8380354818137838, 0.7911355076572903, 0.8424491049086884, 0.2113055135437097, 0.633916540631129, 0.03891771159919139, 0.7394365203846364, 0.03891771159919139, 0.11675313479757417, 0.03891771159919139, 0.03891771159919139, 0.8084060044811936, 0.05389373363207957, 0.10778746726415914, 0.05389373363207957, 0.0267864867416635, 0.6696621685415874, 0.053572973483327, 0.16071892044998098, 0.053572973483327, 0.053572973483327, 0.861854741439034, 0.9102313417351539, 0.7580562644554251, 0.06594270056045773, 0.46159890392320413, 0.0989140508406866, 0.2637708022418309, 0.06594270056045773, 0.06594270056045773, 0.711503994871347, 0.11631849870350063, 0.11631849870350063, 0.23263699740700125, 0.11631849870350063, 0.5815924935175031, 0.04386207251642268, 0.8772414503284536, 0.04386207251642268, 0.8709017676291381, 0.08294302548848934, 0.04147151274424467, 0.9649039175100163, 0.6051342774659607, 0.1716604665127945, 0.686641866051178, 0.8499144412234246, 0.7666237169123036, 0.05897105514710028, 0.05897105514710028, 0.02948552757355014, 0.05897105514710028, 0.02948552757355014, 0.7028711824534803, 0.2510254223048144, 0.8942688785592993, 0.8837804990657825, 0.8571043378541718, 0.49160078367241905, 0.01755717084544354, 0.08778585422721769, 0.052671512536330616, 0.19312887929987893, 0.17557170845443537, 0.04648264758691617, 0.9296529517383234, 0.45208396420124436, 0.11302099105031109, 0.3955734686760888, 0.07453011659921847, 0.4471806995953108, 0.03726505829960924, 0.3353855246964831, 0.07453011659921847, 0.03726505829960924, 0.8812021704258548, 0.14790103455853382, 0.7395051727926691, 0.7878918239522433, 0.7692673482732282, 0.030770693930929127, 0.12308277572371651, 0.061541387861858254, 0.925627887648381, 0.6994145365037856, 0.04995818117884183, 0.1498745435365255, 0.024979090589420914, 0.04995818117884183, 0.7532061199919713, 0.8949484191482745, 0.058877942954278714, 0.5593404580656478, 0.029438971477139357, 0.1471948573856968, 0.1471948573856968, 0.058877942954278714, 0.7255934024357923, 0.8087316271941287, 0.8353482762409067, 0.9140947094706161, 0.21302171863705915, 0.7455760152297071, 0.709223647285622, 0.7962390429828502, 0.8133158653016176, 0.13589655828053757, 0.8153793496832253, 0.8767732484714156, 0.07228626576126398, 0.8674351891351678, 0.07228626576126398, 0.47701913024701476, 0.057242295629641775, 0.3816153041976118, 0.01908076520988059, 0.057242295629641775, 0.01908076520988059, 0.8619559412553445, 0.6063006543733801, 0.026360898016233914, 0.07908269404870175, 0.10544359206493566, 0.18452628611363742, 0.2084210580674087, 0.7555263354943565, 0.013026316129213044, 0.013026316129213044, 0.9595669023098083, 0.8600406279726056, 0.8573962047383878, 0.06940742421542702, 0.20822227264628104, 0.06940742421542702, 0.6246668179388432, 0.06940742421542702, 0.8392180527528975, 0.5722470829433728, 0.04291853122075296, 0.10014323951509024, 0.01430617707358432, 0.15736794780942753, 0.10014323951509024, 0.15918656457849212, 0.048980481408766804, 0.0367353610565751, 0.6612364990183518, 0.09796096281753361, 0.9377924699446162, 0.7615390829844086, 0.8790238566468392, 0.5794883687426753, 0.040429421075070374, 0.24257652645042224, 0.02695294738338025, 0.040429421075070374, 0.06738236845845062, 0.9718059217976543, 0.6904531109444378, 0.845357943457046, 0.04137982463128364, 0.786216667994389, 0.08275964926256728, 0.08275964926256728, 0.02932444564636718, 0.7331111411591795, 0.02932444564636718, 0.1466222282318359, 0.02932444564636718, 0.02932444564636718, 0.9540543948852057, 0.2320276354706853, 0.05800690886767133, 0.696082906412056, 0.9114830158074546, 0.7544938240211887, 0.13314596894491565, 0.04438198964830521, 0.8546265562349863, 0.8861853147467623, 0.08056230134061476, 0.548239487387875, 0.03537028950889516, 0.17095639929299328, 0.04126533776037769, 0.12379601328113306, 0.08253067552075538, 0.7420155225311359, 0.3468904288223118, 0.1734452144111559, 0.20813425729338708, 0.15031918582300177, 0.06937808576446236, 0.0578150714703853, 0.8928524849784835, 0.6373401216400036, 0.934647824710316, 0.77074785803942, 0.035033993547246366, 0.035033993547246366, 0.035033993547246366, 0.035033993547246366, 0.07006798709449273, 0.711771839682035, 0.8054644620666513, 0.7606585805230718, 0.8544709385184355, 0.9416823016825074, 0.9158450084319336, 0.02289612521079834, 0.04579225042159668, 0.8621462050633636, 0.09579402278481818, 0.8948323799489969, 0.834018580005922, 0.7733683156423227, 0.05333574590636708, 0.05333574590636708, 0.05333574590636708, 0.02666787295318354, 0.02666787295318354, 0.886912973796366, 0.9110210447679468, 0.05693881529799667, 0.7885652040799178, 0.04928532525499486, 0.04928532525499486, 0.04928532525499486, 0.9492402888988675, 0.6562478439577285, 0.6738446755116754, 0.951287963298663, 0.7261515357971526, 0.03069468435345111, 0.36833621224141333, 0.06138936870690222, 0.30694684353451107, 0.18416810612070666, 0.03069468435345111, 0.26115662742222934, 0.06528915685555733, 0.293801205850008, 0.3590903627055653, 0.03264457842777867, 0.11067158243276597, 0.22134316486553193, 0.5533579121638298, 0.894726504933824, 0.06390903606670172, 0.06390903606670172, 0.6294010848313712, 0.0393375678019607, 0.17701905510882315, 0.05900635170294105, 0.0786751356039214, 0.01966878390098035, 0.05544293636028305, 0.4805054484557864, 0.05544293636028305, 0.29569566058817626, 0.05544293636028305, 0.05544293636028305, 0.8346710155363072, 0.0521669384710192, 0.0521669384710192, 0.9260094308732205, 0.05787558942957628, 0.8786427672490192, 0.15643877252314767, 0.15643877252314767, 0.6257550900925907, 0.13153347865893986, 0.7234341326241692, 0.06576673932946993, 0.8557476147782351, 0.8739523134282933, 0.06551520995596638, 0.8516977294275628, 0.6620325045427878, 0.24390671219997448, 0.03484381602856778, 0.7110548801886891, 0.7973881980854226, 0.6098652052310203, 0.861898776254274, 0.8812105558474598, 0.08011005053158726, 0.41045841308468994, 0.058636916154955705, 0.5277322453946014, 0.1602310732568646, 0.8011553662843229, 0.8152932368652066, 0.8230902053364745, 0.054872680355764966, 0.054872680355764966, 0.054872680355764966, 0.909298532224872, 0.8705608280759748, 0.7928342622198502, 0.13213904370330837, 0.04404634790110279, 0.8516623973291536, 0.9874942686936624, 0.051052910009847616, 0.5785996467782729, 0.017017636669949206, 0.22122927670933967, 0.06807054667979683, 0.051052910009847616, 0.932763169008128, 0.025209815378598052, 0.8499605661539541, 0.03695480722408496, 0.07390961444816992, 0.06847356681261783, 0.27389426725047133, 0.6162621013135605, 0.06213348910840169, 0.031066744554200845, 0.8388021029634228, 0.09320023366260254, 0.82127920109082, 0.6596938407660218, 0.06184629757181454, 0.22676975776331998, 0.02061543252393818, 0.02061543252393818, 0.02061543252393818, 0.8575290426403525, 0.6046100021295738, 0.060461000212957375, 0.18138300063887214, 0.03627660012777443, 0.08464540029814033, 0.03627660012777443, 0.08638563224759065, 0.6910850579807252, 0.1727712644951813, 0.911251503541156, 0.08284104577646874, 0.869468028979387, 0.8230246632448085, 0.4916577813759331, 0.43990433070478224, 0.05175345067115085, 0.11893780783737054, 0.7136268470242232, 0.12743394518565712, 0.7646036711139427, 0.027535016005133937, 0.6883754001283484, 0.027535016005133937, 0.0826050480154018, 0.1376750800256697, 0.027535016005133937, 0.021723320152705918, 0.4996363635122361, 0.021723320152705918, 0.1303399209162355, 0.30412648213788285, 0.021723320152705918, 0.9633418345621669, 0.7260322708966876, 0.04148755833695358, 0.06223133750543037, 0.06223133750543037, 0.06223133750543037, 0.04148755833695358, 0.5120696199300898, 0.08534493665501497, 0.28448312218338323, 0.056896624436676646, 0.028448312218338323, 0.9214287483094411, 0.9326564099267496, 0.3463464778271819, 0.04947806826102599, 0.19791227304410397, 0.14843420478307798, 0.29686840956615596, 0.07666739776469257, 0.8433413754116184, 0.10615293788593819, 0.7961470341445365, 0.05307646894296909, 0.29290558245604353, 0.0585811164912087, 0.5272300484208783, 0.1171622329824174, 0.0712758576719338, 0.6414827190474042, 0.2138275730158014, 0.06863325561865428, 0.8922323230425057, 0.5386022021891813, 0.0742899589226457, 0.055717469191984274, 0.0742899589226457, 0.055717469191984274, 0.20429738703727565, 0.36097316279330305, 0.12032438759776769, 0.6016219379888385, 0.18874260987579558, 0.09437130493789779, 0.7549704395031823, 0.6154023644291089, 0.03550398256321782, 0.22485855623371287, 0.03550398256321782, 0.0591733042720297, 0.04733864341762376, 0.20571776593166693, 0.6171532977950008, 0.15232733200282314, 0.22849099800423472, 0.15232733200282314, 0.3808183300070579, 0.07616366600141157, 0.13390645945279592, 0.8034387567167754, 0.8659318782314879, 0.03764921209702121, 0.03764921209702121, 0.03764921209702121, 0.03764921209702121, 0.9791601914546222, 0.07993104105663114, 0.7993104105663114, 0.8392294811582766, 0.04725588947576341, 0.4725588947576341, 0.04725588947576341, 0.30716328159246215, 0.09451177895152682, 0.023627944737881705, 0.9688171988358883, 0.16634937942764172, 0.6653975177105669, 0.3505247150984313, 0.0500749592997759, 0.47571211334787106, 0.02503747964988795, 0.0500749592997759, 0.0500749592997759, 0.04061212643032331, 0.04061212643032331, 0.8934667814671128, 0.04061212643032331, 0.9030130361620446, 0.6923875970654103, 0.11643845358387615, 0.8150691750871331, 0.03570149981494404, 0.49982099740921654, 0.04760199975325872, 0.2856119985195523, 0.07140299962988808, 0.0595024996915734, 0.7871525251735245, 0.02459851641167264, 0.09839406564669056, 0.02459851641167264, 0.02459851641167264, 0.02459851641167264], \"Term\": [\"a_lot\", \"a_must\", \"a_must\", \"a_must\", \"affordable\", \"agama_hindu\", \"agama_hindu\", \"ajaib_dunia\", \"ajaib_dunia\", \"ajaib_dunia\", \"ajaib_dunia\", \"ajaib_dunia\", \"ajar_sejarah\", \"ajar_sejarah\", \"ajar_sejarah\", \"ajar_sejarah\", \"ajar_sejarah\", \"ajar_sejarah\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"always\", \"always\", \"always\", \"always\", \"always\", \"amaze\", \"amaze\", \"amaze\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"an_amazing\", \"ancient_hindu\", \"ancient_hindu\", \"angle\", \"annual\", \"anymore\", \"around\", \"around\", \"around\", \"around\", \"around\", \"around\", \"around_mute\", \"arrange\", \"artist\", \"artistic\", \"awesome\", \"awesome\", \"awesome\", \"awesome\", \"awesome\", \"bagus\", \"bagus\", \"bagus\", \"bagus\", \"bagus\", \"bagus\", \"bagus_banget\", \"banget\", \"banget\", \"banget\", \"banget\", \"banget\", \"banget\", \"bangsa_indonesia\", \"bangsa_indonesia\", \"bangsa_indonesia\", \"bangsa_indonesia\", \"bawa\", \"bawa\", \"bawa\", \"bawa\", \"bawa\", \"bawa\", \"beatifull\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautifull\", \"became\", \"became\", \"bersih\", \"bersih\", \"bersih\", \"bersih\", \"bersih\", \"bersih\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best_place\", \"bgt\", \"bgt\", \"bgt\", \"bgt\", \"bit_expensive\", \"borobudur\", \"borobudur\", \"borobudur\", \"borobudur\", \"borobudur\", \"borobudur\", \"brahma_vishnu\", \"brahma_vishnu\", \"brahma_vishnu\", \"bring\", \"bring\", \"bring\", \"bring\", \"bring\", \"bring\", \"bring_hat\", \"bring_hat\", \"bring_hat\", \"bring_umbrella\", \"bring_umbrella\", \"bring_umbrella\", \"bring_umbrella\", \"cagar\", \"cagar_budaya\", \"cagar_budaya\", \"cagar_budaya\", \"candi_prambanan\", \"candi_prambanan\", \"candi_prambanan\", \"candi_prambanan\", \"candi_prambanan\", \"candi_prambanan\", \"careful\", \"central_java\", \"central_java\", \"central_java\", \"central_java\", \"central_java\", \"central_java\", \"civilization\", \"clean\", \"clean\", \"clean\", \"clean\", \"clean\", \"come_back\", \"come_back\", \"cool\", \"cool\", \"cultural_heritage\", \"cuman\", \"describe\", \"describe\", \"describe\", \"destinasi_wajib\", \"destinasi_wisata\", \"destinasi_wisata\", \"destination\", \"destination\", \"destination\", \"destination\", \"destroyed_earthquake\", \"dewasa_rp\", \"dont_forget\", \"dont_forget\", \"dont_forget\", \"dont_forget\", \"dont_forget_bring_umbrella\", \"dont_miss\", \"dont_miss\", \"easy_access\", \"easy_access\", \"enjoy\", \"enjoy\", \"enjoy\", \"enjoy\", \"enjoy\", \"enjoy\", \"entrance_fee\", \"entrance_fee\", \"entrance_fee\", \"entrance_fee\", \"entrance_fee\", \"entry_ticket\", \"entry_ticket\", \"even\", \"exciting\", \"exit_gate\", \"expensive_foreigner\", \"expensive_foreigner\", \"far_away\", \"feel_like\", \"feel_like\", \"find\", \"find\", \"find\", \"find\", \"foreign_tourist\", \"gak\", \"gak\", \"gak\", \"gak\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go_early\", \"go_early\", \"go_early\", \"gods\", \"golden\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great_place\", \"great_place\", \"great_place\", \"great_place\", \"great_place\", \"great_view\", \"haha\", \"half_day\", \"harga\", \"harga\", \"harga\", \"harga\", \"harga\", \"harga\", \"harga_jangkau\", \"harga_tiket\", \"harga_tiket\", \"harga_tiket\", \"harga_tiket\", \"harga_tiket\", \"harga_tiket\", \"have\", \"have\", \"have\", \"heritage\", \"heritage\", \"heritage\", \"heritage\", \"heritage\", \"heritage\", \"heritage_site\", \"heritage_site\", \"heritage_site\", \"heritage_site\", \"heritage_site\", \"herritage\", \"highly_recommend\", \"hindhu\", \"hindu\", \"hindu\", \"hindu\", \"hindu\", \"hindu\", \"hindu\", \"hindu_besar\", \"hindu_besar\", \"hindu_besar\", \"hindu_besar\", \"hindu_besar\", \"hindu_temple\", \"hindu_temple\", \"hindu_temple\", \"hindu_temple\", \"hindus\", \"hindus\", \"hindus\", \"hindus_temple\", \"hindus_temple\", \"hindus_temple\", \"his\", \"historic\", \"historic\", \"historic_place\", \"historical\", \"historical\", \"historical\", \"historical\", \"historical\", \"historical\", \"historical_building\", \"historical_place\", \"historical_place\", \"historical_site\", \"historical_site\", \"historical_value\", \"history\", \"history\", \"history\", \"history\", \"history\", \"history\", \"holiday_season\", \"holiday_season\", \"hospitality\", \"hot_day\", \"hot_day\", \"hot_weather\", \"htm\", \"htm\", \"human\", \"human\", \"human\", \"i\", \"i\", \"i\", \"i\", \"i\", \"i\", \"i_came\", \"i_came\", \"i_hope\", \"i_love\", \"i_love\", \"i_love\", \"i_love\", \"i_love\", \"i_recommend\", \"i_recommend\", \"i_recommend\", \"i_recommend\", \"i_suggest\", \"i_suggest\", \"iconic\", \"if_youre\", \"if_youre\", \"ill\", \"indah\", \"indah\", \"indah\", \"indah\", \"indah\", \"indah\", \"indonesia\", \"indonesia\", \"indonesia\", \"indonesia\", \"indonesia\", \"indonesia\", \"indonesias\", \"is\", \"it\", \"it\", \"it\", \"it\", \"it\", \"it\", \"its\", \"its\", \"its\", \"its\", \"its\", \"its\", \"its_really\", \"its_really\", \"jangan_lupa\", \"jangan_lupa\", \"java\", \"java\", \"java\", \"java\", \"java\", \"jazz\", \"jogja\", \"jogja\", \"jogja\", \"jogja\", \"jogja\", \"jogja\", \"jual_souvenir\", \"kalo_jogja\", \"kalo_kesini\", \"kamar_mandi\", \"kenal_sejarah\", \"kenang\", \"kenang\", \"keren\", \"keren\", \"keren\", \"keren\", \"keren\", \"keren\", \"kesana\", \"kesana\", \"kesana\", \"kesana\", \"kesini\", \"kesini\", \"kesini\", \"kesini\", \"kesini\", \"kesini\", \"kesini_pa\", \"kingdom\", \"knowing\", \"kunjung\", \"kunjung\", \"kunjung\", \"kunjung\", \"kunjung\", \"kunjung\", \"landmark\", \"largest_buddhist\", \"largest_buddhist\", \"largest_buddhist\", \"largest_buddhist\", \"largest_buddhist\", \"largest_hindu\", \"largest_hindu\", \"largest_hindu\", \"learn\", \"learn\", \"learn\", \"learn_history\", \"legacy\", \"lg\", \"lg\", \"lifetime\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"little_bit\", \"little_bit\", \"local_guide\", \"local_tourist\", \"location\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love_place\", \"love_place\", \"lovely\", \"lovely\", \"lovely\", \"luas\", \"luas\", \"luas\", \"luas\", \"luas\", \"luas\", \"lumayan_mahal\", \"main_anak\", \"main_anak\", \"main_road\", \"make_sure\", \"make_sure\", \"make_sure\", \"make_sure\", \"manca_negara\", \"many\", \"many\", \"many\", \"many\", \"many\", \"marathon\", \"marvelous\", \"masuk\", \"masuk\", \"masuk\", \"masuk\", \"masuk\", \"masuk\", \"masuk_dewasa\", \"meet\", \"memorable\", \"mesmerizing\", \"middle\", \"middle\", \"mineral_water\", \"monumental\", \"more\", \"much_better\", \"much_better\", \"musholla\", \"musim_libur\", \"musim_libur\", \"musim_libur\", \"must\", \"must\", \"must\", \"must\", \"must\", \"must\", \"must_come\", \"must_see\", \"must_see\", \"must_see\", \"must_see\", \"must_see\", \"must_visit\", \"must_visit\", \"must_visit\", \"must_visit\", \"must_visited\", \"named\", \"national\", \"nenek_moyang\", \"nenek_moyang\", \"nenek_moyang\", \"nenek_moyang\", \"nenek_moyang\", \"never_forget\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice_place\", \"nice_place\", \"nice_place\", \"nice_place\", \"nice_place\", \"nice_view\", \"noon\", \"of\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one_best\", \"one_oldest\", \"one_wonder\", \"pa\", \"pa\", \"pa\", \"pa\", \"panas\", \"panas\", \"panas\", \"panas\", \"panas\", \"panas\", \"parking_area\", \"parkir_luas\", \"parkir_luas\", \"parkir_luas\", \"parkir_mobil\", \"payung\", \"payung\", \"payung\", \"pd\", \"pertama_kali\", \"pertama_kali\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"polite\", \"prambanan\", \"prambanan\", \"prambanan\", \"prambanan\", \"prambanan\", \"prambanan\", \"prambanan_jazz\", \"prasasti_siwagrha\", \"preserve\", \"price\", \"price\", \"price\", \"price\", \"price\", \"price\", \"province\", \"pulau_jawa\", \"raining\", \"raka\", \"raka_pikat\", \"ramayana_ballet\", \"ramayana_ballet\", \"ramayana_ballet\", \"rame\", \"rame\", \"rame_banget\", \"rara_jonggrang\", \"really\", \"really\", \"really\", \"really\", \"really\", \"really\", \"really_hot\", \"recomended\", \"recomended\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"restoration_work\", \"restoring\", \"rich_history\", \"romantic\", \"rumah_siwa\", \"salah\", \"salah\", \"salah\", \"salah\", \"salah\", \"salah\", \"salah_ajaib\", \"salah_ajaib\", \"salah_ajaib\", \"salah_ajaib\", \"salah_ajaib\", \"salah_destinasi\", \"salah_destinasi\", \"salah_destinasi\", \"scenery\", \"scenery\", \"scenery\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"sejarah\", \"sejarah\", \"sejarah\", \"sejarah\", \"sejarah\", \"sejarah\", \"sewa_payung\", \"sewa_payung\", \"sewa_payung\", \"siang_panas\", \"siang_panas\", \"sinar_matahari\", \"situs_sejarah\", \"situs_sejarah\", \"situs_sejarah\", \"south_east\", \"south_east\", \"south_east\", \"southeast_asia\", \"spectacular\", \"spend_time\", \"spend_time\", \"spot_foto\", \"spot_foto\", \"spot_foto\", \"square_three\", \"stage\", \"state\", \"story_behind\", \"study_tour\", \"study_tour\", \"such\", \"such\", \"such\", \"such_amazing\", \"such_amazing\", \"suggested\", \"suka\", \"suka\", \"suka\", \"suka\", \"sunny\", \"sunny_day\", \"take_photo\", \"take_photo\", \"take_photo\", \"taman_wisata\", \"tample\", \"tempat\", \"tempat\", \"tempat\", \"tempat\", \"tempat\", \"tempat\", \"tempat_bagus\", \"tempat_bagus\", \"tempat_bersih\", \"tempat_bersih\", \"tempat_bersih\", \"tempat_luas\", \"tempat_luas\", \"tempat_luas\", \"tempat_wisata\", \"tempat_wisata\", \"tempat_wisata\", \"tempat_wisata\", \"tempel\", \"temple_complex\", \"temple_complex\", \"temple_complex\", \"temple_complex\", \"temple_complex\", \"temple_complex\", \"terus\", \"the\", \"the\", \"the\", \"the\", \"the\", \"the\", \"the_best\", \"the_best\", \"the_best\", \"the_biggest\", \"the_biggest\", \"they\", \"this_one\", \"this_place\", \"this_place\", \"this_place\", \"three_main\", \"three_main\", \"ticket_expensive\", \"ticket_expensive\", \"tiket\", \"tiket\", \"tiket\", \"tiket\", \"tiket\", \"tiket\", \"tiket_masuk\", \"tiket_masuk\", \"tiket_masuk\", \"tiket_masuk\", \"tiket_masuk\", \"tiket_masuk\", \"tiket_terus\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"tinggal_sejarah\", \"tinggal_sejarah\", \"tinggal_sejarah\", \"tinggal_sejarah\", \"tinggal_sejarah\", \"tourist_attraction\", \"travelling\", \"umbrella\", \"umbrella\", \"umbrella\", \"umbrella\", \"umbrella\", \"unesco_heritage\", \"unesco_heritage\", \"unesco_world\", \"unesco_world\", \"unesco_world\", \"utk\", \"utk\", \"utk\", \"utk\", \"very_beautiful\", \"very_beautiful\", \"very_beautiful\", \"very_nice\", \"very_nice\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view_top\", \"view_top\", \"view_top\", \"vishnu\", \"vishnu\", \"vishnu\", \"visit\", \"visit\", \"visit\", \"visit\", \"visit\", \"visit\", \"wahana\", \"wahana\", \"waris_budaya\", \"waris_budaya\", \"waris_budaya\", \"waris_budaya\", \"waris_budaya\", \"watch_ramayana\", \"watch_ramayana\", \"well_maintained\", \"well_maintained\", \"well_maintained\", \"well_maintained\", \"well_maintained\", \"well_managed\", \"well_preserved\", \"well_preserved\", \"whole_complex\", \"wisata\", \"wisata\", \"wisata\", \"wisata\", \"wisata\", \"wisata\", \"wonderfull\", \"word\", \"word\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world_heritage\", \"world_heritage\", \"world_heritage\", \"world_heritage\", \"worlds\", \"worth_seeing\", \"worthy\", \"worthy\", \"yg\", \"yg\", \"yg\", \"yg\", \"yg\", \"yg\", \"you\", \"you\", \"you\", \"you\", \"you\", \"you\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 2, 1, 6, 3, 4]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el219461279844152166243659113434\", ldavis_el219461279844152166243659113434_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el219461279844152166243659113434\", ldavis_el219461279844152166243659113434_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el219461279844152166243659113434\", ldavis_el219461279844152166243659113434_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "4      0.188594 -0.051464       1        1  33.007772\n",
       "1     -0.162611  0.020288       2        1  23.231395\n",
       "0      0.091314  0.125169       3        1  13.811300\n",
       "5     -0.090154 -0.005614       4        1  12.927387\n",
       "2     -0.021128 -0.035559       5        1   9.045828\n",
       "3     -0.006016 -0.052820       6        1   7.976318, topic_info=                  Term       Freq      Total Category  logprob  loglift\n",
       "3298  historical_place  70.000000  70.000000  Default  30.0000  30.0000\n",
       "1614        nice_place  81.000000  81.000000  Default  29.0000  29.0000\n",
       "1810        must_visit  76.000000  76.000000  Default  28.0000  28.0000\n",
       "2735            tample  73.000000  73.000000  Default  27.0000  27.0000\n",
       "3634          one_best  37.000000  37.000000  Default  26.0000  26.0000\n",
       "...                ...        ...        ...      ...      ...      ...\n",
       "1613              nice   6.935702  69.899876   Topic6  -5.6203   0.2183\n",
       "1577      entrance_fee   5.005875  17.853839   Topic6  -5.9464   1.2571\n",
       "2292        little_bit   5.067644  19.918301   Topic6  -5.9342   1.1599\n",
       "1167               one   5.473688  74.203388   Topic6  -5.8571  -0.0782\n",
       "109                 yg   5.103653  84.030083   Topic6  -5.9271  -0.2725\n",
       "\n",
       "[389 rows x 6 columns], token_table=      Topic      Freq        Term\n",
       "term                             \n",
       "3076      3  0.898009       a_lot\n",
       "2386      1  0.526315      a_must\n",
       "2386      2  0.032895      a_must\n",
       "2386      3  0.394737      a_must\n",
       "3577      1  0.849186  affordable\n",
       "...     ...       ...         ...\n",
       "1935      2  0.024599         you\n",
       "1935      3  0.098394         you\n",
       "1935      4  0.024599         you\n",
       "1935      5  0.024599         you\n",
       "1935      6  0.024599         you\n",
       "\n",
       "[867 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[5, 2, 1, 6, 3, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluasi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
